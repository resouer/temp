kubeadm reset...
compile k8s...
install k8s...
install local pv...
k8s e2e test...
2018/09/04 01:37:06 e2e.go:153: The kubetest binary is older than 24h0m0s.
2018/09/04 01:37:06 e2e.go:158: Updating kubetest binary...
2018/09/04 01:38:32 e2e.go:79: Calling kubetest --verbose-commands=true --provider=local --test --test_args=--ginkgo.focus=\[Conformance\]...
2018/09/04 01:38:32 process.go:153: Running: ./hack/e2e-internal/e2e-status.sh
Skeleton Provider: prepare-e2e not implemented
Client Version: version.Info{Major:"1", Minor:"11", GitVersion:"v1.11.2", GitCommit:"bb9ffb1654d4a729bb4cec18ff088eacc153c239", GitTreeState:"clean", BuildDate:"2018-08-31T09:39:29Z", GoVersion:"go1.10.2", Compiler:"gc", Platform:"linux/arm64"}
Server Version: version.Info{Major:"1", Minor:"11", GitVersion:"v1.11.2", GitCommit:"bb9ffb1654d4a729bb4cec18ff088eacc153c239", GitTreeState:"clean", BuildDate:"2018-08-07T23:08:19Z", GoVersion:"go1.10.3", Compiler:"gc", Platform:"linux/arm64"}
2018/09/04 01:38:32 process.go:155: Step './hack/e2e-internal/e2e-status.sh' finished in 597.33558ms
2018/09/04 01:38:32 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false version
2018/09/04 01:38:33 process.go:155: Step './cluster/kubectl.sh --match-server-version=false version' finished in 328.4157ms
2018/09/04 01:38:33 process.go:153: Running: ./hack/ginkgo-e2e.sh --ginkgo.focus=\[Conformance\]
Conformance test: not doing test setup.
Sep  4 01:38:34.982: INFO: Overriding default scale value of zero to 1
Sep  4 01:38:34.982: INFO: Overriding default milliseconds value of zero to 5000
I0904 01:38:35.349197   10499 e2e.go:333] Starting e2e run "3cd852a6-afe3-11e8-8336-00073e906c7f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: [1m1536025114[0m - Will randomize all specs
Will run [1m167[0m of [1m996[0m specs

Sep  4 01:38:35.420: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 01:38:35.430: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  4 01:38:35.569: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  4 01:38:35.628: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  4 01:38:35.628: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Sep  4 01:38:35.634: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Sep  4 01:38:35.634: INFO: Dumping network health container logs from all nodes...
Sep  4 01:38:35.639: INFO: e2e test version: v1.11.2
Sep  4 01:38:35.642: INFO: kube-apiserver version: v1.11.2
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:38:35.642: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
Sep  4 01:38:35.825: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-3d748b21-afe3-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 01:38:35.847: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3d75a788-afe3-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-fw4cz" to be "success or failure"
Sep  4 01:38:35.852: INFO: Pod "pod-projected-configmaps-3d75a788-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.16456ms
Sep  4 01:38:37.858: INFO: Pod "pod-projected-configmaps-3d75a788-afe3-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01032514s
[1mSTEP[0m: Saw pod success
Sep  4 01:38:37.858: INFO: Pod "pod-projected-configmaps-3d75a788-afe3-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:38:37.862: INFO: Trying to get logs from node node3 pod pod-projected-configmaps-3d75a788-afe3-11e8-8336-00073e906c7f container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:38:38.017: INFO: Waiting for pod pod-projected-configmaps-3d75a788-afe3-11e8-8336-00073e906c7f to disappear
Sep  4 01:38:38.022: INFO: Pod pod-projected-configmaps-3d75a788-afe3-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:38:38.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-fw4cz" for this suite.
Sep  4 01:38:44.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:38:44.168: INFO: namespace: e2e-tests-projected-fw4cz, resource: bindings, ignored listing per whitelist
Sep  4 01:38:44.179: INFO: namespace e2e-tests-projected-fw4cz deletion completed in 6.15215888s

[32mâ€¢ [SLOW TEST:8.537 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:38:44.180: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating the pod
Sep  4 01:38:46.890: INFO: Successfully updated pod "labelsupdate4287ec57-afe3-11e8-8336-00073e906c7f"
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:38:50.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-2s9kx" for this suite.
Sep  4 01:39:12.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:39:13.015: INFO: namespace: e2e-tests-projected-2s9kx, resource: bindings, ignored listing per whitelist
Sep  4 01:39:13.088: INFO: namespace e2e-tests-projected-2s9kx deletion completed in 22.1483328s

[32mâ€¢ [SLOW TEST:28.908 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should update labels on modification [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0666,default) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:39:13.089: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0666 on node default medium
Sep  4 01:39:13.262: INFO: Waiting up to 5m0s for pod "pod-53c360a8-afe3-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-j625j" to be "success or failure"
Sep  4 01:39:13.267: INFO: Pod "pod-53c360a8-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.81692ms
Sep  4 01:39:15.272: INFO: Pod "pod-53c360a8-afe3-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00980752s
[1mSTEP[0m: Saw pod success
Sep  4 01:39:15.272: INFO: Pod "pod-53c360a8-afe3-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:39:15.276: INFO: Trying to get logs from node node3 pod pod-53c360a8-afe3-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:39:15.300: INFO: Waiting for pod pod-53c360a8-afe3-11e8-8336-00073e906c7f to disappear
Sep  4 01:39:15.304: INFO: Pod pod-53c360a8-afe3-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:39:15.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-j625j" for this suite.
Sep  4 01:39:21.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:39:21.458: INFO: namespace: e2e-tests-emptydir-j625j, resource: bindings, ignored listing per whitelist
Sep  4 01:39:21.462: INFO: namespace e2e-tests-emptydir-j625j deletion completed in 6.1524051s

[32mâ€¢ [SLOW TEST:8.373 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0666,default) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl label[0m 
  [1mshould update the label on a resource  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:39:21.462: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl label
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1012
[1mSTEP[0m: creating the pod
Sep  4 01:39:21.622: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-2v6tb'
Sep  4 01:39:22.131: INFO: stderr: ""
Sep  4 01:39:22.131: INFO: stdout: "pod/pause created\n"
Sep  4 01:39:22.131: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  4 01:39:22.131: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-2v6tb" to be "running and ready"
Sep  4 01:39:22.137: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.57664ms
Sep  4 01:39:24.142: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.01058296s
Sep  4 01:39:24.142: INFO: Pod "pause" satisfied condition "running and ready"
Sep  4 01:39:24.142: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: adding the label testing-label with value testing-label-value to a pod
Sep  4 01:39:24.142: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-2v6tb'
Sep  4 01:39:24.476: INFO: stderr: ""
Sep  4 01:39:24.476: INFO: stdout: "pod/pause labeled\n"
[1mSTEP[0m: verifying the pod has the label testing-label with the value testing-label-value
Sep  4 01:39:24.476: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pod pause -L testing-label --namespace=e2e-tests-kubectl-2v6tb'
Sep  4 01:39:24.800: INFO: stderr: ""
Sep  4 01:39:24.800: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          2s        testing-label-value\n"
[1mSTEP[0m: removing the label testing-label of a pod
Sep  4 01:39:24.801: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf label pods pause testing-label- --namespace=e2e-tests-kubectl-2v6tb'
Sep  4 01:39:25.134: INFO: stderr: ""
Sep  4 01:39:25.134: INFO: stdout: "pod/pause labeled\n"
[1mSTEP[0m: verifying the pod doesn't have the label testing-label
Sep  4 01:39:25.134: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pod pause -L testing-label --namespace=e2e-tests-kubectl-2v6tb'
Sep  4 01:39:25.461: INFO: stderr: ""
Sep  4 01:39:25.461: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          3s        \n"
[AfterEach] [k8s.io] Kubectl label
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1018
[1mSTEP[0m: using delete to clean up resources
Sep  4 01:39:25.461: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2v6tb'
Sep  4 01:39:25.834: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 01:39:25.834: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  4 01:39:25.834: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-2v6tb'
Sep  4 01:39:26.176: INFO: stderr: "No resources found.\n"
Sep  4 01:39:26.176: INFO: stdout: ""
Sep  4 01:39:26.176: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -l name=pause --namespace=e2e-tests-kubectl-2v6tb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 01:39:26.502: INFO: stderr: ""
Sep  4 01:39:26.502: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:39:26.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-2v6tb" for this suite.
Sep  4 01:39:32.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:39:32.538: INFO: namespace: e2e-tests-kubectl-2v6tb, resource: bindings, ignored listing per whitelist
Sep  4 01:39:32.658: INFO: namespace e2e-tests-kubectl-2v6tb deletion completed in 6.1507577s

[32mâ€¢ [SLOW TEST:11.196 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl label
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should update the label on a resource  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:39:32.659: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-5f6f06df-afe3-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-5f6f0780-afe3-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-5f6f06df-afe3-11e8-8336-00073e906c7f
[1mSTEP[0m: Updating configmap cm-test-opt-upd-5f6f0780-afe3-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-5f6f07b9-afe3-11e8-8336-00073e906c7f
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:41:03.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-52nks" for this suite.
Sep  4 01:41:25.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:41:25.676: INFO: namespace: e2e-tests-configmap-52nks, resource: bindings, ignored listing per whitelist
Sep  4 01:41:25.796: INFO: namespace e2e-tests-configmap-52nks deletion completed in 22.1473431s

[32mâ€¢ [SLOW TEST:113.138 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Pods Extended[0m [90m[k8s.io] Pods Set QOS Class[0m 
  [1mshould be submitted and removed  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:41:25.797: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:41:25.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-7fgpf" for this suite.
Sep  4 01:41:47.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:41:48.024: INFO: namespace: e2e-tests-pods-7fgpf, resource: bindings, ignored listing per whitelist
Sep  4 01:41:48.130: INFO: namespace e2e-tests-pods-7fgpf deletion completed in 22.15058856s

[32mâ€¢ [SLOW TEST:22.333 seconds][0m
[k8s.io] [sig-node] Pods Extended
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  [k8s.io] Pods Set QOS Class
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should be submitted and removed  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0666,tmpfs) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:41:48.131: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0666 on tmpfs
Sep  4 01:41:48.302: INFO: Waiting up to 5m0s for pod "pod-b02c7817-afe3-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-q4m8c" to be "success or failure"
Sep  4 01:41:48.309: INFO: Pod "pod-b02c7817-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.076ms
Sep  4 01:41:50.314: INFO: Pod "pod-b02c7817-afe3-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01209802s
[1mSTEP[0m: Saw pod success
Sep  4 01:41:50.314: INFO: Pod "pod-b02c7817-afe3-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:41:50.318: INFO: Trying to get logs from node node3 pod pod-b02c7817-afe3-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:41:50.344: INFO: Waiting for pod pod-b02c7817-afe3-11e8-8336-00073e906c7f to disappear
Sep  4 01:41:50.349: INFO: Pod pod-b02c7817-afe3-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:41:50.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-q4m8c" for this suite.
Sep  4 01:41:56.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:41:56.441: INFO: namespace: e2e-tests-emptydir-q4m8c, resource: bindings, ignored listing per whitelist
Sep  4 01:41:56.502: INFO: namespace e2e-tests-emptydir-q4m8c deletion completed in 6.1470071s

[32mâ€¢ [SLOW TEST:8.371 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run deployment[0m 
  [1mshould create a deployment from an image  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:41:56.503: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run deployment
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1316
[It] should create a deployment from an image  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: running the image k8s.gcr.io/nginx-slim-arm64:0.26
Sep  4 01:41:56.663: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-arm64:0.26 --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-z2cgq'
Sep  4 01:41:57.146: INFO: stderr: ""
Sep  4 01:41:57.146: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
[1mSTEP[0m: verifying the deployment e2e-test-nginx-deployment was created
[1mSTEP[0m: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1321
Sep  4 01:41:59.157: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-z2cgq'
Sep  4 01:41:59.490: INFO: stderr: ""
Sep  4 01:41:59.490: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:41:59.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-z2cgq" for this suite.
Sep  4 01:42:05.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:42:05.608: INFO: namespace: e2e-tests-kubectl-z2cgq, resource: bindings, ignored listing per whitelist
Sep  4 01:42:05.647: INFO: namespace e2e-tests-kubectl-z2cgq deletion completed in 6.15009652s

[32mâ€¢ [SLOW TEST:9.144 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run deployment
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create a deployment from an image  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould run and stop complex daemon [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:42:05.647: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop complex daemon [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 01:42:05.827: INFO: Creating daemon "daemon-set" with a node selector
[1mSTEP[0m: Initially, daemon pods should not be running on any nodes.
Sep  4 01:42:05.838: INFO: Number of nodes with available pods: 0
Sep  4 01:42:05.838: INFO: Number of running nodes: 0, number of available pods: 0
[1mSTEP[0m: Change node label to blue, check that daemon pod is launched.
Sep  4 01:42:05.863: INFO: Number of nodes with available pods: 0
Sep  4 01:42:05.863: INFO: Node node3 is running more than one daemon pod
Sep  4 01:42:06.868: INFO: Number of nodes with available pods: 0
Sep  4 01:42:06.868: INFO: Node node3 is running more than one daemon pod
Sep  4 01:42:07.868: INFO: Number of nodes with available pods: 1
Sep  4 01:42:07.868: INFO: Number of running nodes: 1, number of available pods: 1
[1mSTEP[0m: Update the node label to green, and wait for daemons to be unscheduled
Sep  4 01:42:07.890: INFO: Number of nodes with available pods: 1
Sep  4 01:42:07.890: INFO: Number of running nodes: 0, number of available pods: 1
Sep  4 01:42:08.895: INFO: Number of nodes with available pods: 0
Sep  4 01:42:08.895: INFO: Number of running nodes: 0, number of available pods: 0
[1mSTEP[0m: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  4 01:42:08.913: INFO: Number of nodes with available pods: 0
Sep  4 01:42:08.913: INFO: Node node3 is running more than one daemon pod
Sep  4 01:42:09.918: INFO: Number of nodes with available pods: 0
Sep  4 01:42:09.918: INFO: Node node3 is running more than one daemon pod
Sep  4 01:42:10.918: INFO: Number of nodes with available pods: 0
Sep  4 01:42:10.918: INFO: Node node3 is running more than one daemon pod
Sep  4 01:42:11.918: INFO: Number of nodes with available pods: 0
Sep  4 01:42:11.918: INFO: Node node3 is running more than one daemon pod
Sep  4 01:42:12.917: INFO: Number of nodes with available pods: 1
Sep  4 01:42:12.918: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-lmq5q, will wait for the garbage collector to delete the pods
Sep  4 01:42:12.990: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.21496ms
Sep  4 01:42:13.090: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.23546ms
Sep  4 01:42:15.895: INFO: Number of nodes with available pods: 0
Sep  4 01:42:15.895: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 01:42:15.904: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lmq5q/daemonsets","resourceVersion":"168016"},"items":null}

Sep  4 01:42:15.909: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lmq5q/pods","resourceVersion":"168016"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:42:15.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-lmq5q" for this suite.
Sep  4 01:42:21.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:42:22.000: INFO: namespace: e2e-tests-daemonsets-lmq5q, resource: bindings, ignored listing per whitelist
Sep  4 01:42:22.089: INFO: namespace e2e-tests-daemonsets-lmq5q deletion completed in 6.15586904s

[32mâ€¢ [SLOW TEST:16.441 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should run and stop complex daemon [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:42:22.089: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-c46a5551-afe3-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 01:42:22.267: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c46b1816-afe3-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-dh6xh" to be "success or failure"
Sep  4 01:42:22.272: INFO: Pod "pod-projected-configmaps-c46b1816-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.6114ms
Sep  4 01:42:24.277: INFO: Pod "pod-projected-configmaps-c46b1816-afe3-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00987232s
[1mSTEP[0m: Saw pod success
Sep  4 01:42:24.277: INFO: Pod "pod-projected-configmaps-c46b1816-afe3-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:42:24.281: INFO: Trying to get logs from node node3 pod pod-projected-configmaps-c46b1816-afe3-11e8-8336-00073e906c7f container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:42:24.304: INFO: Waiting for pod pod-projected-configmaps-c46b1816-afe3-11e8-8336-00073e906c7f to disappear
Sep  4 01:42:24.308: INFO: Pod pod-projected-configmaps-c46b1816-afe3-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:42:24.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-dh6xh" for this suite.
Sep  4 01:42:30.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:42:30.422: INFO: namespace: e2e-tests-projected-dh6xh, resource: bindings, ignored listing per whitelist
Sep  4 01:42:30.463: INFO: namespace e2e-tests-projected-dh6xh deletion completed in 6.14939204s

[32mâ€¢ [SLOW TEST:8.374 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide pod UID as env vars [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:42:30.463: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward api env vars
Sep  4 01:42:30.632: INFO: Waiting up to 5m0s for pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-6fxmg" to be "success or failure"
Sep  4 01:42:30.636: INFO: Pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.58786ms
Sep  4 01:42:32.641: INFO: Pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0092469s
Sep  4 01:42:34.646: INFO: Pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01421646s
Sep  4 01:42:36.651: INFO: Pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01910674s
Sep  4 01:42:38.656: INFO: Pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02446202s
Sep  4 01:42:40.661: INFO: Pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02940136s
Sep  4 01:42:42.667: INFO: Pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03507778s
[1mSTEP[0m: Saw pod success
Sep  4 01:42:42.667: INFO: Pod "downward-api-c9678440-afe3-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:42:42.671: INFO: Trying to get logs from node node3 pod downward-api-c9678440-afe3-11e8-8336-00073e906c7f container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:42:42.696: INFO: Waiting for pod downward-api-c9678440-afe3-11e8-8336-00073e906c7f to disappear
Sep  4 01:42:42.701: INFO: Pod downward-api-c9678440-afe3-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:42:42.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-6fxmg" for this suite.
Sep  4 01:42:48.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:42:48.781: INFO: namespace: e2e-tests-downward-api-6fxmg, resource: bindings, ignored listing per whitelist
Sep  4 01:42:48.852: INFO: namespace e2e-tests-downward-api-6fxmg deletion completed in 6.14551842s

[32mâ€¢ [SLOW TEST:18.389 seconds][0m
[sig-api-machinery] Downward API
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37[0m
  should provide pod UID as env vars [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates that NodeSelector is respected if not matching  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:42:48.853: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Sep  4 01:42:49.016: INFO: Waiting up to 1m0s for all nodes to be ready
Sep  4 01:43:49.046: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 01:43:49.053: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  4 01:43:49.069: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  4 01:43:49.069: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Sep  4 01:43:49.075: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Sep  4 01:43:49.075: INFO: 
Logging pods the kubelet thinks is on node node3 before test
Sep  4 01:43:49.091: INFO: etcd-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 01:43:49.091: INFO: coredns-78fcdf6894-vlxkz from kube-system started at 2018-09-01 03:57:03 +0000 UTC (1 container statuses recorded)
Sep  4 01:43:49.091: INFO: 	Container coredns ready: true, restart count 1
Sep  4 01:43:49.091: INFO: kube-proxy-d6xgq from kube-system started at 2018-09-01 03:55:38 +0000 UTC (1 container statuses recorded)
Sep  4 01:43:49.091: INFO: 	Container kube-proxy ready: true, restart count 1
Sep  4 01:43:49.091: INFO: weave-net-qrwm8 from kube-system started at 2018-09-01 03:55:38 +0000 UTC (2 container statuses recorded)
Sep  4 01:43:49.091: INFO: 	Container weave ready: true, restart count 2
Sep  4 01:43:49.091: INFO: 	Container weave-npc ready: true, restart count 1
Sep  4 01:43:49.091: INFO: coredns-78fcdf6894-f55jj from kube-system started at 2018-09-01 03:57:03 +0000 UTC (1 container statuses recorded)
Sep  4 01:43:49.091: INFO: 	Container coredns ready: true, restart count 1
Sep  4 01:43:49.091: INFO: kube-apiserver-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 01:43:49.091: INFO: kube-controller-manager-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 01:43:49.091: INFO: kube-scheduler-node3 from kube-system started at <nil> (0 container statuses recorded)
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Trying to schedule Pod with nonempty NodeSelector.
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [restricted-pod.15510efd54c0dee4], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:43:50.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-cxlzh" for this suite.
Sep  4 01:43:56.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:43:56.252: INFO: namespace: e2e-tests-sched-pred-cxlzh, resource: bindings, ignored listing per whitelist
Sep  4 01:43:56.278: INFO: namespace e2e-tests-sched-pred-cxlzh deletion completed in 6.14723338s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

[32mâ€¢ [SLOW TEST:67.426 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates that NodeSelector is respected if not matching  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide host IP as an env var [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:43:56.279: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward api env vars
Sep  4 01:43:56.460: INFO: Waiting up to 5m0s for pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-mhflr" to be "success or failure"
Sep  4 01:43:56.465: INFO: Pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.6808ms
Sep  4 01:43:58.470: INFO: Pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00971702s
Sep  4 01:44:00.475: INFO: Pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01472814s
Sep  4 01:44:02.480: INFO: Pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01985834s
Sep  4 01:44:04.485: INFO: Pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02473768s
Sep  4 01:44:06.491: INFO: Pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.03105368s
Sep  4 01:44:08.496: INFO: Pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03609346s
[1mSTEP[0m: Saw pod success
Sep  4 01:44:08.496: INFO: Pod "downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:44:08.500: INFO: Trying to get logs from node node3 pod downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:44:08.526: INFO: Waiting for pod downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f to disappear
Sep  4 01:44:08.530: INFO: Pod downward-api-fc8fa113-afe3-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:44:08.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-mhflr" for this suite.
Sep  4 01:44:14.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:44:14.640: INFO: namespace: e2e-tests-downward-api-mhflr, resource: bindings, ignored listing per whitelist
Sep  4 01:44:14.685: INFO: namespace e2e-tests-downward-api-mhflr deletion completed in 6.15036026s

[32mâ€¢ [SLOW TEST:18.406 seconds][0m
[sig-api-machinery] Downward API
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37[0m
  should provide host IP as an env var [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0666,tmpfs) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:44:14.685: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0666 on tmpfs
Sep  4 01:44:14.860: INFO: Waiting up to 5m0s for pod "pod-0787529b-afe4-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-lb9cq" to be "success or failure"
Sep  4 01:44:14.865: INFO: Pod "pod-0787529b-afe4-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52686ms
Sep  4 01:44:16.870: INFO: Pod "pod-0787529b-afe4-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00975028s
[1mSTEP[0m: Saw pod success
Sep  4 01:44:16.870: INFO: Pod "pod-0787529b-afe4-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:44:16.875: INFO: Trying to get logs from node node3 pod pod-0787529b-afe4-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:44:16.897: INFO: Waiting for pod pod-0787529b-afe4-11e8-8336-00073e906c7f to disappear
Sep  4 01:44:16.902: INFO: Pod pod-0787529b-afe4-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:44:16.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-lb9cq" for this suite.
Sep  4 01:44:22.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:44:23.030: INFO: namespace: e2e-tests-emptydir-lb9cq, resource: bindings, ignored listing per whitelist
Sep  4 01:44:23.052: INFO: namespace e2e-tests-emptydir-lb9cq deletion completed in 6.14566994s

[32mâ€¢ [SLOW TEST:8.367 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run pod[0m 
  [1mshould create a pod from an image when restart is Never  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:44:23.053: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run pod
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
[It] should create a pod from an image when restart is Never  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: running the image k8s.gcr.io/nginx-slim-arm64:0.26
Sep  4 01:44:23.210: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-arm64:0.26 --namespace=e2e-tests-kubectl-wv59t'
Sep  4 01:44:23.560: INFO: stderr: ""
Sep  4 01:44:23.560: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1449
Sep  4 01:44:23.565: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-wv59t'
Sep  4 01:44:26.274: INFO: stderr: ""
Sep  4 01:44:26.274: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:44:26.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-wv59t" for this suite.
Sep  4 01:44:32.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:44:32.403: INFO: namespace: e2e-tests-kubectl-wv59t, resource: bindings, ignored listing per whitelist
Sep  4 01:44:32.428: INFO: namespace e2e-tests-kubectl-wv59t deletion completed in 6.14760772s

[32mâ€¢ [SLOW TEST:9.375 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run pod
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create a pod from an image when restart is Never  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould run and stop simple daemon [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:44:32.428: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop simple daemon [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating simple DaemonSet "daemon-set"
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Sep  4 01:44:32.621: INFO: Number of nodes with available pods: 0
Sep  4 01:44:32.621: INFO: Node node3 is running more than one daemon pod
Sep  4 01:44:33.632: INFO: Number of nodes with available pods: 0
Sep  4 01:44:33.632: INFO: Node node3 is running more than one daemon pod
Sep  4 01:44:34.646: INFO: Number of nodes with available pods: 1
Sep  4 01:44:34.646: INFO: Number of running nodes: 1, number of available pods: 1
[1mSTEP[0m: Stop a daemon pod, check that the daemon pod is revived.
Sep  4 01:44:34.670: INFO: Number of nodes with available pods: 0
Sep  4 01:44:34.671: INFO: Node node3 is running more than one daemon pod
Sep  4 01:44:35.681: INFO: Number of nodes with available pods: 0
Sep  4 01:44:35.681: INFO: Node node3 is running more than one daemon pod
Sep  4 01:44:36.681: INFO: Number of nodes with available pods: 0
Sep  4 01:44:36.681: INFO: Node node3 is running more than one daemon pod
Sep  4 01:44:37.681: INFO: Number of nodes with available pods: 0
Sep  4 01:44:37.681: INFO: Node node3 is running more than one daemon pod
Sep  4 01:44:38.682: INFO: Number of nodes with available pods: 1
Sep  4 01:44:38.682: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-6gbh2, will wait for the garbage collector to delete the pods
Sep  4 01:44:38.749: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.42628ms
Sep  4 01:44:38.850: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.35528ms
Sep  4 01:44:41.755: INFO: Number of nodes with available pods: 0
Sep  4 01:44:41.755: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 01:44:41.760: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6gbh2/daemonsets","resourceVersion":"168383"},"items":null}

Sep  4 01:44:41.765: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6gbh2/pods","resourceVersion":"168383"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:44:41.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-6gbh2" for this suite.
Sep  4 01:44:47.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:44:47.874: INFO: namespace: e2e-tests-daemonsets-6gbh2, resource: bindings, ignored listing per whitelist
Sep  4 01:44:47.935: INFO: namespace e2e-tests-daemonsets-6gbh2 deletion completed in 6.15114558s

[32mâ€¢ [SLOW TEST:15.507 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should run and stop simple daemon [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould allow opting out of API token automount  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:44:47.935: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: getting the auto-created API token
Sep  4 01:44:48.626: INFO: created pod pod-service-account-defaultsa
Sep  4 01:44:48.626: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  4 01:44:48.632: INFO: created pod pod-service-account-mountsa
Sep  4 01:44:48.632: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  4 01:44:48.638: INFO: created pod pod-service-account-nomountsa
Sep  4 01:44:48.639: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  4 01:44:48.646: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  4 01:44:48.646: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  4 01:44:48.657: INFO: created pod pod-service-account-mountsa-mountspec
Sep  4 01:44:48.657: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  4 01:44:48.664: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  4 01:44:48.664: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  4 01:44:48.672: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  4 01:44:48.672: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  4 01:44:48.680: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  4 01:44:48.680: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  4 01:44:48.689: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  4 01:44:48.689: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:44:48.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svcaccounts-t8fb8" for this suite.
Sep  4 01:45:10.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:45:10.762: INFO: namespace: e2e-tests-svcaccounts-t8fb8, resource: bindings, ignored listing per whitelist
Sep  4 01:45:10.855: INFO: namespace e2e-tests-svcaccounts-t8fb8 deletion completed in 22.15953484s

[32mâ€¢ [SLOW TEST:22.920 seconds][0m
[sig-auth] ServiceAccounts
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22[0m
  should allow opting out of API token automount  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:45:10.855: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name secret-test-29021055-afe4-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 01:45:11.033: INFO: Waiting up to 5m0s for pod "pod-secrets-2902d459-afe4-11e8-8336-00073e906c7f" in namespace "e2e-tests-secrets-dzd5s" to be "success or failure"
Sep  4 01:45:11.038: INFO: Pod "pod-secrets-2902d459-afe4-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.4006ms
Sep  4 01:45:13.043: INFO: Pod "pod-secrets-2902d459-afe4-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00977512s
[1mSTEP[0m: Saw pod success
Sep  4 01:45:13.043: INFO: Pod "pod-secrets-2902d459-afe4-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:45:13.048: INFO: Trying to get logs from node node3 pod pod-secrets-2902d459-afe4-11e8-8336-00073e906c7f container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:45:13.077: INFO: Waiting for pod pod-secrets-2902d459-afe4-11e8-8336-00073e906c7f to disappear
Sep  4 01:45:13.081: INFO: Pod pod-secrets-2902d459-afe4-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:45:13.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-dzd5s" for this suite.
Sep  4 01:45:19.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:45:19.129: INFO: namespace: e2e-tests-secrets-dzd5s, resource: bindings, ignored listing per whitelist
Sep  4 01:45:19.235: INFO: namespace e2e-tests-secrets-dzd5s deletion completed in 6.14919768s

[32mâ€¢ [SLOW TEST:8.380 seconds][0m
[sig-storage] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:45:19.236: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 01:45:19.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2dffd595-afe4-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-qskf9" to be "success or failure"
Sep  4 01:45:19.409: INFO: Pod "downwardapi-volume-2dffd595-afe4-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.35448ms
Sep  4 01:45:21.414: INFO: Pod "downwardapi-volume-2dffd595-afe4-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01074696s
[1mSTEP[0m: Saw pod success
Sep  4 01:45:21.414: INFO: Pod "downwardapi-volume-2dffd595-afe4-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:45:21.418: INFO: Trying to get logs from node node3 pod downwardapi-volume-2dffd595-afe4-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:45:21.442: INFO: Waiting for pod downwardapi-volume-2dffd595-afe4-11e8-8336-00073e906c7f to disappear
Sep  4 01:45:21.446: INFO: Pod downwardapi-volume-2dffd595-afe4-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:45:21.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-qskf9" for this suite.
Sep  4 01:45:27.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:45:27.539: INFO: namespace: e2e-tests-downward-api-qskf9, resource: bindings, ignored listing per whitelist
Sep  4 01:45:27.604: INFO: namespace e2e-tests-downward-api-qskf9 deletion completed in 6.15327092s

[32mâ€¢ [SLOW TEST:8.369 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould get a host IP [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:45:27.605: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating pod
Sep  4 01:45:29.800: INFO: Pod pod-hostip-32fe3ffe-afe4-11e8-8336-00073e906c7f has hostIP: 192.168.2.117
[AfterEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:45:29.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-w9k97" for this suite.
Sep  4 01:45:51.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:45:51.929: INFO: namespace: e2e-tests-pods-w9k97, resource: bindings, ignored listing per whitelist
Sep  4 01:45:51.954: INFO: namespace e2e-tests-pods-w9k97 deletion completed in 22.14945522s

[32mâ€¢ [SLOW TEST:24.350 seconds][0m
[k8s.io] Pods
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should get a host IP [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not be blocked by dependency circle [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:45:51.955: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 01:45:52.151: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4183f1f1-afe4-11e8-97fd-00073e906c7f", Controller:(*bool)(0x44220031b2), BlockOwnerDeletion:(*bool)(0x44220031b3)}}
Sep  4 01:45:52.158: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"41821564-afe4-11e8-97fd-00073e906c7f", Controller:(*bool)(0x442209e5aa), BlockOwnerDeletion:(*bool)(0x442209e5ab)}}
Sep  4 01:45:52.164: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4182f537-afe4-11e8-97fd-00073e906c7f", Controller:(*bool)(0x44220033b2), BlockOwnerDeletion:(*bool)(0x44220033b3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:45:57.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-xjx6d" for this suite.
Sep  4 01:46:03.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:46:03.319: INFO: namespace: e2e-tests-gc-xjx6d, resource: bindings, ignored listing per whitelist
Sep  4 01:46:03.331: INFO: namespace e2e-tests-gc-xjx6d deletion completed in 6.14853488s

[32mâ€¢ [SLOW TEST:11.376 seconds][0m
[sig-api-machinery] Garbage collector
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should not be blocked by dependency circle [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Proxy server[0m 
  [1mshould support --unix-socket=/path  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:46:03.331: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Starting the proxy
Sep  4 01:46:03.513: INFO: Asynchronously running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf proxy --unix-socket=/tmp/kubectl-proxy-unix938928690/test'
[1mSTEP[0m: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:46:03.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-k7qnx" for this suite.
Sep  4 01:46:09.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:46:09.726: INFO: namespace: e2e-tests-kubectl-k7qnx, resource: bindings, ignored listing per whitelist
Sep  4 01:46:09.844: INFO: namespace e2e-tests-kubectl-k7qnx deletion completed in 6.14929488s

[32mâ€¢ [SLOW TEST:6.513 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Proxy server
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should support --unix-socket=/path  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve multiport endpoints from pods  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:46:09.844: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating service multi-endpoint-test in namespace e2e-tests-services-762xp
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-762xp to expose endpoints map[]
Sep  4 01:46:10.022: INFO: Get endpoints failed (4.41274ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep  4 01:46:11.027: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-762xp exposes endpoints map[] (1.00890594s elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace e2e-tests-services-762xp
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-762xp to expose endpoints map[pod1:[100]]
Sep  4 01:46:13.061: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-762xp exposes endpoints map[pod1:[100]] (2.02616458s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace e2e-tests-services-762xp
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-762xp to expose endpoints map[pod1:[100] pod2:[101]]
Sep  4 01:46:15.106: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-762xp exposes endpoints map[pod2:[101] pod1:[100]] (2.03861506s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace e2e-tests-services-762xp
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-762xp to expose endpoints map[pod2:[101]]
Sep  4 01:46:16.131: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-762xp exposes endpoints map[pod2:[101]] (1.01949176s elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace e2e-tests-services-762xp
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-762xp to expose endpoints map[]
Sep  4 01:46:17.146: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-762xp exposes endpoints map[] (1.00873164s elapsed)
[AfterEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:46:17.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-762xp" for this suite.
Sep  4 01:46:39.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:46:39.323: INFO: namespace: e2e-tests-services-762xp, resource: bindings, ignored listing per whitelist
Sep  4 01:46:39.325: INFO: namespace e2e-tests-services-762xp deletion completed in 22.14944894s
[AfterEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

[32mâ€¢ [SLOW TEST:29.481 seconds][0m
[sig-network] Services
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should serve multiport endpoints from pods  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe an object deletion if it stops meeting the requirements of the selector [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Watchers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:46:39.326: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating a watch on configmaps with a certain label
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: changing the label value of the configmap
[1mSTEP[0m: Expecting to observe a delete notification for the watched object
Sep  4 01:46:39.523: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b2nzf,SelfLink:/api/v1/namespaces/e2e-tests-watch-b2nzf/configmaps/e2e-watch-test-label-changed,UID:5dbeff66-afe4-11e8-97fd-00073e906c7f,ResourceVersion:168811,Generation:0,CreationTimestamp:2018-09-04 01:46:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 01:46:39.523: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b2nzf,SelfLink:/api/v1/namespaces/e2e-tests-watch-b2nzf/configmaps/e2e-watch-test-label-changed,UID:5dbeff66-afe4-11e8-97fd-00073e906c7f,ResourceVersion:168812,Generation:0,CreationTimestamp:2018-09-04 01:46:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  4 01:46:39.523: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b2nzf,SelfLink:/api/v1/namespaces/e2e-tests-watch-b2nzf/configmaps/e2e-watch-test-label-changed,UID:5dbeff66-afe4-11e8-97fd-00073e906c7f,ResourceVersion:168813,Generation:0,CreationTimestamp:2018-09-04 01:46:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: Expecting not to observe a notification because the object no longer meets the selector's requirements
[1mSTEP[0m: changing the label value of the configmap back
[1mSTEP[0m: modifying the configmap a third time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe an add notification for the watched object when the label value was restored
Sep  4 01:46:49.560: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b2nzf,SelfLink:/api/v1/namespaces/e2e-tests-watch-b2nzf/configmaps/e2e-watch-test-label-changed,UID:5dbeff66-afe4-11e8-97fd-00073e906c7f,ResourceVersion:168827,Generation:0,CreationTimestamp:2018-09-04 01:46:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 01:46:49.560: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b2nzf,SelfLink:/api/v1/namespaces/e2e-tests-watch-b2nzf/configmaps/e2e-watch-test-label-changed,UID:5dbeff66-afe4-11e8-97fd-00073e906c7f,ResourceVersion:168828,Generation:0,CreationTimestamp:2018-09-04 01:46:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  4 01:46:49.560: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b2nzf,SelfLink:/api/v1/namespaces/e2e-tests-watch-b2nzf/configmaps/e2e-watch-test-label-changed,UID:5dbeff66-afe4-11e8-97fd-00073e906c7f,ResourceVersion:168829,Generation:0,CreationTimestamp:2018-09-04 01:46:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:46:49.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-b2nzf" for this suite.
Sep  4 01:46:55.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:46:55.647: INFO: namespace: e2e-tests-watch-b2nzf, resource: bindings, ignored listing per whitelist
Sep  4 01:46:55.713: INFO: namespace e2e-tests-watch-b2nzf deletion completed in 6.14713112s

[32mâ€¢ [SLOW TEST:16.387 seconds][0m
[sig-api-machinery] Watchers
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0644,tmpfs) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:46:55.713: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0644 on tmpfs
Sep  4 01:46:55.892: INFO: Waiting up to 5m0s for pod "pod-6782e368-afe4-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-8kcjp" to be "success or failure"
Sep  4 01:46:55.899: INFO: Pod "pod-6782e368-afe4-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.94462ms
Sep  4 01:46:57.903: INFO: Pod "pod-6782e368-afe4-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0118678s
[1mSTEP[0m: Saw pod success
Sep  4 01:46:57.904: INFO: Pod "pod-6782e368-afe4-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:46:57.908: INFO: Trying to get logs from node node3 pod pod-6782e368-afe4-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:46:57.931: INFO: Waiting for pod pod-6782e368-afe4-11e8-8336-00073e906c7f to disappear
Sep  4 01:46:57.935: INFO: Pod pod-6782e368-afe4-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:46:57.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-8kcjp" for this suite.
Sep  4 01:47:03.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:47:04.010: INFO: namespace: e2e-tests-emptydir-8kcjp, resource: bindings, ignored listing per whitelist
Sep  4 01:47:04.090: INFO: namespace e2e-tests-emptydir-8kcjp deletion completed in 6.15016788s

[32mâ€¢ [SLOW TEST:8.377 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command and arguments [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Docker Containers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:47:04.091: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test override all
Sep  4 01:47:04.257: INFO: Waiting up to 5m0s for pod "client-containers-6c7f33c8-afe4-11e8-8336-00073e906c7f" in namespace "e2e-tests-containers-9bjdw" to be "success or failure"
Sep  4 01:47:04.262: INFO: Pod "client-containers-6c7f33c8-afe4-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.84114ms
Sep  4 01:47:06.267: INFO: Pod "client-containers-6c7f33c8-afe4-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00996374s
[1mSTEP[0m: Saw pod success
Sep  4 01:47:06.267: INFO: Pod "client-containers-6c7f33c8-afe4-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:47:06.271: INFO: Trying to get logs from node node3 pod client-containers-6c7f33c8-afe4-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:47:06.294: INFO: Waiting for pod client-containers-6c7f33c8-afe4-11e8-8336-00073e906c7f to disappear
Sep  4 01:47:06.298: INFO: Pod client-containers-6c7f33c8-afe4-11e8-8336-00073e906c7f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:47:06.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-9bjdw" for this suite.
Sep  4 01:47:12.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:47:12.421: INFO: namespace: e2e-tests-containers-9bjdw, resource: bindings, ignored listing per whitelist
Sep  4 01:47:12.459: INFO: namespace e2e-tests-containers-9bjdw deletion completed in 6.15570256s

[32mâ€¢ [SLOW TEST:8.369 seconds][0m
[k8s.io] Docker Containers
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume as non-root [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:47:12.460: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-717cf15f-afe4-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 01:47:12.635: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-717db810-afe4-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-f4zms" to be "success or failure"
Sep  4 01:47:12.639: INFO: Pod "pod-projected-configmaps-717db810-afe4-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.5996ms
Sep  4 01:47:14.651: INFO: Pod "pod-projected-configmaps-717db810-afe4-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01586502s
[1mSTEP[0m: Saw pod success
Sep  4 01:47:14.651: INFO: Pod "pod-projected-configmaps-717db810-afe4-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:47:14.655: INFO: Trying to get logs from node node3 pod pod-projected-configmaps-717db810-afe4-11e8-8336-00073e906c7f container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:47:14.699: INFO: Waiting for pod pod-projected-configmaps-717db810-afe4-11e8-8336-00073e906c7f to disappear
Sep  4 01:47:14.704: INFO: Pod pod-projected-configmaps-717db810-afe4-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:47:14.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-f4zms" for this suite.
Sep  4 01:47:20.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:47:20.808: INFO: namespace: e2e-tests-projected-f4zms, resource: bindings, ignored listing per whitelist
Sep  4 01:47:20.884: INFO: namespace e2e-tests-projected-f4zms deletion completed in 6.17438906s

[32mâ€¢ [SLOW TEST:8.424 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould have monotonically increasing restart count [Slow][NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:47:20.884: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-dtmtn
Sep  4 01:47:23.062: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-dtmtn
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Sep  4 01:47:23.067: INFO: Initial restart count of pod liveness-http is 0
Sep  4 01:47:37.104: INFO: Restart count of pod e2e-tests-container-probe-dtmtn/liveness-http is now 1 (14.0365652s elapsed)
Sep  4 01:47:57.153: INFO: Restart count of pod e2e-tests-container-probe-dtmtn/liveness-http is now 2 (34.08577578s elapsed)
Sep  4 01:48:17.202: INFO: Restart count of pod e2e-tests-container-probe-dtmtn/liveness-http is now 3 (54.13473742s elapsed)
Sep  4 01:48:37.250: INFO: Restart count of pod e2e-tests-container-probe-dtmtn/liveness-http is now 4 (1m14.18286062s elapsed)
Sep  4 01:49:47.420: INFO: Restart count of pod e2e-tests-container-probe-dtmtn/liveness-http is now 5 (2m24.35280402s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:49:47.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-dtmtn" for this suite.
Sep  4 01:49:53.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:49:53.559: INFO: namespace: e2e-tests-container-probe-dtmtn, resource: bindings, ignored listing per whitelist
Sep  4 01:49:53.591: INFO: namespace e2e-tests-container-probe-dtmtn deletion completed in 6.15524902s

[32mâ€¢ [SLOW TEST:152.707 seconds][0m
[k8s.io] Probing container
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run rc[0m 
  [1mshould create an rc from an image  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:49:53.591: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run rc
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
[It] should create an rc from an image  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: running the image k8s.gcr.io/nginx-slim-arm64:0.26
Sep  4 01:49:53.756: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-arm64:0.26 --generator=run/v1 --namespace=e2e-tests-kubectl-ph8ts'
Sep  4 01:49:54.113: INFO: stderr: ""
Sep  4 01:49:54.113: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
[1mSTEP[0m: verifying the rc e2e-test-nginx-rc was created
[1mSTEP[0m: verifying the pod controlled by rc e2e-test-nginx-rc was created
[1mSTEP[0m: confirm that you can get logs from an rc
Sep  4 01:49:54.124: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-z2t92]
Sep  4 01:49:54.124: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-z2t92" in namespace "e2e-tests-kubectl-ph8ts" to be "running and ready"
Sep  4 01:49:54.129: INFO: Pod "e2e-test-nginx-rc-z2t92": Phase="Pending", Reason="", readiness=false. Elapsed: 4.9927ms
Sep  4 01:49:56.134: INFO: Pod "e2e-test-nginx-rc-z2t92": Phase="Running", Reason="", readiness=true. Elapsed: 2.01010226s
Sep  4 01:49:56.135: INFO: Pod "e2e-test-nginx-rc-z2t92" satisfied condition "running and ready"
Sep  4 01:49:56.135: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-z2t92]
Sep  4 01:49:56.135: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ph8ts'
Sep  4 01:49:56.511: INFO: stderr: ""
Sep  4 01:49:56.511: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1221
Sep  4 01:49:56.511: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ph8ts'
Sep  4 01:49:56.844: INFO: stderr: ""
Sep  4 01:49:56.844: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:49:56.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-ph8ts" for this suite.
Sep  4 01:50:02.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:50:02.929: INFO: namespace: e2e-tests-kubectl-ph8ts, resource: bindings, ignored listing per whitelist
Sep  4 01:50:02.998: INFO: namespace e2e-tests-kubectl-ph8ts deletion completed in 6.14782016s

[32mâ€¢ [SLOW TEST:9.407 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run rc
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create an rc from an image  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:50:02.998: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating pod liveness-exec in namespace e2e-tests-container-probe-7hvwk
Sep  4 01:50:17.177: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-7hvwk
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Sep  4 01:50:17.181: INFO: Initial restart count of pod liveness-exec is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:54:17.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-7hvwk" for this suite.
Sep  4 01:54:23.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:54:23.864: INFO: namespace: e2e-tests-container-probe-7hvwk, resource: bindings, ignored listing per whitelist
Sep  4 01:54:23.933: INFO: namespace e2e-tests-container-probe-7hvwk deletion completed in 6.14915704s

[32mâ€¢ [SLOW TEST:260.935 seconds][0m
[k8s.io] Probing container
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for the cluster  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] DNS
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:54:23.934: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tv4x8.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tv4x8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tv4x8.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tv4x8.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tv4x8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tv4x8.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
Sep  4 01:54:36.230: INFO: DNS probes using dns-test-72ab4e39-afe5-11e8-8336-00073e906c7f succeeded

[1mSTEP[0m: deleting the pod
[AfterEach] [sig-network] DNS
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:54:36.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-dns-tv4x8" for this suite.
Sep  4 01:54:42.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:54:42.295: INFO: namespace: e2e-tests-dns-tv4x8, resource: bindings, ignored listing per whitelist
Sep  4 01:54:42.395: INFO: namespace e2e-tests-dns-tv4x8 deletion completed in 6.14767224s

[32mâ€¢ [SLOW TEST:18.461 seconds][0m
[sig-network] DNS
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide DNS for the cluster  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:54:42.396: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
Sep  4 01:54:45.096: INFO: Successfully updated pod "pod-update-activedeadlineseconds-7dac2127-afe5-11e8-8336-00073e906c7f"
Sep  4 01:54:45.097: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-7dac2127-afe5-11e8-8336-00073e906c7f" in namespace "e2e-tests-pods-r9llp" to be "terminated due to deadline exceeded"
Sep  4 01:54:45.103: INFO: Pod "pod-update-activedeadlineseconds-7dac2127-afe5-11e8-8336-00073e906c7f": Phase="Running", Reason="", readiness=true. Elapsed: 6.33382ms
Sep  4 01:54:47.108: INFO: Pod "pod-update-activedeadlineseconds-7dac2127-afe5-11e8-8336-00073e906c7f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01118084s
Sep  4 01:54:49.113: INFO: Pod "pod-update-activedeadlineseconds-7dac2127-afe5-11e8-8336-00073e906c7f": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.01595738s
Sep  4 01:54:49.113: INFO: Pod "pod-update-activedeadlineseconds-7dac2127-afe5-11e8-8336-00073e906c7f" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:54:49.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-r9llp" for this suite.
Sep  4 01:54:55.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:54:55.149: INFO: namespace: e2e-tests-pods-r9llp, resource: bindings, ignored listing per whitelist
Sep  4 01:54:55.264: INFO: namespace e2e-tests-pods-r9llp deletion completed in 6.14646474s

[32mâ€¢ [SLOW TEST:12.869 seconds][0m
[k8s.io] Pods
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicaSet[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] ReplicaSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:54:55.265: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 01:54:55.432: INFO: Creating ReplicaSet my-hostname-basic-85584f12-afe5-11e8-8336-00073e906c7f
Sep  4 01:54:55.444: INFO: Pod name my-hostname-basic-85584f12-afe5-11e8-8336-00073e906c7f: Found 0 pods out of 1
Sep  4 01:55:00.450: INFO: Pod name my-hostname-basic-85584f12-afe5-11e8-8336-00073e906c7f: Found 1 pods out of 1
Sep  4 01:55:00.450: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-85584f12-afe5-11e8-8336-00073e906c7f" is running
Sep  4 01:55:00.454: INFO: Pod "my-hostname-basic-85584f12-afe5-11e8-8336-00073e906c7f-lfjgf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-09-04 01:54:55 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-09-04 01:54:56 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-09-04 01:54:55 +0000 UTC Reason: Message:}])
Sep  4 01:55:00.454: INFO: Trying to dial the pod
Sep  4 01:55:05.470: INFO: Controller my-hostname-basic-85584f12-afe5-11e8-8336-00073e906c7f: Got expected result from replica 1 [my-hostname-basic-85584f12-afe5-11e8-8336-00073e906c7f-lfjgf]: "my-hostname-basic-85584f12-afe5-11e8-8336-00073e906c7f-lfjgf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:55:05.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replicaset-fv8kx" for this suite.
Sep  4 01:55:11.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:55:11.578: INFO: namespace: e2e-tests-replicaset-fv8kx, resource: bindings, ignored listing per whitelist
Sep  4 01:55:11.631: INFO: namespace e2e-tests-replicaset-fv8kx deletion completed in 6.15509658s

[32mâ€¢ [SLOW TEST:16.366 seconds][0m
[sig-apps] ReplicaSet
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should serve a basic image on each replica with a public image  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] PreStop[0m 
  [1mshould call prestop when killing a pod  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] [sig-node] PreStop
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:55:11.631: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating server pod server in namespace e2e-tests-prestop-jl47z
[1mSTEP[0m: Waiting for pods to come up.
[1mSTEP[0m: Creating tester pod tester in namespace e2e-tests-prestop-jl47z
[1mSTEP[0m: Deleting pre-stop pod
Sep  4 01:55:30.856: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
[1mSTEP[0m: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:55:30.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-prestop-jl47z" for this suite.
Sep  4 01:56:08.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:56:09.000: INFO: namespace: e2e-tests-prestop-jl47z, resource: bindings, ignored listing per whitelist
Sep  4 01:56:09.015: INFO: namespace e2e-tests-prestop-jl47z deletion completed in 38.14752976s

[32mâ€¢ [SLOW TEST:57.384 seconds][0m
[k8s.io] [sig-node] PreStop
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should call prestop when killing a pod  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run --rm job[0m 
  [1mshould create a job from an image, then delete the job  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:56:09.016: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create a job from an image, then delete the job  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: executing a command with run --rm and attach with stdin
Sep  4 01:56:09.180: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf --namespace=e2e-tests-kubectl-sbn9k run e2e-test-rm-busybox-job --image=busybox --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  4 01:56:23.975: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
Sep  4 01:56:23.976: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
[1mSTEP[0m: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:56:25.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-sbn9k" for this suite.
Sep  4 01:56:32.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:56:32.078: INFO: namespace: e2e-tests-kubectl-sbn9k, resource: bindings, ignored listing per whitelist
Sep  4 01:56:32.138: INFO: namespace e2e-tests-kubectl-sbn9k deletion completed in 6.14945364s

[32mâ€¢ [SLOW TEST:23.123 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run --rm job
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create a job from an image, then delete the job  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl describe[0m 
  [1mshould check if kubectl describe prints relevant information for rc and pods  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:56:32.139: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 01:56:32.304: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf version --client'
Sep  4 01:56:32.484: INFO: stderr: ""
Sep  4 01:56:32.484: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.2\", GitCommit:\"bb9ffb1654d4a729bb4cec18ff088eacc153c239\", GitTreeState:\"clean\", BuildDate:\"2018-08-31T09:39:29Z\", GoVersion:\"go1.10.2\", Compiler:\"gc\", Platform:\"linux/arm64\"}\n"
Sep  4 01:56:32.488: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-88tll'
Sep  4 01:56:32.966: INFO: stderr: ""
Sep  4 01:56:32.967: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep  4 01:56:32.967: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-88tll'
Sep  4 01:56:33.465: INFO: stderr: ""
Sep  4 01:56:33.465: INFO: stdout: "service/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
Sep  4 01:56:34.471: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 01:56:34.471: INFO: Found 0 / 1
Sep  4 01:56:35.471: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 01:56:35.471: INFO: Found 1 / 1
Sep  4 01:56:35.471: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 01:56:35.476: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 01:56:35.476: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 01:56:35.476: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe pod redis-master-mpfz7 --namespace=e2e-tests-kubectl-88tll'
Sep  4 01:56:35.828: INFO: stderr: ""
Sep  4 01:56:35.828: INFO: stdout: "Name:               redis-master-mpfz7\nNamespace:          e2e-tests-kubectl-88tll\nPriority:           0\nPriorityClassName:  <none>\nNode:               node3/192.168.2.117\nStart Time:         Tue, 04 Sep 2018 01:56:32 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.32.0.8\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   hyper://4079feac385ba852fedf6676bb170457c9d14d594f3b4357fe9596d04d938b1e\n    Image:          gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis-arm64@sha256:fdb1bec2aee1dd8bf5062359ece72330f0b1513d6c4620dbd9cab9c2c1367958\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 04 Sep 2018 01:56:34 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-txtgf (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-txtgf:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-txtgf\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned e2e-tests-kubectl-88tll/redis-master-mpfz7 to node3\n  Normal  Pulled     2s    kubelet, node3     Container image \"gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0\" already present on machine\n  Normal  Created    2s    kubelet, node3     Created container\n  Normal  Started    1s    kubelet, node3     Started container\n"
Sep  4 01:56:35.829: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe rc redis-master --namespace=e2e-tests-kubectl-88tll'
Sep  4 01:56:36.203: INFO: stderr: ""
Sep  4 01:56:36.203: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-88tll\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-mpfz7\n"
Sep  4 01:56:36.203: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe service redis-master --namespace=e2e-tests-kubectl-88tll'
Sep  4 01:56:36.549: INFO: stderr: ""
Sep  4 01:56:36.549: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-88tll\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.107.220.8\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.32.0.8:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep  4 01:56:36.555: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe node node3'
Sep  4 01:56:36.928: INFO: stderr: ""
Sep  4 01:56:36.928: INFO: stdout: "Name:               node3\nRoles:              master\nLabels:             beta.kubernetes.io/arch=arm64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=node3\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket=/var/run/frakti.sock\n                    node.alpha.kubernetes.io/ttl=0\n                    volumes.kubernetes.io/controller-managed-attach-detach=true\nCreationTimestamp:  Sat, 01 Sep 2018 03:55:18 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 03 Sep 2018 03:46:46 +0000   Mon, 03 Sep 2018 03:46:46 +0000   WeaveIsUp                    Weave pod has set this\n  OutOfDisk            False   Tue, 04 Sep 2018 01:56:32 +0000   Sat, 01 Sep 2018 03:55:11 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Tue, 04 Sep 2018 01:56:32 +0000   Sat, 01 Sep 2018 03:55:11 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 04 Sep 2018 01:56:32 +0000   Sat, 01 Sep 2018 03:55:11 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 04 Sep 2018 01:56:32 +0000   Sat, 01 Sep 2018 03:55:11 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 04 Sep 2018 01:56:32 +0000   Tue, 04 Sep 2018 01:30:47 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.2.117\n  Hostname:    node3\nCapacity:\n cpu:                16\n ephemeral-storage:  80603936Ki\n hugepages-2Mi:      0\n memory:             65952304Ki\n pods:               110\nAllocatable:\n cpu:                16\n ephemeral-storage:  74284587295\n hugepages-2Mi:      0\n memory:             65849904Ki\n pods:               110\nSystem Info:\n Machine ID:                 373be5c264ac4b78a49077a4b4ded99c\n System UUID:                373be5c264ac4b78a49077a4b4ded99c\n Boot ID:                    c3229fda-d628-476e-9988-7af0bb46b762\n Kernel Version:             4.4.58-20171215.kylin.server.YUN+-generic\n OS Image:                   Kylin 4.0.2\n Operating System:           linux\n Architecture:               arm64\n Container Runtime Version:  hyper://0.8.0\n Kubelet Version:            v1.11.2\n Kube-Proxy Version:         v1.11.2\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                             CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                             ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-88tll    redis-master-mpfz7               0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                coredns-78fcdf6894-f55jj         100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)\n  kube-system                coredns-78fcdf6894-vlxkz         100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)\n  kube-system                etcd-node3                       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-node3             250m (1%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-node3    200m (1%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-d6xgq                 0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-node3             100m (0%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                weave-net-qrwm8                  20m (0%)      0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       770m (4%)   0 (0%)\n  memory    140Mi (0%)  340Mi (0%)\nEvents:\n  Type    Reason                   Age   From            Message\n  ----    ------                   ----  ----            -------\n  Normal  Starting                 25m   kubelet, node3  Starting kubelet.\n  Normal  NodeHasSufficientDisk    25m   kubelet, node3  Node node3 status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  25m   kubelet, node3  Node node3 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    25m   kubelet, node3  Node node3 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     25m   kubelet, node3  Node node3 status is now: NodeHasSufficientPID\n  Normal  NodeNotReady             25m   kubelet, node3  Node node3 status is now: NodeNotReady\n  Normal  NodeAllocatableEnforced  25m   kubelet, node3  Updated Node Allocatable limit across pods\n  Normal  NodeReady                25m   kubelet, node3  Node node3 status is now: NodeReady\n"
Sep  4 01:56:36.929: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe namespace e2e-tests-kubectl-88tll'
Sep  4 01:56:37.271: INFO: stderr: ""
Sep  4 01:56:37.271: INFO: stdout: "Name:         e2e-tests-kubectl-88tll\nLabels:       e2e-framework=kubectl\n              e2e-run=3cd852a6-afe3-11e8-8336-00073e906c7f\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:56:37.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-88tll" for this suite.
Sep  4 01:56:57.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:56:57.327: INFO: namespace: e2e-tests-kubectl-88tll, resource: bindings, ignored listing per whitelist
Sep  4 01:56:57.429: INFO: namespace e2e-tests-kubectl-88tll deletion completed in 20.15187136s

[32mâ€¢ [SLOW TEST:25.290 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl describe
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mScaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:56:57.429: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-cxd7b
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Initializing watcher for selector baz=blah,foo=bar
[1mSTEP[0m: Creating stateful set ss in namespace e2e-tests-statefulset-cxd7b
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-cxd7b
Sep  4 01:56:57.614: INFO: Found 0 stateful pods, waiting for 1
Sep  4 01:57:07.620: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  4 01:57:07.625: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-cxd7b ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 01:57:08.289: INFO: stderr: ""
Sep  4 01:57:08.290: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 01:57:08.290: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 01:57:08.295: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  4 01:57:18.301: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 01:57:18.301: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 01:57:18.321: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999876s
Sep  4 01:57:19.326: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99471992s
Sep  4 01:57:20.331: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.9895484s
Sep  4 01:57:21.337: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98414742s
Sep  4 01:57:22.343: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.9784336s
Sep  4 01:57:23.348: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97287548s
Sep  4 01:57:24.354: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.96732406s
Sep  4 01:57:25.359: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.96207944s
Sep  4 01:57:26.364: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.95657964s
Sep  4 01:57:27.370: INFO: Verifying statefulset ss doesn't scale past 1 for another 951.16248ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-cxd7b
Sep  4 01:57:28.375: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-cxd7b ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 01:57:29.061: INFO: stderr: ""
Sep  4 01:57:29.061: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 01:57:29.061: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 01:57:29.067: INFO: Found 1 stateful pods, waiting for 3
Sep  4 01:57:39.073: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 01:57:39.073: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 01:57:39.073: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Verifying that stateful set ss was scaled up in order
[1mSTEP[0m: Scale down will halt with unhealthy stateful pod
Sep  4 01:57:39.083: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-cxd7b ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 01:57:39.877: INFO: stderr: ""
Sep  4 01:57:39.877: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 01:57:39.877: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 01:57:39.878: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-cxd7b ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 01:57:40.659: INFO: stderr: ""
Sep  4 01:57:40.659: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 01:57:40.660: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 01:57:40.660: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-cxd7b ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 01:57:41.457: INFO: stderr: ""
Sep  4 01:57:41.457: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 01:57:41.457: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 01:57:41.457: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 01:57:41.462: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  4 01:57:51.473: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 01:57:51.473: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 01:57:51.473: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 01:57:51.489: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999988s
Sep  4 01:57:52.495: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99353192s
Sep  4 01:57:53.501: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98761548s
Sep  4 01:57:54.507: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98187078s
Sep  4 01:57:55.513: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97601716s
Sep  4 01:57:56.518: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.96995036s
Sep  4 01:57:57.525: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96408412s
Sep  4 01:57:58.531: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95787046s
Sep  4 01:57:59.537: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95183106s
Sep  4 01:58:00.543: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.53232ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-cxd7b
Sep  4 01:58:01.549: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-cxd7b ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 01:58:02.216: INFO: stderr: ""
Sep  4 01:58:02.216: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 01:58:02.216: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 01:58:02.217: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-cxd7b ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 01:58:02.897: INFO: stderr: ""
Sep  4 01:58:02.897: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 01:58:02.897: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 01:58:02.897: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-cxd7b ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 01:58:03.588: INFO: stderr: ""
Sep  4 01:58:03.588: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 01:58:03.589: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 01:58:03.589: INFO: Scaling statefulset ss to 0
[1mSTEP[0m: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Sep  4 01:58:33.618: INFO: Deleting all statefulset in ns e2e-tests-statefulset-cxd7b
Sep  4 01:58:33.623: INFO: Scaling statefulset ss to 0
Sep  4 01:58:33.636: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 01:58:33.640: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:58:33.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-cxd7b" for this suite.
Sep  4 01:58:39.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:58:39.761: INFO: namespace: e2e-tests-statefulset-cxd7b, resource: bindings, ignored listing per whitelist
Sep  4 01:58:39.819: INFO: namespace e2e-tests-statefulset-cxd7b deletion completed in 6.15842054s

[32mâ€¢ [SLOW TEST:102.390 seconds][0m
[sig-apps] StatefulSet
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's args [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Variable Expansion
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:58:39.820: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test substitution in container's args
Sep  4 01:58:39.998: INFO: Waiting up to 5m0s for pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-var-expansion-rzxk9" to be "success or failure"
Sep  4 01:58:40.003: INFO: Pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.81294ms
Sep  4 01:58:42.008: INFO: Pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00983306s
Sep  4 01:58:44.013: INFO: Pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01492324s
Sep  4 01:58:46.018: INFO: Pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01995708s
Sep  4 01:58:48.023: INFO: Pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02502072s
Sep  4 01:58:50.028: INFO: Pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0300843s
Sep  4 01:58:52.034: INFO: Pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03619172s
[1mSTEP[0m: Saw pod success
Sep  4 01:58:52.034: INFO: Pod "var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:58:52.039: INFO: Trying to get logs from node node3 pod var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:58:52.065: INFO: Waiting for pod var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 01:58:52.070: INFO: Pod var-expansion-0b30f7ff-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:58:52.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-rzxk9" for this suite.
Sep  4 01:58:58.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:58:58.110: INFO: namespace: e2e-tests-var-expansion-rzxk9, resource: bindings, ignored listing per whitelist
Sep  4 01:58:58.229: INFO: namespace e2e-tests-var-expansion-rzxk9 deletion completed in 6.15378326s

[32mâ€¢ [SLOW TEST:18.409 seconds][0m
[k8s.io] Variable Expansion
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould mount an API token into pods  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:58:58.229: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: getting the auto-created API token
[1mSTEP[0m: Creating a pod to test consume service account token
Sep  4 01:58:58.910: INFO: Waiting up to 5m0s for pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-gkhpz" in namespace "e2e-tests-svcaccounts-t8f9m" to be "success or failure"
Sep  4 01:58:58.915: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-gkhpz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.49172ms
Sep  4 01:59:00.920: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-gkhpz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00935134s
Sep  4 01:59:02.925: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-gkhpz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01437932s
[1mSTEP[0m: Saw pod success
Sep  4 01:59:02.925: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-gkhpz" satisfied condition "success or failure"
Sep  4 01:59:02.929: INFO: Trying to get logs from node node3 pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-gkhpz container token-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:59:02.953: INFO: Waiting for pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-gkhpz to disappear
Sep  4 01:59:02.957: INFO: Pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-gkhpz no longer exists
[1mSTEP[0m: Creating a pod to test consume service account root CA
Sep  4 01:59:02.962: INFO: Waiting up to 5m0s for pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-r28s5" in namespace "e2e-tests-svcaccounts-t8f9m" to be "success or failure"
Sep  4 01:59:02.967: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-r28s5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.64016ms
Sep  4 01:59:04.973: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-r28s5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01029172s
[1mSTEP[0m: Saw pod success
Sep  4 01:59:04.973: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-r28s5" satisfied condition "success or failure"
Sep  4 01:59:04.977: INFO: Trying to get logs from node node3 pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-r28s5 container root-ca-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:59:05.003: INFO: Waiting for pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-r28s5 to disappear
Sep  4 01:59:05.008: INFO: Pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-r28s5 no longer exists
[1mSTEP[0m: Creating a pod to test consume service account namespace
Sep  4 01:59:05.013: INFO: Waiting up to 5m0s for pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-ps4kl" in namespace "e2e-tests-svcaccounts-t8f9m" to be "success or failure"
Sep  4 01:59:05.018: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-ps4kl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.9125ms
Sep  4 01:59:07.024: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-ps4kl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01019378s
[1mSTEP[0m: Saw pod success
Sep  4 01:59:07.024: INFO: Pod "pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-ps4kl" satisfied condition "success or failure"
Sep  4 01:59:07.028: INFO: Trying to get logs from node node3 pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-ps4kl container namespace-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:59:07.055: INFO: Waiting for pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-ps4kl to disappear
Sep  4 01:59:07.059: INFO: Pod pod-service-account-1676c882-afe6-11e8-8336-00073e906c7f-ps4kl no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:59:07.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svcaccounts-t8f9m" for this suite.
Sep  4 01:59:13.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:59:13.122: INFO: namespace: e2e-tests-svcaccounts-t8f9m, resource: bindings, ignored listing per whitelist
Sep  4 01:59:13.214: INFO: namespace e2e-tests-svcaccounts-t8f9m deletion completed in 6.14979s

[32mâ€¢ [SLOW TEST:14.985 seconds][0m
[sig-auth] ServiceAccounts
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22[0m
  should mount an API token into pods  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:59:13.215: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name secret-test-1f181acc-afe6-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 01:59:13.394: INFO: Waiting up to 5m0s for pod "pod-secrets-1f18d725-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-secrets-cbrx9" to be "success or failure"
Sep  4 01:59:13.399: INFO: Pod "pod-secrets-1f18d725-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.81932ms
Sep  4 01:59:15.408: INFO: Pod "pod-secrets-1f18d725-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0138607s
[1mSTEP[0m: Saw pod success
Sep  4 01:59:15.408: INFO: Pod "pod-secrets-1f18d725-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 01:59:15.412: INFO: Trying to get logs from node node3 pod pod-secrets-1f18d725-afe6-11e8-8336-00073e906c7f container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 01:59:15.435: INFO: Waiting for pod pod-secrets-1f18d725-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 01:59:15.439: INFO: Pod pod-secrets-1f18d725-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:59:15.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-cbrx9" for this suite.
Sep  4 01:59:21.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:59:21.510: INFO: namespace: e2e-tests-secrets-cbrx9, resource: bindings, ignored listing per whitelist
Sep  4 01:59:21.596: INFO: namespace e2e-tests-secrets-cbrx9 deletion completed in 6.15183494s

[32mâ€¢ [SLOW TEST:8.382 seconds][0m
[sig-storage] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to restart watching from the last resource version observed by the previous watch [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Watchers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:59:21.597: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating a watch on configmaps
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: closing the watch once it receives two notifications
Sep  4 01:59:21.770: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-prvsd,SelfLink:/api/v1/namespaces/e2e-tests-watch-prvsd/configmaps/e2e-watch-test-watch-closed,UID:24168889-afe6-11e8-97fd-00073e906c7f,ResourceVersion:170474,Generation:0,CreationTimestamp:2018-09-04 01:59:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 01:59:21.770: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-prvsd,SelfLink:/api/v1/namespaces/e2e-tests-watch-prvsd/configmaps/e2e-watch-test-watch-closed,UID:24168889-afe6-11e8-97fd-00073e906c7f,ResourceVersion:170475,Generation:0,CreationTimestamp:2018-09-04 01:59:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time, while the watch is closed
[1mSTEP[0m: creating a new watch on configmaps from the last resource version observed by the first watch
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  4 01:59:21.790: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-prvsd,SelfLink:/api/v1/namespaces/e2e-tests-watch-prvsd/configmaps/e2e-watch-test-watch-closed,UID:24168889-afe6-11e8-97fd-00073e906c7f,ResourceVersion:170476,Generation:0,CreationTimestamp:2018-09-04 01:59:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 01:59:21.790: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-prvsd,SelfLink:/api/v1/namespaces/e2e-tests-watch-prvsd/configmaps/e2e-watch-test-watch-closed,UID:24168889-afe6-11e8-97fd-00073e906c7f,ResourceVersion:170477,Generation:0,CreationTimestamp:2018-09-04 01:59:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:59:21.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-prvsd" for this suite.
Sep  4 01:59:27.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:59:27.848: INFO: namespace: e2e-tests-watch-prvsd, resource: bindings, ignored listing per whitelist
Sep  4 01:59:27.941: INFO: namespace e2e-tests-watch-prvsd deletion completed in 6.14558956s

[32mâ€¢ [SLOW TEST:6.344 seconds][0m
[sig-api-machinery] Watchers
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl replace[0m 
  [1mshould update a single-container pod's image  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:59:27.942: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl replace
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should update a single-container pod's image  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: running the image k8s.gcr.io/nginx-slim-arm64:0.26
Sep  4 01:59:28.107: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf run e2e-test-nginx-pod --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-arm64:0.26 --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w9h94'
Sep  4 01:59:28.456: INFO: stderr: ""
Sep  4 01:59:28.457: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod is running
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod was created
Sep  4 01:59:33.507: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w9h94 -o json'
Sep  4 01:59:33.830: INFO: stderr: ""
Sep  4 01:59:33.830: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-09-04T01:59:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-w9h94\",\n        \"resourceVersion\": \"170504\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-w9h94/pods/e2e-test-nginx-pod\",\n        \"uid\": \"281028d3-afe6-11e8-97fd-00073e906c7f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/nginx-slim-arm64:0.26\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-crc2b\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"node3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-crc2b\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-crc2b\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-09-04T01:59:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-09-04T01:59:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": null,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-09-04T01:59:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"hyper://e1aa8da9f658613e396176d1bf6ed55c425bd34eb8eb5441ccaa2ea4f9602535\",\n                \"image\": \"k8s.gcr.io/nginx-slim-arm64:0.26\",\n                \"imageID\": \"docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-09-04T01:59:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.2.117\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.32.0.9\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-09-04T01:59:28Z\"\n    }\n}\n"
[1mSTEP[0m: replace the image in the pod
Sep  4 01:59:33.830: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf replace -f - --namespace=e2e-tests-kubectl-w9h94'
Sep  4 01:59:34.302: INFO: stderr: ""
Sep  4 01:59:34.303: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod has the right image busybox
[AfterEach] [k8s.io] Kubectl replace
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1485
Sep  4 01:59:34.308: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w9h94'
Sep  4 01:59:47.526: INFO: stderr: ""
Sep  4 01:59:47.526: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 01:59:47.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-w9h94" for this suite.
Sep  4 01:59:53.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 01:59:53.654: INFO: namespace: e2e-tests-kubectl-w9h94, resource: bindings, ignored listing per whitelist
Sep  4 01:59:53.679: INFO: namespace e2e-tests-kubectl-w9h94 deletion completed in 6.1458198s

[32mâ€¢ [SLOW TEST:25.737 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl replace
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should update a single-container pod's image  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete pods created by rc when not orphaning [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 01:59:53.679: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for all pods to be garbage collected
[1mSTEP[0m: Gathering metrics
W0904 02:00:03.871639   10499 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 02:00:03.871: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:00:03.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-jtl5p" for this suite.
Sep  4 02:00:09.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:00:09.961: INFO: namespace: e2e-tests-gc-jtl5p, resource: bindings, ignored listing per whitelist
Sep  4 02:00:10.024: INFO: namespace e2e-tests-gc-jtl5p deletion completed in 6.14746306s

[32mâ€¢ [SLOW TEST:16.345 seconds][0m
[sig-api-machinery] Garbage collector
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should delete pods created by rc when not orphaning [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be submitted and removed [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:00:10.024: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating the pod
[1mSTEP[0m: setting up watch
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: verifying pod creation was observed
Sep  4 02:00:12.222: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-40f4125c-afe6-11e8-8336-00073e906c7f", GenerateName:"", Namespace:"e2e-tests-pods-6smpf", SelfLink:"/api/v1/namespaces/e2e-tests-pods-6smpf/pods/pod-submit-remove-40f4125c-afe6-11e8-8336-00073e906c7f", UID:"40f60694-afe6-11e8-97fd-00073e906c7f", ResourceVersion:"170641", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63671623210, loc:(*time.Location)(0x5ce8240)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"187641740"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8fz7t", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0x4421780d40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-arm64:0.26", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8fz7t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0x4420ce6a58), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0x4421ed5920), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0x4420ce6aa0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0x4420ce6ac0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0x4420ce6ac8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63671623210, loc:(*time.Location)(0x5ce8240)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63671623211, loc:(*time.Location)(0x5ce8240)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63671623210, loc:(*time.Location)(0x5ce8240)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.2.117", PodIP:"10.32.0.8", StartTime:(*v1.Time)(0x4421813fc0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0x4421813fe0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-arm64:0.26", ImageID:"docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14", ContainerID:"hyper://1b5335d1a4eb977b0b2a5b3ec30889692c0ebf7830a7992f5643225720f6dc59"}}, QOSClass:"BestEffort"}}
[1mSTEP[0m: deleting the pod gracefully
[1mSTEP[0m: verifying the kubelet observed the termination notice
Sep  4 02:00:17.242: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[1mSTEP[0m: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:00:17.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-6smpf" for this suite.
Sep  4 02:00:23.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:00:23.312: INFO: namespace: e2e-tests-pods-6smpf, resource: bindings, ignored listing per whitelist
Sep  4 02:00:23.400: INFO: namespace e2e-tests-pods-6smpf deletion completed in 6.14823398s

[32mâ€¢ [SLOW TEST:13.376 seconds][0m
[k8s.io] Pods
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should be submitted and removed [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould rollback without unnecessary restarts [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:00:23.401: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should rollback without unnecessary restarts [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 02:00:23.584: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
Sep  4 02:00:23.594: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-w9rxw/daemonsets","resourceVersion":"170676"},"items":null}

Sep  4 02:00:23.598: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-w9rxw/pods","resourceVersion":"170676"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:00:23.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-w9rxw" for this suite.
Sep  4 02:00:29.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:00:29.672: INFO: namespace: e2e-tests-daemonsets-w9rxw, resource: bindings, ignored listing per whitelist
Sep  4 02:00:29.759: INFO: namespace e2e-tests-daemonsets-w9rxw deletion completed in 6.14655468s

[36m[1mS [SKIPPING] [6.358 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [36m[1mshould rollback without unnecessary restarts [Conformance] [It][0m
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m

  [36mSep  4 02:00:23.584: Requires at least 2 nodes (not -1)[0m

  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:305
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for services  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] DNS
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:00:29.759: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a test headless service
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wc7wz A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wc7wz A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wc7wz.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wc7wz.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wc7wz.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wc7wz.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-wc7wz.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-wc7wz.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 82.87.104.10.in-addr.arpa. PTR)" && echo OK > /results/10.104.87.82_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 82.87.104.10.in-addr.arpa. PTR)" && echo OK > /results/10.104.87.82_tcp@PTR;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wc7wz A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-wc7wz;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wc7wz A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wc7wz.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wc7wz.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wc7wz.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-wc7wz.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wc7wz.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-wc7wz.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-wc7wz.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 82.87.104.10.in-addr.arpa. PTR)" && echo OK > /results/10.104.87.82_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 82.87.104.10.in-addr.arpa. PTR)" && echo OK > /results/10.104.87.82_tcp@PTR;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
Sep  4 02:00:43.966: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:43.972: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:43.978: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:43.984: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:43.990: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:43.996: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.001: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.007: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.049: INFO: Unable to read jessie_udp@dns-test-service from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.055: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.060: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wc7wz from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.065: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.070: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.075: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.080: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.085: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:44.114: INFO: Lookups using dns-test-4cb93383-afe6-11e8-8336-00073e906c7f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz.svc wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-wc7wz jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz jessie_udp@dns-test-service.e2e-tests-dns-wc7wz.svc jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc]

Sep  4 02:00:53.965: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:53.970: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:53.975: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:53.980: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:53.984: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:53.989: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:53.994: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:53.999: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.033: INFO: Unable to read jessie_udp@dns-test-service from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.038: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.043: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wc7wz from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.047: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.052: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.057: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.062: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.066: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc from pod dns-test-4cb93383-afe6-11e8-8336-00073e906c7f: the server could not find the requested resource (get pods dns-test-4cb93383-afe6-11e8-8336-00073e906c7f)
Sep  4 02:00:54.096: INFO: Lookups using dns-test-4cb93383-afe6-11e8-8336-00073e906c7f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz wheezy_udp@dns-test-service.e2e-tests-dns-wc7wz.svc wheezy_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-wc7wz jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz jessie_udp@dns-test-service.e2e-tests-dns-wc7wz.svc jessie_tcp@dns-test-service.e2e-tests-dns-wc7wz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wc7wz.svc]

Sep  4 02:01:04.099: INFO: DNS probes using dns-test-4cb93383-afe6-11e8-8336-00073e906c7f succeeded

[1mSTEP[0m: deleting the pod
[1mSTEP[0m: deleting the test service
[1mSTEP[0m: deleting the test headless service
[AfterEach] [sig-network] DNS
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:01:04.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-dns-wc7wz" for this suite.
Sep  4 02:01:10.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:01:10.227: INFO: namespace: e2e-tests-dns-wc7wz, resource: bindings, ignored listing per whitelist
Sep  4 02:01:10.313: INFO: namespace e2e-tests-dns-wc7wz deletion completed in 6.15414906s

[32mâ€¢ [SLOW TEST:40.554 seconds][0m
[sig-network] DNS
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide DNS for services  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mvolume on tmpfs should have the correct mode [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:01:10.314: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir volume type on tmpfs
Sep  4 02:01:10.487: INFO: Waiting up to 5m0s for pod "pod-64e3ee84-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-zn74b" to be "success or failure"
Sep  4 02:01:10.492: INFO: Pod "pod-64e3ee84-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.691ms
Sep  4 02:01:12.497: INFO: Pod "pod-64e3ee84-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00980306s
[1mSTEP[0m: Saw pod success
Sep  4 02:01:12.497: INFO: Pod "pod-64e3ee84-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:01:12.501: INFO: Trying to get logs from node node3 pod pod-64e3ee84-afe6-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:01:12.526: INFO: Waiting for pod pod-64e3ee84-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 02:01:12.530: INFO: Pod pod-64e3ee84-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:01:12.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-zn74b" for this suite.
Sep  4 02:01:18.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:01:18.678: INFO: namespace: e2e-tests-emptydir-zn74b, resource: bindings, ignored listing per whitelist
Sep  4 02:01:18.686: INFO: namespace e2e-tests-emptydir-zn74b deletion completed in 6.15025294s

[32mâ€¢ [SLOW TEST:8.372 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates resource limits of pods that are allowed to run  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:01:18.686: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Sep  4 02:01:18.844: INFO: Waiting up to 1m0s for all nodes to be ready
Sep  4 02:02:18.874: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 02:02:18.882: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  4 02:02:18.898: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  4 02:02:18.898: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Sep  4 02:02:18.904: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Sep  4 02:02:18.904: INFO: 
Logging pods the kubelet thinks is on node node3 before test
Sep  4 02:02:18.915: INFO: kube-scheduler-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 02:02:18.915: INFO: coredns-78fcdf6894-vlxkz from kube-system started at 2018-09-01 03:57:03 +0000 UTC (1 container statuses recorded)
Sep  4 02:02:18.915: INFO: 	Container coredns ready: true, restart count 1
Sep  4 02:02:18.915: INFO: kube-proxy-d6xgq from kube-system started at 2018-09-01 03:55:38 +0000 UTC (1 container statuses recorded)
Sep  4 02:02:18.915: INFO: 	Container kube-proxy ready: true, restart count 1
Sep  4 02:02:18.915: INFO: kube-apiserver-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 02:02:18.915: INFO: kube-controller-manager-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 02:02:18.915: INFO: etcd-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 02:02:18.915: INFO: weave-net-qrwm8 from kube-system started at 2018-09-01 03:55:38 +0000 UTC (2 container statuses recorded)
Sep  4 02:02:18.915: INFO: 	Container weave ready: true, restart count 2
Sep  4 02:02:18.915: INFO: 	Container weave-npc ready: true, restart count 1
Sep  4 02:02:18.915: INFO: coredns-78fcdf6894-f55jj from kube-system started at 2018-09-01 03:57:03 +0000 UTC (1 container statuses recorded)
Sep  4 02:02:18.915: INFO: 	Container coredns ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: verifying the node has the label node node3
Sep  4 02:02:18.950: INFO: Pod coredns-78fcdf6894-f55jj requesting resource cpu=100m on Node node3
Sep  4 02:02:18.950: INFO: Pod coredns-78fcdf6894-vlxkz requesting resource cpu=100m on Node node3
Sep  4 02:02:18.950: INFO: Pod etcd-node3 requesting resource cpu=0m on Node node3
Sep  4 02:02:18.950: INFO: Pod kube-apiserver-node3 requesting resource cpu=250m on Node node3
Sep  4 02:02:18.950: INFO: Pod kube-controller-manager-node3 requesting resource cpu=200m on Node node3
Sep  4 02:02:18.950: INFO: Pod kube-proxy-d6xgq requesting resource cpu=0m on Node node3
Sep  4 02:02:18.950: INFO: Pod kube-scheduler-node3 requesting resource cpu=100m on Node node3
Sep  4 02:02:18.950: INFO: Pod weave-net-qrwm8 requesting resource cpu=20m on Node node3
[1mSTEP[0m: Starting Pods to consume most of the cluster CPU.
[1mSTEP[0m: Creating another pod that requires unavailable amount of CPU.
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8db3b528-afe6-11e8-8336-00073e906c7f.15510fffbcb86e24], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-gvnvf/filler-pod-8db3b528-afe6-11e8-8336-00073e906c7f to node3]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8db3b528-afe6-11e8-8336-00073e906c7f.15510fffed00eb60], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8db3b528-afe6-11e8-8336-00073e906c7f.15510ffff2585aa8], Reason = [Created], Message = [Created container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8db3b528-afe6-11e8-8336-00073e906c7f.15510ffffb6cbd3c], Reason = [Started], Message = [Started container]
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [additional-pod.1551100034f162d8], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
[1mSTEP[0m: removing the label node off the node node3
[1mSTEP[0m: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:02:22.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-gvnvf" for this suite.
Sep  4 02:02:28.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:02:28.091: INFO: namespace: e2e-tests-sched-pred-gvnvf, resource: bindings, ignored listing per whitelist
Sep  4 02:02:28.165: INFO: namespace e2e-tests-sched-pred-gvnvf deletion completed in 6.151552s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

[32mâ€¢ [SLOW TEST:69.479 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates resource limits of pods that are allowed to run  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:02:28.165: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:02:28.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-934b1eb4-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-jbt8k" to be "success or failure"
Sep  4 02:02:28.343: INFO: Pod "downwardapi-volume-934b1eb4-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.40138ms
Sep  4 02:02:30.348: INFO: Pod "downwardapi-volume-934b1eb4-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00964486s
[1mSTEP[0m: Saw pod success
Sep  4 02:02:30.348: INFO: Pod "downwardapi-volume-934b1eb4-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:02:30.352: INFO: Trying to get logs from node node3 pod downwardapi-volume-934b1eb4-afe6-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:02:30.383: INFO: Waiting for pod downwardapi-volume-934b1eb4-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 02:02:30.387: INFO: Pod downwardapi-volume-934b1eb4-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:02:30.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-jbt8k" for this suite.
Sep  4 02:02:36.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:02:36.534: INFO: namespace: e2e-tests-projected-jbt8k, resource: bindings, ignored listing per whitelist
Sep  4 02:02:36.542: INFO: namespace e2e-tests-projected-jbt8k deletion completed in 6.14896288s

[32mâ€¢ [SLOW TEST:8.377 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:02:36.542: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-98481f73-afe6-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:02:36.712: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9848df80-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-274z4" to be "success or failure"
Sep  4 02:02:36.717: INFO: Pod "pod-projected-secrets-9848df80-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.8219ms
Sep  4 02:02:38.722: INFO: Pod "pod-projected-secrets-9848df80-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00936556s
[1mSTEP[0m: Saw pod success
Sep  4 02:02:38.722: INFO: Pod "pod-projected-secrets-9848df80-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:02:38.726: INFO: Trying to get logs from node node3 pod pod-projected-secrets-9848df80-afe6-11e8-8336-00073e906c7f container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:02:38.749: INFO: Waiting for pod pod-projected-secrets-9848df80-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 02:02:38.753: INFO: Pod pod-projected-secrets-9848df80-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:02:38.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-274z4" for this suite.
Sep  4 02:02:44.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:02:44.863: INFO: namespace: e2e-tests-projected-274z4, resource: bindings, ignored listing per whitelist
Sep  4 02:02:44.908: INFO: namespace e2e-tests-projected-274z4 deletion completed in 6.15012506s

[32mâ€¢ [SLOW TEST:8.366 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mBurst scaling should run to completion even with unhealthy pods [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:02:44.909: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-6929l
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating stateful set ss in namespace e2e-tests-statefulset-6929l
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-6929l
Sep  4 02:02:45.091: INFO: Found 0 stateful pods, waiting for 1
Sep  4 02:02:55.097: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  4 02:02:55.101: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-6929l ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 02:02:55.788: INFO: stderr: ""
Sep  4 02:02:55.788: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 02:02:55.788: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 02:02:55.793: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  4 02:03:05.800: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 02:03:05.800: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 02:03:05.820: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Sep  4 02:03:05.820: INFO: ss-0  node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:45 +0000 UTC  }]
Sep  4 02:03:05.820: INFO: 
Sep  4 02:03:05.820: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  4 02:03:06.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99446894s
Sep  4 02:03:07.833: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.9881452s
Sep  4 02:03:08.839: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98149262s
Sep  4 02:03:09.844: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97551894s
Sep  4 02:03:10.850: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.96969804s
Sep  4 02:03:11.857: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96392366s
Sep  4 02:03:12.862: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95770156s
Sep  4 02:03:13.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95177688s
Sep  4 02:03:14.874: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.8311ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-6929l
Sep  4 02:03:15.880: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-6929l ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 02:03:16.588: INFO: stderr: ""
Sep  4 02:03:16.588: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 02:03:16.588: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 02:03:16.588: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-6929l ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 02:03:17.274: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Sep  4 02:03:17.274: INFO: stdout: ""
Sep  4 02:03:17.274: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Sep  4 02:03:17.274: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-6929l ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 02:03:17.945: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Sep  4 02:03:17.945: INFO: stdout: ""
Sep  4 02:03:17.945: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Sep  4 02:03:17.952: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 02:03:17.952: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 02:03:17.952: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Scale down will not halt with unhealthy stateful pod
Sep  4 02:03:17.957: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-6929l ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 02:03:18.628: INFO: stderr: ""
Sep  4 02:03:18.628: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 02:03:18.628: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 02:03:18.628: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-6929l ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 02:03:19.311: INFO: stderr: ""
Sep  4 02:03:19.311: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 02:03:19.311: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 02:03:19.312: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-6929l ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 02:03:19.984: INFO: stderr: ""
Sep  4 02:03:19.984: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 02:03:19.984: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 02:03:19.984: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 02:03:19.989: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Sep  4 02:03:30.000: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 02:03:30.000: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 02:03:30.000: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 02:03:30.016: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Sep  4 02:03:30.016: INFO: ss-0  node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:45 +0000 UTC  }]
Sep  4 02:03:30.016: INFO: ss-1  node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  }]
Sep  4 02:03:30.016: INFO: ss-2  node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  }]
Sep  4 02:03:30.016: INFO: 
Sep  4 02:03:30.016: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 02:03:31.022: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Sep  4 02:03:31.023: INFO: ss-0  node3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:45 +0000 UTC  }]
Sep  4 02:03:31.023: INFO: ss-1  node3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  }]
Sep  4 02:03:31.023: INFO: ss-2  node3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  }]
Sep  4 02:03:31.023: INFO: 
Sep  4 02:03:31.023: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 02:03:32.029: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Sep  4 02:03:32.029: INFO: ss-0  node3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:02:45 +0000 UTC  }]
Sep  4 02:03:32.029: INFO: ss-1  node3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  }]
Sep  4 02:03:32.029: INFO: ss-2  node3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:03:05 +0000 UTC  }]
Sep  4 02:03:32.029: INFO: 
Sep  4 02:03:32.029: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 02:03:33.034: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.98009194s
Sep  4 02:03:34.039: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.97540356s
Sep  4 02:03:35.044: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.97052844s
Sep  4 02:03:36.049: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.9657374s
Sep  4 02:03:37.054: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.9606815s
Sep  4 02:03:38.059: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.95581346s
Sep  4 02:03:39.063: INFO: Verifying statefulset ss doesn't scale past 0 for another 950.82274ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-6929l
Sep  4 02:03:40.069: INFO: Scaling statefulset ss to 0
Sep  4 02:03:40.082: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Sep  4 02:03:40.086: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6929l
Sep  4 02:03:40.090: INFO: Scaling statefulset ss to 0
Sep  4 02:03:40.103: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 02:03:40.107: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:03:40.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-6929l" for this suite.
Sep  4 02:03:46.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:03:46.243: INFO: namespace: e2e-tests-statefulset-6929l, resource: bindings, ignored listing per whitelist
Sep  4 02:03:46.277: INFO: namespace e2e-tests-statefulset-6929l deletion completed in 6.14977798s

[32mâ€¢ [SLOW TEST:61.369 seconds][0m
[sig-apps] StatefulSet
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:03:46.278: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name secret-test-c1d98168-afe6-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:03:46.452: INFO: Waiting up to 5m0s for pod "pod-secrets-c1da44b0-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-secrets-qspcz" to be "success or failure"
Sep  4 02:03:46.457: INFO: Pod "pod-secrets-c1da44b0-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.58096ms
Sep  4 02:03:48.462: INFO: Pod "pod-secrets-c1da44b0-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00940832s
[1mSTEP[0m: Saw pod success
Sep  4 02:03:48.462: INFO: Pod "pod-secrets-c1da44b0-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:03:48.466: INFO: Trying to get logs from node node3 pod pod-secrets-c1da44b0-afe6-11e8-8336-00073e906c7f container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:03:48.489: INFO: Waiting for pod pod-secrets-c1da44b0-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 02:03:48.494: INFO: Pod pod-secrets-c1da44b0-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:03:48.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-qspcz" for this suite.
Sep  4 02:03:54.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:03:54.546: INFO: namespace: e2e-tests-secrets-qspcz, resource: bindings, ignored listing per whitelist
Sep  4 02:03:54.648: INFO: namespace e2e-tests-secrets-qspcz deletion completed in 6.1491834s

[32mâ€¢ [SLOW TEST:8.370 seconds][0m
[sig-storage] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] ConfigMap[0m 
  [1mshould be consumable via environment variable [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:03:54.649: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap e2e-tests-configmap-96qsd/configmap-test-c6d6b1de-afe6-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:03:54.823: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-96qsd" to be "success or failure"
Sep  4 02:03:54.827: INFO: Pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.69058ms
Sep  4 02:03:56.832: INFO: Pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0095s
Sep  4 02:03:58.837: INFO: Pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01405874s
Sep  4 02:04:00.842: INFO: Pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01887706s
Sep  4 02:04:02.846: INFO: Pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02366828s
Sep  4 02:04:04.851: INFO: Pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02829316s
Sep  4 02:04:06.856: INFO: Pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.0333187s
[1mSTEP[0m: Saw pod success
Sep  4 02:04:06.856: INFO: Pod "pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:04:06.860: INFO: Trying to get logs from node node3 pod pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f container env-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:04:06.888: INFO: Waiting for pod pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 02:04:06.893: INFO: Pod pod-configmaps-c6d78569-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:04:06.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-96qsd" for this suite.
Sep  4 02:04:12.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:04:12.970: INFO: namespace: e2e-tests-configmap-96qsd, resource: bindings, ignored listing per whitelist
Sep  4 02:04:13.046: INFO: namespace e2e-tests-configmap-96qsd deletion completed in 6.14781014s

[32mâ€¢ [SLOW TEST:18.398 seconds][0m
[sig-api-machinery] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29[0m
  should be consumable via environment variable [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:04:13.047: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name secret-test-map-d1ce615a-afe6-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:04:13.222: INFO: Waiting up to 5m0s for pod "pod-secrets-d1cf1752-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-secrets-xzcbs" to be "success or failure"
Sep  4 02:04:13.227: INFO: Pod "pod-secrets-d1cf1752-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.77592ms
Sep  4 02:04:15.232: INFO: Pod "pod-secrets-d1cf1752-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00968934s
[1mSTEP[0m: Saw pod success
Sep  4 02:04:15.232: INFO: Pod "pod-secrets-d1cf1752-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:04:15.237: INFO: Trying to get logs from node node3 pod pod-secrets-d1cf1752-afe6-11e8-8336-00073e906c7f container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:04:15.261: INFO: Waiting for pod pod-secrets-d1cf1752-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 02:04:15.265: INFO: Pod pod-secrets-d1cf1752-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:04:15.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-xzcbs" for this suite.
Sep  4 02:04:21.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:04:21.298: INFO: namespace: e2e-tests-secrets-xzcbs, resource: bindings, ignored listing per whitelist
Sep  4 02:04:21.417: INFO: namespace e2e-tests-secrets-xzcbs deletion completed in 6.14692476s

[32mâ€¢ [SLOW TEST:8.371 seconds][0m
[sig-storage] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:04:21.418: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward api env vars
Sep  4 02:04:21.586: INFO: Waiting up to 5m0s for pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-bm8tx" to be "success or failure"
Sep  4 02:04:21.591: INFO: Pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.91802ms
Sep  4 02:04:23.597: INFO: Pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01034544s
Sep  4 02:04:25.602: INFO: Pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0154525s
Sep  4 02:04:27.607: INFO: Pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02042594s
Sep  4 02:04:29.612: INFO: Pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02539428s
Sep  4 02:04:31.617: INFO: Pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0304631s
Sep  4 02:04:33.622: INFO: Pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03555296s
[1mSTEP[0m: Saw pod success
Sep  4 02:04:33.622: INFO: Pod "downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:04:33.626: INFO: Trying to get logs from node node3 pod downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:04:33.660: INFO: Waiting for pod downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f to disappear
Sep  4 02:04:33.664: INFO: Pod downward-api-d6cb3030-afe6-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:04:33.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-bm8tx" for this suite.
Sep  4 02:04:39.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:04:39.728: INFO: namespace: e2e-tests-downward-api-bm8tx, resource: bindings, ignored listing per whitelist
Sep  4 02:04:39.815: INFO: namespace e2e-tests-downward-api-bm8tx deletion completed in 6.14571106s

[32mâ€¢ [SLOW TEST:18.398 seconds][0m
[sig-api-machinery] Downward API
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37[0m
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:04:39.816: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating projection with configMap that has name projected-configmap-test-upd-e1c46d37-afe6-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap projected-configmap-test-upd-e1c46d37-afe6-11e8-8336-00073e906c7f
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:06:06.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-88vmq" for this suite.
Sep  4 02:06:28.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:06:28.784: INFO: namespace: e2e-tests-projected-88vmq, resource: bindings, ignored listing per whitelist
Sep  4 02:06:28.872: INFO: namespace e2e-tests-projected-88vmq deletion completed in 22.14669476s

[32mâ€¢ [SLOW TEST:109.056 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run job[0m 
  [1mshould create a job from an image when restart is OnFailure  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:06:28.872: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run job
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1371
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: running the image k8s.gcr.io/nginx-slim-arm64:0.26
Sep  4 02:06:29.043: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=k8s.gcr.io/nginx-slim-arm64:0.26 --namespace=e2e-tests-kubectl-86vsw'
Sep  4 02:06:29.519: INFO: stderr: ""
Sep  4 02:06:29.519: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
[1mSTEP[0m: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1376
Sep  4 02:06:29.524: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-86vsw'
Sep  4 02:06:29.861: INFO: stderr: ""
Sep  4 02:06:29.861: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:06:29.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-86vsw" for this suite.
Sep  4 02:06:35.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:06:35.917: INFO: namespace: e2e-tests-kubectl-86vsw, resource: bindings, ignored listing per whitelist
Sep  4 02:06:36.018: INFO: namespace e2e-tests-kubectl-86vsw deletion completed in 6.15124536s

[32mâ€¢ [SLOW TEST:7.146 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run job
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create a job from an image when restart is OnFailure  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould set mode on item file [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:06:36.019: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:06:36.185: INFO: Waiting up to 5m0s for pod "downwardapi-volume-27056b67-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-wjgbn" to be "success or failure"
Sep  4 02:06:36.189: INFO: Pod "downwardapi-volume-27056b67-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.40138ms
Sep  4 02:06:38.195: INFO: Pod "downwardapi-volume-27056b67-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00996s
[1mSTEP[0m: Saw pod success
Sep  4 02:06:38.195: INFO: Pod "downwardapi-volume-27056b67-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:06:38.200: INFO: Trying to get logs from node node3 pod downwardapi-volume-27056b67-afe7-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:06:38.231: INFO: Waiting for pod downwardapi-volume-27056b67-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:06:38.236: INFO: Pod downwardapi-volume-27056b67-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:06:38.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-wjgbn" for this suite.
Sep  4 02:06:44.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:06:44.275: INFO: namespace: e2e-tests-projected-wjgbn, resource: bindings, ignored listing per whitelist
Sep  4 02:06:44.388: INFO: namespace e2e-tests-projected-wjgbn deletion completed in 6.14779284s

[32mâ€¢ [SLOW TEST:8.370 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should set mode on item file [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mShould recreate evicted statefulset [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:06:44.389: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-bghsz
[It] Should recreate evicted statefulset [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Looking for a node to schedule stateful set and pod
[1mSTEP[0m: Creating pod with conflicting port in namespace e2e-tests-statefulset-bghsz
[1mSTEP[0m: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-bghsz
[1mSTEP[0m: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-bghsz
[1mSTEP[0m: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-bghsz
Sep  4 02:06:48.591: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-bghsz, name: ss-0, uid: 2d786813-afe7-11e8-97fd-00073e906c7f, status phase: Failed. Waiting for statefulset controller to delete.
Sep  4 02:06:48.593: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-bghsz
[1mSTEP[0m: Removing pod with conflicting port in namespace e2e-tests-statefulset-bghsz
[1mSTEP[0m: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-bghsz and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Sep  4 02:06:52.624: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bghsz
Sep  4 02:06:52.629: INFO: Scaling statefulset ss to 0
Sep  4 02:07:02.649: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 02:07:02.654: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:07:02.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-bghsz" for this suite.
Sep  4 02:07:08.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:07:08.814: INFO: namespace: e2e-tests-statefulset-bghsz, resource: bindings, ignored listing per whitelist
Sep  4 02:07:08.824: INFO: namespace e2e-tests-statefulset-bghsz deletion completed in 6.14829092s

[32mâ€¢ [SLOW TEST:24.435 seconds][0m
[sig-apps] StatefulSet
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    Should recreate evicted statefulset [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:07:08.825: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name secret-test-map-3a939d17-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:07:08.998: INFO: Waiting up to 5m0s for pod "pod-secrets-3a9464e7-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-secrets-w797p" to be "success or failure"
Sep  4 02:07:09.003: INFO: Pod "pod-secrets-3a9464e7-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.6412ms
Sep  4 02:07:11.008: INFO: Pod "pod-secrets-3a9464e7-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00968286s
[1mSTEP[0m: Saw pod success
Sep  4 02:07:11.008: INFO: Pod "pod-secrets-3a9464e7-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:07:11.012: INFO: Trying to get logs from node node3 pod pod-secrets-3a9464e7-afe7-11e8-8336-00073e906c7f container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:07:11.036: INFO: Waiting for pod pod-secrets-3a9464e7-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:07:11.040: INFO: Pod pod-secrets-3a9464e7-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:07:11.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-w797p" for this suite.
Sep  4 02:07:17.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:07:17.091: INFO: namespace: e2e-tests-secrets-w797p, resource: bindings, ignored listing per whitelist
Sep  4 02:07:17.194: INFO: namespace e2e-tests-secrets-w797p deletion completed in 6.14901922s

[32mâ€¢ [SLOW TEST:8.370 seconds][0m
[sig-storage] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:07:17.195: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward api env vars
Sep  4 02:07:17.359: INFO: Waiting up to 5m0s for pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-84kvc" to be "success or failure"
Sep  4 02:07:17.364: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.34962ms
Sep  4 02:07:19.368: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00911736s
Sep  4 02:07:21.373: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01409672s
Sep  4 02:07:23.378: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01922162s
Sep  4 02:07:25.383: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02406084s
Sep  4 02:07:27.388: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02911908s
Sep  4 02:07:29.393: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.03407992s
Sep  4 02:07:31.399: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.03950558s
[1mSTEP[0m: Saw pod success
Sep  4 02:07:31.399: INFO: Pod "downward-api-3f901d49-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:07:31.403: INFO: Trying to get logs from node node3 pod downward-api-3f901d49-afe7-11e8-8336-00073e906c7f container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:07:31.446: INFO: Waiting for pod downward-api-3f901d49-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:07:31.452: INFO: Pod downward-api-3f901d49-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:07:31.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-84kvc" for this suite.
Sep  4 02:07:37.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:07:37.500: INFO: namespace: e2e-tests-downward-api-84kvc, resource: bindings, ignored listing per whitelist
Sep  4 02:07:37.612: INFO: namespace e2e-tests-downward-api-84kvc deletion completed in 6.15420862s

[32mâ€¢ [SLOW TEST:20.417 seconds][0m
[sig-api-machinery] Downward API
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37[0m
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:07:37.612: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-test-volume-4bbca0fe-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:07:37.789: INFO: Waiting up to 5m0s for pod "pod-configmaps-4bbd6c32-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-nw9c2" to be "success or failure"
Sep  4 02:07:37.793: INFO: Pod "pod-configmaps-4bbd6c32-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.51412ms
Sep  4 02:07:39.799: INFO: Pod "pod-configmaps-4bbd6c32-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00972954s
[1mSTEP[0m: Saw pod success
Sep  4 02:07:39.799: INFO: Pod "pod-configmaps-4bbd6c32-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:07:39.803: INFO: Trying to get logs from node node3 pod pod-configmaps-4bbd6c32-afe7-11e8-8336-00073e906c7f container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:07:39.825: INFO: Waiting for pod pod-configmaps-4bbd6c32-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:07:39.830: INFO: Pod pod-configmaps-4bbd6c32-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:07:39.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-nw9c2" for this suite.
Sep  4 02:07:45.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:07:45.901: INFO: namespace: e2e-tests-configmap-nw9c2, resource: bindings, ignored listing per whitelist
Sep  4 02:07:45.991: INFO: namespace e2e-tests-configmap-nw9c2 deletion completed in 6.15589372s

[32mâ€¢ [SLOW TEST:8.379 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0644,default) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:07:45.991: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0644 on node default medium
Sep  4 02:07:46.156: INFO: Waiting up to 5m0s for pod "pod-50ba2512-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-kfn9b" to be "success or failure"
Sep  4 02:07:46.161: INFO: Pod "pod-50ba2512-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.94366ms
Sep  4 02:07:48.166: INFO: Pod "pod-50ba2512-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01009866s
[1mSTEP[0m: Saw pod success
Sep  4 02:07:48.166: INFO: Pod "pod-50ba2512-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:07:48.170: INFO: Trying to get logs from node node3 pod pod-50ba2512-afe7-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:07:48.192: INFO: Waiting for pod pod-50ba2512-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:07:48.197: INFO: Pod pod-50ba2512-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:07:48.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-kfn9b" for this suite.
Sep  4 02:07:54.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:07:54.319: INFO: namespace: e2e-tests-emptydir-kfn9b, resource: bindings, ignored listing per whitelist
Sep  4 02:07:54.354: INFO: namespace e2e-tests-emptydir-kfn9b deletion completed in 6.1519287s

[32mâ€¢ [SLOW TEST:8.363 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0644,default) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:07:54.355: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-55b7571c-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:07:54.531: INFO: Waiting up to 5m0s for pod "pod-configmaps-55b8241f-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-6gzdv" to be "success or failure"
Sep  4 02:07:54.536: INFO: Pod "pod-configmaps-55b8241f-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.78856ms
Sep  4 02:07:56.541: INFO: Pod "pod-configmaps-55b8241f-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00983812s
[1mSTEP[0m: Saw pod success
Sep  4 02:07:56.541: INFO: Pod "pod-configmaps-55b8241f-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:07:56.545: INFO: Trying to get logs from node node3 pod pod-configmaps-55b8241f-afe7-11e8-8336-00073e906c7f container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:07:56.568: INFO: Waiting for pod pod-configmaps-55b8241f-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:07:56.572: INFO: Pod pod-configmaps-55b8241f-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:07:56.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-6gzdv" for this suite.
Sep  4 02:08:02.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:08:02.622: INFO: namespace: e2e-tests-configmap-6gzdv, resource: bindings, ignored listing per whitelist
Sep  4 02:08:02.729: INFO: namespace e2e-tests-configmap-6gzdv deletion completed in 6.15138142s

[32mâ€¢ [SLOW TEST:8.374 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Docker Containers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:08:02.729: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test override arguments
Sep  4 02:08:02.894: INFO: Waiting up to 5m0s for pod "client-containers-5ab440fd-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-containers-t45vt" to be "success or failure"
Sep  4 02:08:02.899: INFO: Pod "client-containers-5ab440fd-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.50936ms
Sep  4 02:08:04.904: INFO: Pod "client-containers-5ab440fd-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00952068s
[1mSTEP[0m: Saw pod success
Sep  4 02:08:04.904: INFO: Pod "client-containers-5ab440fd-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:08:04.908: INFO: Trying to get logs from node node3 pod client-containers-5ab440fd-afe7-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:08:04.931: INFO: Waiting for pod client-containers-5ab440fd-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:08:04.935: INFO: Pod client-containers-5ab440fd-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:08:04.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-t45vt" for this suite.
Sep  4 02:08:10.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:08:10.990: INFO: namespace: e2e-tests-containers-t45vt, resource: bindings, ignored listing per whitelist
Sep  4 02:08:11.089: INFO: namespace e2e-tests-containers-t45vt deletion completed in 6.14884462s

[32mâ€¢ [SLOW TEST:8.361 seconds][0m
[k8s.io] Docker Containers
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:08:11.090: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-test-upd-5fb1e3da-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap configmap-test-upd-5fb1e3da-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:08:15.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-685dm" for this suite.
Sep  4 02:08:37.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:08:37.431: INFO: namespace: e2e-tests-configmap-685dm, resource: bindings, ignored listing per whitelist
Sep  4 02:08:37.480: INFO: namespace e2e-tests-configmap-685dm deletion completed in 22.14493202s

[32mâ€¢ [SLOW TEST:26.390 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Events[0m 
  [1mshould be sent by kubelets and the scheduler about pods scheduling and running  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] [sig-node] Events
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:08:37.480: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-6f6bcfc3-afe7-11e8-8336-00073e906c7f,GenerateName:,Namespace:e2e-tests-events-6j27k,SelfLink:/api/v1/namespaces/e2e-tests-events-6j27k/pods/send-events-6f6bcfc3-afe7-11e8-8336-00073e906c7f,UID:6f6c959c-afe7-11e8-97fd-00073e906c7f,ResourceVersion:172100,Generation:0,CreationTimestamp:2018-09-04 02:08:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 644292800,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vcbb9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vcbb9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-vcbb9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0x44224edfb0} {node.kubernetes.io/unreachable Exists  NoExecute 0x44224edfd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:08:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:08:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-04 02:08:37 +0000 UTC  }],Message:,Reason:,HostIP:192.168.2.117,PodIP:10.32.0.8,StartTime:2018-09-04 02:08:37 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-09-04 02:08:38 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64@sha256:75090ed67b74bcb8111248dff02c2fc5086c63a6a54596f863131a0d10479741 hyper://4bee1ccebd888354866c5732f1a76f790db09e4bc894ec0678b6abe2808f0c52}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[1mSTEP[0m: checking for scheduler event about the pod
Saw scheduler event for our pod.
[1mSTEP[0m: checking for kubelet event about the pod
Saw kubelet event for our pod.
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:08:43.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-events-6j27k" for this suite.
Sep  4 02:08:49.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:08:49.793: INFO: namespace: e2e-tests-events-6j27k, resource: bindings, ignored listing per whitelist
Sep  4 02:08:49.845: INFO: namespace e2e-tests-events-6j27k deletion completed in 6.1509213s

[32mâ€¢ [SLOW TEST:12.365 seconds][0m
[k8s.io] [sig-node] Events
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:08:49.845: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-76cc2f44-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-76cc2fc5-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-76cc2f44-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Updating configmap cm-test-opt-upd-76cc2fc5-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-76cc3002-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:10:04.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-6qdlt" for this suite.
Sep  4 02:10:26.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:10:26.769: INFO: namespace: e2e-tests-projected-6qdlt, resource: bindings, ignored listing per whitelist
Sep  4 02:10:26.813: INFO: namespace e2e-tests-projected-6qdlt deletion completed in 22.14652754s

[32mâ€¢ [SLOW TEST:96.968 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:10:26.814: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:10:26.986: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b096d596-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-pln9k" to be "success or failure"
Sep  4 02:10:26.990: INFO: Pod "downwardapi-volume-b096d596-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.51848ms
Sep  4 02:10:28.995: INFO: Pod "downwardapi-volume-b096d596-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00960124s
[1mSTEP[0m: Saw pod success
Sep  4 02:10:28.995: INFO: Pod "downwardapi-volume-b096d596-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:10:29.000: INFO: Trying to get logs from node node3 pod downwardapi-volume-b096d596-afe7-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:10:29.025: INFO: Waiting for pod downwardapi-volume-b096d596-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:10:29.030: INFO: Pod downwardapi-volume-b096d596-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:10:29.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-pln9k" for this suite.
Sep  4 02:10:35.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:10:35.157: INFO: namespace: e2e-tests-downward-api-pln9k, resource: bindings, ignored listing per whitelist
Sep  4 02:10:35.188: INFO: namespace e2e-tests-downward-api-pln9k deletion completed in 6.15285818s

[32mâ€¢ [SLOW TEST:8.374 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should provide container's cpu request [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould set DefaultMode on files [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:10:35.188: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:10:35.356: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b593dd65-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-4njdj" to be "success or failure"
Sep  4 02:10:35.361: INFO: Pod "downwardapi-volume-b593dd65-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.86792ms
Sep  4 02:10:37.366: INFO: Pod "downwardapi-volume-b593dd65-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01019906s
[1mSTEP[0m: Saw pod success
Sep  4 02:10:37.366: INFO: Pod "downwardapi-volume-b593dd65-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:10:37.370: INFO: Trying to get logs from node node3 pod downwardapi-volume-b593dd65-afe7-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:10:37.394: INFO: Waiting for pod downwardapi-volume-b593dd65-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:10:37.398: INFO: Pod downwardapi-volume-b593dd65-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:10:37.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-4njdj" for this suite.
Sep  4 02:10:43.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:10:43.519: INFO: namespace: e2e-tests-projected-4njdj, resource: bindings, ignored listing per whitelist
Sep  4 02:10:43.563: INFO: namespace e2e-tests-projected-4njdj deletion completed in 6.16011568s

[32mâ€¢ [SLOW TEST:8.375 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should set DefaultMode on files [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:10:43.563: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:10:43.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba928983-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-rkxmc" to be "success or failure"
Sep  4 02:10:43.739: INFO: Pod "downwardapi-volume-ba928983-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52096ms
Sep  4 02:10:45.745: INFO: Pod "downwardapi-volume-ba928983-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01038934s
[1mSTEP[0m: Saw pod success
Sep  4 02:10:45.745: INFO: Pod "downwardapi-volume-ba928983-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:10:45.750: INFO: Trying to get logs from node node3 pod downwardapi-volume-ba928983-afe7-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:10:45.776: INFO: Waiting for pod downwardapi-volume-ba928983-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:10:45.781: INFO: Pod downwardapi-volume-ba928983-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:10:45.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-rkxmc" for this suite.
Sep  4 02:10:51.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:10:51.840: INFO: namespace: e2e-tests-projected-rkxmc, resource: bindings, ignored listing per whitelist
Sep  4 02:10:51.942: INFO: namespace e2e-tests-projected-rkxmc deletion completed in 6.1564351s

[32mâ€¢ [SLOW TEST:8.379 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should provide container's cpu limit [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould set mode on item file [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:10:51.943: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:10:52.111: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf90a6e7-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-gfd24" to be "success or failure"
Sep  4 02:10:52.116: INFO: Pod "downwardapi-volume-bf90a6e7-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.67328ms
Sep  4 02:10:54.121: INFO: Pod "downwardapi-volume-bf90a6e7-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01004764s
[1mSTEP[0m: Saw pod success
Sep  4 02:10:54.121: INFO: Pod "downwardapi-volume-bf90a6e7-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:10:54.126: INFO: Trying to get logs from node node3 pod downwardapi-volume-bf90a6e7-afe7-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:10:54.149: INFO: Waiting for pod downwardapi-volume-bf90a6e7-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:10:54.153: INFO: Pod downwardapi-volume-bf90a6e7-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:10:54.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-gfd24" for this suite.
Sep  4 02:11:00.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:11:00.287: INFO: namespace: e2e-tests-downward-api-gfd24, resource: bindings, ignored listing per whitelist
Sep  4 02:11:00.306: INFO: namespace e2e-tests-downward-api-gfd24 deletion completed in 6.14703582s

[32mâ€¢ [SLOW TEST:8.363 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should set mode on item file [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve a basic endpoint from pods  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:11:00.307: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating service endpoint-test2 in namespace e2e-tests-services-h97mq
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h97mq to expose endpoints map[]
Sep  4 02:11:00.482: INFO: Get endpoints failed (4.47494ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep  4 02:11:01.487: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h97mq exposes endpoints map[] (1.00921028s elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace e2e-tests-services-h97mq
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h97mq to expose endpoints map[pod1:[80]]
Sep  4 02:11:03.524: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h97mq exposes endpoints map[pod1:[80]] (2.02783856s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace e2e-tests-services-h97mq
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h97mq to expose endpoints map[pod1:[80] pod2:[80]]
Sep  4 02:11:05.570: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h97mq exposes endpoints map[pod1:[80] pod2:[80]] (2.04058022s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace e2e-tests-services-h97mq
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h97mq to expose endpoints map[pod2:[80]]
Sep  4 02:11:05.589: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h97mq exposes endpoints map[pod2:[80]] (11.90404ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace e2e-tests-services-h97mq
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h97mq to expose endpoints map[]
Sep  4 02:11:06.605: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h97mq exposes endpoints map[] (1.0096427s elapsed)
[AfterEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:11:06.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-h97mq" for this suite.
Sep  4 02:11:28.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:11:28.695: INFO: namespace: e2e-tests-services-h97mq, resource: bindings, ignored listing per whitelist
Sep  4 02:11:28.788: INFO: namespace e2e-tests-services-h97mq deletion completed in 22.15867332s
[AfterEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

[32mâ€¢ [SLOW TEST:28.481 seconds][0m
[sig-network] Services
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should serve a basic endpoint from pods  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould project all components that make up the projection API [Projection][NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:11:28.788: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-projected-all-test-volume-d58791a9-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating secret with name secret-projected-all-test-volume-d5879177-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test Check all projections for projected volume plugin
Sep  4 02:11:28.971: INFO: Waiting up to 5m0s for pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-rcbhr" to be "success or failure"
Sep  4 02:11:28.976: INFO: Pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.51396ms
Sep  4 02:11:30.981: INFO: Pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00946032s
Sep  4 02:11:32.986: INFO: Pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01430352s
Sep  4 02:11:34.991: INFO: Pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01910602s
Sep  4 02:11:36.996: INFO: Pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02437004s
Sep  4 02:11:39.001: INFO: Pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0294784s
Sep  4 02:11:41.006: INFO: Pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03470402s
[1mSTEP[0m: Saw pod success
Sep  4 02:11:41.006: INFO: Pod "projected-volume-d587910e-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:11:41.010: INFO: Trying to get logs from node node3 pod projected-volume-d587910e-afe7-11e8-8336-00073e906c7f container projected-all-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:11:41.035: INFO: Waiting for pod projected-volume-d587910e-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:11:41.039: INFO: Pod projected-volume-d587910e-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:11:41.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-rcbhr" for this suite.
Sep  4 02:11:47.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:11:47.141: INFO: namespace: e2e-tests-projected-rcbhr, resource: bindings, ignored listing per whitelist
Sep  4 02:11:47.196: INFO: namespace e2e-tests-projected-rcbhr deletion completed in 6.15141932s

[32mâ€¢ [SLOW TEST:18.408 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:11:47.196: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-test-volume-e0808bfb-afe7-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:11:47.375: INFO: Waiting up to 5m0s for pod "pod-configmaps-e08146a2-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-222qc" to be "success or failure"
Sep  4 02:11:47.379: INFO: Pod "pod-configmaps-e08146a2-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.78866ms
Sep  4 02:11:49.384: INFO: Pod "pod-configmaps-e08146a2-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00934858s
[1mSTEP[0m: Saw pod success
Sep  4 02:11:49.384: INFO: Pod "pod-configmaps-e08146a2-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:11:49.388: INFO: Trying to get logs from node node3 pod pod-configmaps-e08146a2-afe7-11e8-8336-00073e906c7f container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:11:49.412: INFO: Waiting for pod pod-configmaps-e08146a2-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:11:49.417: INFO: Pod pod-configmaps-e08146a2-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:11:49.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-222qc" for this suite.
Sep  4 02:11:55.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:11:55.465: INFO: namespace: e2e-tests-configmap-222qc, resource: bindings, ignored listing per whitelist
Sep  4 02:11:55.571: INFO: namespace e2e-tests-configmap-222qc deletion completed in 6.1485321s

[32mâ€¢ [SLOW TEST:8.375 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0666,default) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:11:55.571: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0666 on node default medium
Sep  4 02:11:55.743: INFO: Waiting up to 5m0s for pod "pod-e57e13d2-afe7-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-vg9wr" to be "success or failure"
Sep  4 02:11:55.748: INFO: Pod "pod-e57e13d2-afe7-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.70462ms
Sep  4 02:11:57.752: INFO: Pod "pod-e57e13d2-afe7-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00956136s
[1mSTEP[0m: Saw pod success
Sep  4 02:11:57.752: INFO: Pod "pod-e57e13d2-afe7-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:11:57.757: INFO: Trying to get logs from node node3 pod pod-e57e13d2-afe7-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:11:57.788: INFO: Waiting for pod pod-e57e13d2-afe7-11e8-8336-00073e906c7f to disappear
Sep  4 02:11:57.793: INFO: Pod pod-e57e13d2-afe7-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:11:57.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-vg9wr" for this suite.
Sep  4 02:12:03.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:12:03.911: INFO: namespace: e2e-tests-emptydir-vg9wr, resource: bindings, ignored listing per whitelist
Sep  4 02:12:03.945: INFO: namespace e2e-tests-emptydir-vg9wr deletion completed in 6.14646294s

[32mâ€¢ [SLOW TEST:8.374 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl version[0m 
  [1mshould check is all data is printed  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:12:03.945: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 02:12:04.109: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf version'
Sep  4 02:12:04.415: INFO: stderr: ""
Sep  4 02:12:04.415: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.2\", GitCommit:\"bb9ffb1654d4a729bb4cec18ff088eacc153c239\", GitTreeState:\"clean\", BuildDate:\"2018-08-31T09:39:29Z\", GoVersion:\"go1.10.2\", Compiler:\"gc\", Platform:\"linux/arm64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.2\", GitCommit:\"bb9ffb1654d4a729bb4cec18ff088eacc153c239\", GitTreeState:\"clean\", BuildDate:\"2018-08-07T23:08:19Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/arm64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:12:04.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-bbxtd" for this suite.
Sep  4 02:12:10.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:12:10.529: INFO: namespace: e2e-tests-kubectl-bbxtd, resource: bindings, ignored listing per whitelist
Sep  4 02:12:10.570: INFO: namespace e2e-tests-kubectl-bbxtd deletion completed in 6.14900054s

[32mâ€¢ [SLOW TEST:6.625 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl version
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should check is all data is printed  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be updated [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:12:10.571: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
Sep  4 02:12:13.272: INFO: Successfully updated pod "pod-update-ee6e50f7-afe7-11e8-8336-00073e906c7f"
[1mSTEP[0m: verifying the updated pod is in kubernetes
Sep  4 02:12:13.281: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:12:13.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-85xxm" for this suite.
Sep  4 02:12:35.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:12:35.392: INFO: namespace: e2e-tests-pods-85xxm, resource: bindings, ignored listing per whitelist
Sep  4 02:12:35.434: INFO: namespace e2e-tests-pods-85xxm deletion completed in 22.14781058s

[32mâ€¢ [SLOW TEST:24.864 seconds][0m
[k8s.io] Pods
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should be updated [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:12:35.435: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:13:35.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-nsbnc" for this suite.
Sep  4 02:13:57.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:13:57.665: INFO: namespace: e2e-tests-container-probe-nsbnc, resource: bindings, ignored listing per whitelist
Sep  4 02:13:57.770: INFO: namespace e2e-tests-container-probe-nsbnc deletion completed in 22.15164596s

[32mâ€¢ [SLOW TEST:82.335 seconds][0m
[k8s.io] Probing container
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:13:57.770: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-jrctj
Sep  4 02:13:59.954: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jrctj
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Sep  4 02:13:59.958: INFO: Initial restart count of pod liveness-http is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:18:00.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-jrctj" for this suite.
Sep  4 02:18:06.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:18:06.687: INFO: namespace: e2e-tests-container-probe-jrctj, resource: bindings, ignored listing per whitelist
Sep  4 02:18:06.709: INFO: namespace e2e-tests-container-probe-jrctj deletion completed in 6.14899944s

[32mâ€¢ [SLOW TEST:248.939 seconds][0m
[k8s.io] Probing container
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:18:06.709: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating secret e2e-tests-secrets-8bqdp/secret-test-c2b64024-afe8-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:18:06.895: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f" in namespace "e2e-tests-secrets-8bqdp" to be "success or failure"
Sep  4 02:18:06.899: INFO: Pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.77286ms
Sep  4 02:18:08.905: INFO: Pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01019618s
Sep  4 02:18:10.910: INFO: Pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01534302s
Sep  4 02:18:12.915: INFO: Pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02000628s
Sep  4 02:18:14.924: INFO: Pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.0294044s
Sep  4 02:18:16.929: INFO: Pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.03415916s
Sep  4 02:18:18.934: INFO: Pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.0389506s
[1mSTEP[0m: Saw pod success
Sep  4 02:18:18.934: INFO: Pod "pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:18:18.938: INFO: Trying to get logs from node node3 pod pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f container env-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:18:18.965: INFO: Waiting for pod pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f to disappear
Sep  4 02:18:18.969: INFO: Pod pod-configmaps-c2b72bcf-afe8-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:18:18.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-8bqdp" for this suite.
Sep  4 02:18:24.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:18:25.081: INFO: namespace: e2e-tests-secrets-8bqdp, resource: bindings, ignored listing per whitelist
Sep  4 02:18:25.123: INFO: namespace e2e-tests-secrets-8bqdp deletion completed in 6.14858838s

[32mâ€¢ [SLOW TEST:18.414 seconds][0m
[sig-api-machinery] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30[0m
  should be consumable via the environment [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:18:25.123: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating the pod
Sep  4 02:18:29.836: INFO: Successfully updated pod "annotationupdatecdaf21f2-afe8-11e8-8336-00073e906c7f"
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:18:31.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-jzpnr" for this suite.
Sep  4 02:18:53.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:18:53.900: INFO: namespace: e2e-tests-downward-api-jzpnr, resource: bindings, ignored listing per whitelist
Sep  4 02:18:54.017: INFO: namespace e2e-tests-downward-api-jzpnr deletion completed in 22.14441744s

[32mâ€¢ [SLOW TEST:28.893 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should update annotations on modification [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] ConfigMap[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:18:54.017: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap e2e-tests-configmap-x6zkh/configmap-test-dee7e86b-afe8-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:18:54.195: INFO: Waiting up to 5m0s for pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-x6zkh" to be "success or failure"
Sep  4 02:18:54.199: INFO: Pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.56892ms
Sep  4 02:18:56.204: INFO: Pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0094617s
Sep  4 02:18:58.209: INFO: Pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01453384s
Sep  4 02:19:00.214: INFO: Pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019426s
Sep  4 02:19:02.219: INFO: Pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02451534s
Sep  4 02:19:04.224: INFO: Pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02923788s
Sep  4 02:19:06.229: INFO: Pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03440914s
[1mSTEP[0m: Saw pod success
Sep  4 02:19:06.229: INFO: Pod "pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:19:06.234: INFO: Trying to get logs from node node3 pod pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f container env-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:19:06.258: INFO: Waiting for pod pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f to disappear
Sep  4 02:19:06.262: INFO: Pod pod-configmaps-dee8b696-afe8-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:19:06.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-x6zkh" for this suite.
Sep  4 02:19:12.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:19:12.357: INFO: namespace: e2e-tests-configmap-x6zkh, resource: bindings, ignored listing per whitelist
Sep  4 02:19:12.415: INFO: namespace e2e-tests-configmap-x6zkh deletion completed in 6.1474576s

[32mâ€¢ [SLOW TEST:18.398 seconds][0m
[sig-api-machinery] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29[0m
  should be consumable via the environment [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:19:12.415: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-e9df7965-afe8-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:19:12.594: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e9e0360c-afe8-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-xsc9f" to be "success or failure"
Sep  4 02:19:12.598: INFO: Pod "pod-projected-secrets-e9e0360c-afe8-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.4232ms
Sep  4 02:19:14.603: INFO: Pod "pod-projected-secrets-e9e0360c-afe8-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00935042s
[1mSTEP[0m: Saw pod success
Sep  4 02:19:14.603: INFO: Pod "pod-projected-secrets-e9e0360c-afe8-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:19:14.607: INFO: Trying to get logs from node node3 pod pod-projected-secrets-e9e0360c-afe8-11e8-8336-00073e906c7f container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:19:14.630: INFO: Waiting for pod pod-projected-secrets-e9e0360c-afe8-11e8-8336-00073e906c7f to disappear
Sep  4 02:19:14.635: INFO: Pod pod-projected-secrets-e9e0360c-afe8-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:19:14.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-xsc9f" for this suite.
Sep  4 02:19:20.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:19:20.778: INFO: namespace: e2e-tests-projected-xsc9f, resource: bindings, ignored listing per whitelist
Sep  4 02:19:20.792: INFO: namespace e2e-tests-projected-xsc9f deletion completed in 6.15182246s

[32mâ€¢ [SLOW TEST:8.377 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform canary updates and phased rolling updates of template modifications [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:19:20.793: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-fm9mk
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a new StaefulSet
Sep  4 02:19:20.969: INFO: Found 0 stateful pods, waiting for 3
Sep  4 02:19:30.975: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 02:19:30.975: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 02:19:30.975: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-arm64:0.26 to k8s.gcr.io/nginx-slim-arm64:0.27
Sep  4 02:19:31.011: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Not applying an update when the partition is greater than the number of replicas
[1mSTEP[0m: Performing a canary update
Sep  4 02:19:41.053: INFO: Updating stateful set ss2
Sep  4 02:19:41.062: INFO: Waiting for Pod e2e-tests-statefulset-fm9mk/ss2-2 to have revision ss2-758959485b update revision ss2-866457fcf7
[1mSTEP[0m: Restoring Pods to the correct revision when they are deleted
Sep  4 02:19:51.124: INFO: Found 1 stateful pods, waiting for 3
Sep  4 02:20:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:20:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:20:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:20:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:20:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:20:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:21:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:21:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:21:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:21:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:21:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:21:51.133: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:22:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:22:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:22:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:22:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:22:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:22:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:23:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:23:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:23:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:23:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:23:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:23:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:24:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:24:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:24:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:24:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:24:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:24:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:25:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:25:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:25:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:25:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:25:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:25:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:26:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:26:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:26:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:26:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:26:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:26:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:27:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:27:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:27:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:27:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:27:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:27:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:28:01.132: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:28:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:28:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:28:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:28:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:28:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:29:01.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:29:11.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:29:21.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:29:31.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:29:41.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:29:51.130: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:29:51.135: INFO: Found 2 stateful pods, waiting for 3
Sep  4 02:29:51.135: INFO: Failed waiting for pods to enter running: timed out waiting for the condition
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Sep  4 02:29:51.142: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe po ss2-0 --namespace=e2e-tests-statefulset-fm9mk'
Sep  4 02:29:51.564: INFO: stderr: ""
Sep  4 02:29:51.564: INFO: stdout: "Name:               ss2-0\nNamespace:          e2e-tests-statefulset-fm9mk\nPriority:           0\nPriorityClassName:  <none>\nNode:               node3/192.168.2.117\nStart Time:         Tue, 04 Sep 2018 02:19:51 +0000\nLabels:             baz=blah\n                    controller-revision-hash=ss2-866457fcf7\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-0\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.32.0.8\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   hyper://d621288839b67a24e09fce7e840f3457e973750c6f4c621382f99d64ab1a180d\n    Image:          k8s.gcr.io/nginx-slim-arm64:0.26\n    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 04 Sep 2018 02:19:52 +0000\n    Ready:          False\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4cg6d (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  default-token-4cg6d:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-4cg6d\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type     Reason     Age                From               Message\n  ----     ------     ----               ----               -------\n  Normal   Scheduled  10m                default-scheduler  Successfully assigned e2e-tests-statefulset-fm9mk/ss2-0 to node3\n  Normal   Pulled     9m                 kubelet, node3     Container image \"k8s.gcr.io/nginx-slim-arm64:0.26\" already present on machine\n  Normal   Created    9m                 kubelet, node3     Created container\n  Normal   Started    9m                 kubelet, node3     Started container\n  Warning  Unhealthy  4m (x300 over 9m)  kubelet, node3     Readiness probe failed: Get http://10.32.0.8:80/index.html: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n"
Sep  4 02:29:51.564: INFO: 
Output of kubectl describe ss2-0:
Name:               ss2-0
Namespace:          e2e-tests-statefulset-fm9mk
Priority:           0
PriorityClassName:  <none>
Node:               node3/192.168.2.117
Start Time:         Tue, 04 Sep 2018 02:19:51 +0000
Labels:             baz=blah
                    controller-revision-hash=ss2-866457fcf7
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-0
Annotations:        <none>
Status:             Running
IP:                 10.32.0.8
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   hyper://d621288839b67a24e09fce7e840f3457e973750c6f4c621382f99d64ab1a180d
    Image:          k8s.gcr.io/nginx-slim-arm64:0.26
    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 04 Sep 2018 02:19:52 +0000
    Ready:          False
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4cg6d (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  default-token-4cg6d:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-4cg6d
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  10m                default-scheduler  Successfully assigned e2e-tests-statefulset-fm9mk/ss2-0 to node3
  Normal   Pulled     9m                 kubelet, node3     Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
  Normal   Created    9m                 kubelet, node3     Created container
  Normal   Started    9m                 kubelet, node3     Started container
  Warning  Unhealthy  4m (x300 over 9m)  kubelet, node3     Readiness probe failed: Get http://10.32.0.8:80/index.html: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)

Sep  4 02:29:51.564: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf logs ss2-0 --namespace=e2e-tests-statefulset-fm9mk --tail=100'
Sep  4 02:29:51.916: INFO: stderr: ""
Sep  4 02:29:51.917: INFO: stdout: ""
Sep  4 02:29:51.917: INFO: 
Last 100 log lines of ss2-0:

Sep  4 02:29:51.917: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe po ss2-1 --namespace=e2e-tests-statefulset-fm9mk'
Sep  4 02:29:52.273: INFO: stderr: ""
Sep  4 02:29:52.273: INFO: stdout: "Name:               ss2-1\nNamespace:          e2e-tests-statefulset-fm9mk\nPriority:           0\nPriorityClassName:  <none>\nNode:               node3/192.168.2.117\nStart Time:         Tue, 04 Sep 2018 02:19:23 +0000\nLabels:             baz=blah\n                    controller-revision-hash=ss2-866457fcf7\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-1\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.32.0.11\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   hyper://15e7e789f7cbb51c1de7eb8bff6e60400d301086fb305b0b81fe10e83fb56250\n    Image:          k8s.gcr.io/nginx-slim-arm64:0.26\n    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 04 Sep 2018 02:19:24 +0000\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4cg6d (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-4cg6d:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-4cg6d\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  10m   default-scheduler  Successfully assigned e2e-tests-statefulset-fm9mk/ss2-1 to node3\n  Normal  Pulled     10m   kubelet, node3     Container image \"k8s.gcr.io/nginx-slim-arm64:0.26\" already present on machine\n  Normal  Created    10m   kubelet, node3     Created container\n  Normal  Started    10m   kubelet, node3     Started container\n"
Sep  4 02:29:52.273: INFO: 
Output of kubectl describe ss2-1:
Name:               ss2-1
Namespace:          e2e-tests-statefulset-fm9mk
Priority:           0
PriorityClassName:  <none>
Node:               node3/192.168.2.117
Start Time:         Tue, 04 Sep 2018 02:19:23 +0000
Labels:             baz=blah
                    controller-revision-hash=ss2-866457fcf7
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-1
Annotations:        <none>
Status:             Running
IP:                 10.32.0.11
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   hyper://15e7e789f7cbb51c1de7eb8bff6e60400d301086fb305b0b81fe10e83fb56250
    Image:          k8s.gcr.io/nginx-slim-arm64:0.26
    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 04 Sep 2018 02:19:24 +0000
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4cg6d (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-4cg6d:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-4cg6d
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  10m   default-scheduler  Successfully assigned e2e-tests-statefulset-fm9mk/ss2-1 to node3
  Normal  Pulled     10m   kubelet, node3     Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
  Normal  Created    10m   kubelet, node3     Created container
  Normal  Started    10m   kubelet, node3     Started container

Sep  4 02:29:52.273: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf logs ss2-1 --namespace=e2e-tests-statefulset-fm9mk --tail=100'
Sep  4 02:29:52.630: INFO: stderr: ""
Sep  4 02:29:52.631: INFO: stdout: "10.32.0.1 - - [04/Sep/2018:02:28:13 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:14 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:15 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:16 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:17 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:18 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:19 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:20 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:21 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:22 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:23 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:24 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:25 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:26 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:27 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:28 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:29 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:30 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:31 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:32 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:33 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:34 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:35 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:36 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:37 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:38 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:39 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:40 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:41 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:42 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:43 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:44 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:45 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:46 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:47 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:48 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:49 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:50 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:51 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:52 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:53 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:54 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:55 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:56 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:57 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:58 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:28:59 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:00 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:01 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:02 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:03 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:04 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:05 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:06 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:07 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:08 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:09 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:10 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:11 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:12 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:13 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:14 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:15 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:16 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:17 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:18 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:19 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:20 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:21 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:22 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:23 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:24 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:25 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:26 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:27 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:28 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:29 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:30 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:31 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:32 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:33 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:34 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:35 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:36 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:37 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:38 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:39 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:40 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:41 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:42 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:43 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:44 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:45 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:46 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:47 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:48 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:49 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:50 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:51 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:02:29:52 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n"
Sep  4 02:29:52.631: INFO: 
Last 100 log lines of ss2-1:
10.32.0.1 - - [04/Sep/2018:02:28:13 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:14 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:15 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:16 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:17 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:18 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:19 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:20 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:21 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:22 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:23 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:24 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:25 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:26 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:27 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:28 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:29 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:30 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:31 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:32 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:33 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:34 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:35 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:36 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:37 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:38 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:39 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:40 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:41 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:42 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:43 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:44 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:45 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:46 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:47 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:48 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:49 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:50 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:51 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:52 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:53 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:54 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:55 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:56 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:57 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:58 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:28:59 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:00 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:01 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:02 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:03 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:04 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:05 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:06 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:07 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:08 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:09 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:10 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:11 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:12 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:13 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:14 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:15 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:16 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:17 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:18 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:19 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:20 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:21 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:22 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:23 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:24 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:25 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:26 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:27 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:28 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:29 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:30 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:31 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:32 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:33 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:34 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:35 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:36 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:37 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:38 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:39 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:40 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:41 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:42 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:43 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:44 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:45 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:46 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:47 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:48 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:49 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:50 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:51 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:02:29:52 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"

Sep  4 02:29:52.631: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fm9mk
Sep  4 02:29:52.637: INFO: Scaling statefulset ss2 to 0
Sep  4 02:30:02.664: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 02:30:02.669: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
[1mSTEP[0m: Collecting events from namespace "e2e-tests-statefulset-fm9mk".
[1mSTEP[0m: Found 32 events.
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:20 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-0 in StatefulSet ss2 successful
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:20 +0000 UTC - event for ss2-0: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-fm9mk/ss2-0 to node3
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:21 +0000 UTC - event for ss2-0: {kubelet node3} Created: Created container
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:21 +0000 UTC - event for ss2-0: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:22 +0000 UTC - event for ss2-0: {kubelet node3} Started: Started container
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:23 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-1 in StatefulSet ss2 successful
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:23 +0000 UTC - event for ss2-1: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-fm9mk/ss2-1 to node3
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:24 +0000 UTC - event for ss2-1: {kubelet node3} Created: Created container
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:24 +0000 UTC - event for ss2-1: {kubelet node3} Started: Started container
Sep  4 02:30:02.694: INFO: At 2018-09-04 02:19:24 +0000 UTC - event for ss2-1: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:25 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-2 in StatefulSet ss2 successful
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:25 +0000 UTC - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-fm9mk/ss2-2 to node3
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:25 +0000 UTC - event for ss2-2: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:26 +0000 UTC - event for ss2-2: {kubelet node3} Created: Created container
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:26 +0000 UTC - event for ss2-2: {kubelet node3} Started: Started container
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:41 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-2 in StatefulSet ss2 successful
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:41 +0000 UTC - event for ss2-2: {kubelet node3} Unhealthy: Readiness probe failed: Get http://10.32.0.12:80/index.html: dial tcp 10.32.0.12:80: connect: connection refused
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:41 +0000 UTC - event for ss2-2: {kubelet node3} Killing: Killing container with id hyper://nginx:Need to kill Pod
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:47 +0000 UTC - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-fm9mk/ss2-2 to node3
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:48 +0000 UTC - event for ss2-2: {kubelet node3} Created: Created container
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:48 +0000 UTC - event for ss2-2: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.27" already present on machine
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:48 +0000 UTC - event for ss2-2: {kubelet node3} Started: Started container
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:51 +0000 UTC - event for ss2-0: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-fm9mk/ss2-0 to node3
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:51 +0000 UTC - event for ss2-0: {kubelet node3} Killing: Killing container with id hyper://nginx:Need to kill Pod
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:51 +0000 UTC - event for ss2-2: {kubelet node3} Killing: Killing container with id hyper://nginx:Need to kill Pod
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:52 +0000 UTC - event for ss2-0: {kubelet node3} Created: Created container
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:52 +0000 UTC - event for ss2-0: {kubelet node3} Started: Started container
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:52 +0000 UTC - event for ss2-0: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:19:53 +0000 UTC - event for ss2-0: {kubelet node3} Unhealthy: Readiness probe failed: Get http://10.32.0.8:80/index.html: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:29:52 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-1 in StatefulSet ss2 successful
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:29:52 +0000 UTC - event for ss2-1: {kubelet node3} Killing: Killing container with id hyper://nginx:Need to kill Pod
Sep  4 02:30:02.695: INFO: At 2018-09-04 02:29:57 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-0 in StatefulSet ss2 successful
Sep  4 02:30:02.709: INFO: POD                            NODE   PHASE    GRACE  CONDITIONS
Sep  4 02:30:02.709: INFO: coredns-78fcdf6894-f55jj       node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:57:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:46:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:57:03 +0000 UTC  }]
Sep  4 02:30:02.709: INFO: coredns-78fcdf6894-vlxkz       node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:57:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:46:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:57:03 +0000 UTC  }]
Sep  4 02:30:02.709: INFO: etcd-node3                     node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  }]
Sep  4 02:30:02.709: INFO: kube-apiserver-node3           node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  }]
Sep  4 02:30:02.709: INFO: kube-controller-manager-node3  node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  }]
Sep  4 02:30:02.709: INFO: kube-proxy-d6xgq               node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:55:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:46:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:55:38 +0000 UTC  }]
Sep  4 02:30:02.709: INFO: kube-scheduler-node3           node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  }]
Sep  4 02:30:02.709: INFO: weave-net-qrwm8                node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:55:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:46:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:55:38 +0000 UTC  }]
Sep  4 02:30:02.709: INFO: 
Sep  4 02:30:02.714: INFO: 
Logging node info for node node3
Sep  4 02:30:02.720: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:node3,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/node3,UID:d76c0c97-ad9a-11e8-a7d7-1e59e086a4f1,ResourceVersion:174257,Generation:0,CreationTimestamp:2018-09-01 03:55:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: arm64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: node3,node-role.kubernetes.io/master: ,},Annotations:map[string]string{kubeadm.alpha.kubernetes.io/cri-socket: /var/run/frakti.sock,node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:10.244.0.0/24,DoNotUse_ExternalID:,ProviderID:,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{82538430464 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{67535159296 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{74284587295 0} {<nil>} 74284587295 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{67430301696 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2018-09-03 03:46:46 +0000 UTC 2018-09-03 03:46:46 +0000 UTC WeaveIsUp Weave pod has set this} {OutOfDisk False 2018-09-04 02:29:56 +0000 UTC 2018-09-01 03:55:11 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-09-04 02:29:56 +0000 UTC 2018-09-01 03:55:11 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-09-04 02:29:56 +0000 UTC 2018-09-01 03:55:11 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-09-04 02:29:56 +0000 UTC 2018-09-01 03:55:11 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-09-04 02:29:56 +0000 UTC 2018-09-04 01:30:47 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 192.168.2.117} {Hostname node3}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:373be5c264ac4b78a49077a4b4ded99c,SystemUUID:373be5c264ac4b78a49077a4b4ded99c,BootID:c3229fda-d628-476e-9988-7af0bb46b762,KernelVersion:4.4.58-20171215.kylin.server.YUN+-generic,OSImage:Kylin 4.0.2,ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.11.2,KubeProxyVersion:v1.11.2,OperatingSystem:linux,Architecture:arm64,},Images:[{[k8s.gcr.io/kube-cross@sha256:0c5809a727c38458e9a63b486cf83c504a24ff561d63a031d31e613f6ad50282 k8s.gcr.io/kube-cross:v1.10.2-1] 2076524551} {[mrdreambot/arm64-mysql@sha256:872464bd31f5db2ecfce15824c80a0b78ace914e80e78a0e98d2d9ef7e8bbb79 mrdreambot/arm64-mysql:latest] 529883867} {[bobsense/mysql@sha256:a20cd35207c46b0400ac48fdf21ebb8e432fa5b597eb5f4b6ec6a634ecc26a8a bobsense/mysql:latest] 529882429} {[mariadb@sha256:358f6b50afd9c25707e97869f0c57de802c53973a90a2ff49e283501fccce1b2 mariadb:10.1.14] 387643618} {[wordpress@sha256:b0460dba11737144b232a7794403d4052982f2332caeea82f618fc98d0547387 wordpress:latest] 367973768} {[mariadb@sha256:edef80de393cf4a79504168c663f8b0c6b15060333e5a7d7aee3dc0a4de6e927 mariadb:latest] 348940495} {[hyperhq/mariadb-arm64v8@sha256:bcf8c747e35eddfcd36ffc6011b00ececb56fe467afb290280d80709299fd80d hyperhq/mariadb-arm64v8:10.3-1] 348507360} {[hyperhq/mariadb-arm64v8:10.3] 348507300} {[hyperhq/mariadb-arm64v8@sha256:720d233b09adbea084c15cfa4909008a2df201b300b10c9fd39464bce60af0db hyperhq/mariadb-arm64v8:10.3-2] 348507153} {[bobsense/nginx-arm64@sha256:224f3b5fd469754e5e701bedd28c633c92ba21c00d2b0e9376eaa4adb38b5603 bobsense/nginx-arm64:latest] 338655564} {[gcr.io/google-samples/gb-frontend-arm64@sha256:9587be21f54a9dc04e1f37b83a9d120231b205385d8deba0682d6fb22088e7c9 gcr.io/google-samples/gb-frontend-arm64:v5] 337228898} {[lsioarmhf/mariadb-aarch64@sha256:b2a1bd89d60c579f07ae1837280a2b3b5f35f11f756b9aa61e6a025af03ddf87 lsioarmhf/mariadb-aarch64:latest] 327268490} {[ebspace/aarch64-mysql@sha256:d9f5f5d222a155c930e3837976b5b457e48c000cf34e6919d0f8a0b73dc39965 ebspace/aarch64-mysql:latest] 262591608} {[tobi312/rpi-mysql@sha256:2f0b069765901afbb162838359778088b8d9fdba30b201d5cf51381ec008802a tobi312/rpi-mysql:latest] 256067342} {[k8s.gcr.io/volume-nfs@sha256:83ba87be13a6f74361601c8614527e186ca67f49091e2d0d4ae8a8da67c403ee k8s.gcr.io/volume-nfs:0.8] 247146979} {[postgres@sha256:d9c44f9fc460dd8962c388eacf88a0e252b858ccdf33bc223f68112617e81fc9 postgres:10] 233845668} {[k8s.gcr.io/etcd-arm64@sha256:f0b7368ebb28e6226ab3b4dbce4b5c6d77dab7b5f6579b08fd645c00f7b100ff k8s.gcr.io/etcd-arm64:3.2.18] 229927444} {[k8s.gcr.io/kube-apiserver-arm64@sha256:5c77134dc174453fc0d900ee5cdcb7b488131a0edb934ae8e859a263f8ee55da k8s.gcr.io/kube-apiserver-arm64:v1.10.4] 218561963} {[k8s.gcr.io/kube-apiserver-arm64@sha256:ab41e3e38792750fa122dbeacf7d0d3d52b7ccc466f254c460733846da0ce0c9 k8s.gcr.io/kube-apiserver-arm64:v1.10.3] 218559018} {[hypriot/rpi-mysql@sha256:c1567c885cf560da66a647f91f7e16bfeea2968895f859b5732583a8db3570ea hypriot/rpi-mysql:latest] 209339591} {[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils-arm64@sha256:92105b23ab1bcc1f72b7deeb4b7d72b27b4ba9a47b292fbd4f58f4080f0621a2 gcr.io/kubernetes-e2e-test-images/jessie-dnsutils-arm64:1.0] 193983470} {[k8s.gcr.io/kube-apiserver-arm64@sha256:31fa4a96f582953034fb2906bd2e557620943ebaa2c2f74ee719c89a9bffb0d4 k8s.gcr.io/kube-apiserver-arm64:v1.11.2] 185805939} {[k8s.gcr.io/etcd-arm64@sha256:c6418130352f3632f3858ff466f7fdcde5c2867d9471f40dbb99227ccbb6d458 k8s.gcr.io/etcd-arm64:3.1.12] 180941491} {[functions/faas-netesd@sha256:05072b13c8127d53b48466f6b16beae997ff008e13a74cdb5da64ca2f5708062 functions/faas-netesd:arm64-0.3-alpha6] 154407667} {[k8s.gcr.io/kube-controller-manager-arm64@sha256:af5e55e15e5ab06999716ef72792b0abed63c9fc972db99120b2c40febaf69a7 k8s.gcr.io/kube-controller-manager-arm64:v1.11.2] 153069058} {[functions/faas-netesd@sha256:0903fd0a2c6010fcef6f42eda8fdc22bf4aecc31571b7ab6f461041497f34aa4 functions/faas-netesd:0.4.3-arm64] 148751197} {[k8s.gcr.io/kube-controller-manager-arm64@sha256:138de23ccbdfab3f4e76e05c290aab26c9127a853db8a0cbc2d816b31d5aebbd k8s.gcr.io/kube-controller-manager-arm64:v1.10.4] 142046988} {[k8s.gcr.io/kube-controller-manager-arm64@sha256:4f99bac50d84f8757ef06d06e68eee0aa042fdb5969c300d23ad1ae3b1f914f5 k8s.gcr.io/kube-controller-manager-arm64:v1.10.3] 142046537} {[weaveworks/weave-kube@sha256:3c45b339ab2dc9c11c9c745e44afce27806dc1d8ecd1da84a88deb36756ac713 weaveworks/weave-kube:2.4.0] 131119125} {[k8s.gcr.io/nginx-slim-arm64@sha256:b95f8bebdc6d8a7b65f5954aa5aaea3209ad8a6af5261cf3c8cae0c0a1c0fb79 k8s.gcr.io/nginx-slim-arm64:0.27] 126129565} {[k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14 k8s.gcr.io/nginx-slim-arm64:0.26] 126125347} {[hyperhq/postgres-wordpress-arm:latest] 110592210} {[wordpress@sha256:3c22b14d0269bd50b2011f6d749d8bee68e328167f774bef8bf11f5878a6035d wordpress:4.9-fpm-alpine] 107828983} {[functions/gateway@sha256:01aea2775bb40d69588d2c6e83e8b9ea5009b9f405b140e643eb4be2a775814d functions/gateway:arm64-0.6.6-beta2] 106004910} {[k8s.gcr.io/kube-proxy-arm64@sha256:3bb2bfdc016ae46d131af74040bec2c48134c733ae90fead4da3568014fb450a k8s.gcr.io/kube-proxy-arm64:v1.11.2] 102835336} {[nginx@sha256:3e2ffcf0edca2a4e9b24ca442d227baea7b7f0e33ad654ef1eb806fbd9bedcf0 nginx:latest] 102594503} {[k8s.gcr.io/kube-proxy-arm64@sha256:f024ad81abe8b9bf473c0b8ff5c96723505b8a592379d606038499f8a77f663b k8s.gcr.io/kube-proxy-arm64:v1.10.4] 100601489} {[k8s.gcr.io/kube-proxy-arm64@sha256:b21badcd0799bb7495ebcbc17557861384da1eac42d6527937a8aaed0c329d6c k8s.gcr.io/kube-proxy-arm64:v1.10.3] 100598796} {[k8s.gcr.io/echoserver@sha256:d2a8af33e4e6dc7f18fc8d0cd345b2c893922083c6e2c2cbf24a2efcaa7aa3ba k8s.gcr.io/echoserver:1.6] 95247805} {[gcr.io/google-samples/gb-redisslave-arm64@sha256:2420127acd816ebbdbaa33cab372493859c1d40b3a2d5d6fc05bc38887ad9511 gcr.io/google-samples/gb-redisslave-arm64:v2] 94082700} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91641000} {[<none>@<none> <none>:<none>] 76567645} {[ubuntu@sha256:3f119dc0737f57f704ebecac8a6d8477b0f6ca1ca0332c7ee1395ed2c6a82be7 ubuntu:bionic] 76171071} {[k8s.gcr.io/kube-scheduler-arm64@sha256:3ece3012cc6fedf5193fd1c80aee4b6da2835098b7799d4940fb4a79fc1be0ee k8s.gcr.io/kube-scheduler-arm64:v1.11.2] 56216691} {[weaveworks/weave-npc@sha256:715b03e14874355f1f793f7bc11d843a00b390b2806bd996f1e47e8acb1020aa weaveworks/weave-npc:2.4.0] 51096437} {[k8s.gcr.io/k8s-dns-kube-dns-arm64@sha256:9bcc8fda237765f8b8f8fdf5af220b856adbc8b56d72dc4f336d44510d1749d9 k8s.gcr.io/k8s-dns-kube-dns-arm64:1.14.8] 49350613} {[k8s.gcr.io/kube-scheduler-arm64@sha256:fbff009828de95e14856325ebcfc6e1c0cdb456a052c62ba0c64221773c68686 k8s.gcr.io/kube-scheduler-arm64:v1.10.4] 48502539} {[k8s.gcr.io/kube-scheduler-arm64@sha256:6847ebb67c5a2928d8997d98001eb107a50601e85e07c3245f72b14df4518616 k8s.gcr.io/kube-scheduler-arm64:v1.10.3] 48434682} {[k8s.gcr.io/k8s-dns-dnsmasq-nanny-arm64@sha256:35ac228d45ab5f4209f25317506fa53b762f6d8ad333d1ff795393fa6e97b29c k8s.gcr.io/k8s-dns-dnsmasq-nanny-arm64:1.14.8] 42547598} {[k8s.gcr.io/k8s-dns-sidecar-arm64@sha256:b2c1e4e04d77ed564e918ebd16443dfb2217653b58293e616e36f034068d6da3 k8s.gcr.io/k8s-dns-sidecar-arm64:1.14.8] 41256276}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Sep  4 02:30:02.720: INFO: 
Logging kubelet events for node node3
Sep  4 02:30:02.725: INFO: 
Logging pods the kubelet thinks is on node node3
Sep  4 02:30:02.737: INFO: coredns-78fcdf6894-vlxkz started at 2018-09-01 03:57:03 +0000 UTC (0+1 container statuses recorded)
Sep  4 02:30:02.737: INFO: 	Container coredns ready: true, restart count 1
Sep  4 02:30:02.737: INFO: kube-proxy-d6xgq started at 2018-09-01 03:55:38 +0000 UTC (0+1 container statuses recorded)
Sep  4 02:30:02.737: INFO: 	Container kube-proxy ready: true, restart count 1
Sep  4 02:30:02.737: INFO: kube-apiserver-node3 started at <nil> (0+0 container statuses recorded)
Sep  4 02:30:02.737: INFO: kube-controller-manager-node3 started at <nil> (0+0 container statuses recorded)
Sep  4 02:30:02.737: INFO: kube-scheduler-node3 started at <nil> (0+0 container statuses recorded)
Sep  4 02:30:02.737: INFO: etcd-node3 started at <nil> (0+0 container statuses recorded)
Sep  4 02:30:02.737: INFO: weave-net-qrwm8 started at 2018-09-01 03:55:38 +0000 UTC (0+2 container statuses recorded)
Sep  4 02:30:02.737: INFO: 	Container weave ready: true, restart count 2
Sep  4 02:30:02.737: INFO: 	Container weave-npc ready: true, restart count 1
Sep  4 02:30:02.737: INFO: coredns-78fcdf6894-f55jj started at 2018-09-01 03:57:03 +0000 UTC (0+1 container statuses recorded)
Sep  4 02:30:02.737: INFO: 	Container coredns ready: true, restart count 1
W0904 02:30:02.743273   10499 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 02:30:02.827: INFO: 
Latency metrics for node node3
[1mSTEP[0m: Dumping a list of prepulled images on each node...
Sep  4 02:30:02.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-fm9mk" for this suite.
Sep  4 02:30:08.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:30:08.919: INFO: namespace: e2e-tests-statefulset-fm9mk, resource: bindings, ignored listing per whitelist
Sep  4 02:30:08.993: INFO: namespace e2e-tests-statefulset-fm9mk deletion completed in 6.1537151s

[91m[1mâ€¢ Failure [648.200 seconds][0m
[sig-apps] StatefulSet
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    [91m[1mshould perform canary updates and phased rolling updates of template modifications [Conformance] [It][0m
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m

    [91mSep  4 02:29:51.135: Failed waiting for pods to enter running: timed out waiting for the condition[0m

    /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/statefulset_utils.go:323
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:30:08.993: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:30:09.169: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7139916c-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-nwcwx" to be "success or failure"
Sep  4 02:30:09.173: INFO: Pod "downwardapi-volume-7139916c-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.67168ms
Sep  4 02:30:11.179: INFO: Pod "downwardapi-volume-7139916c-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01018148s
Sep  4 02:30:13.184: INFO: Pod "downwardapi-volume-7139916c-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01549182s
[1mSTEP[0m: Saw pod success
Sep  4 02:30:13.184: INFO: Pod "downwardapi-volume-7139916c-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:30:13.189: INFO: Trying to get logs from node node3 pod downwardapi-volume-7139916c-afea-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:30:13.215: INFO: Waiting for pod downwardapi-volume-7139916c-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:30:13.220: INFO: Pod downwardapi-volume-7139916c-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:30:13.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-nwcwx" for this suite.
Sep  4 02:30:19.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:30:19.262: INFO: namespace: e2e-tests-projected-nwcwx, resource: bindings, ignored listing per whitelist
Sep  4 02:30:19.381: INFO: namespace e2e-tests-projected-nwcwx deletion completed in 6.15564376s

[32mâ€¢ [SLOW TEST:10.388 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should provide container's cpu request [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould retry creating failed daemon pods [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:30:19.382: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should retry creating failed daemon pods [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a simple DaemonSet "daemon-set"
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Sep  4 02:30:19.578: INFO: Number of nodes with available pods: 0
Sep  4 02:30:19.578: INFO: Node node3 is running more than one daemon pod
Sep  4 02:30:20.589: INFO: Number of nodes with available pods: 0
Sep  4 02:30:20.589: INFO: Node node3 is running more than one daemon pod
Sep  4 02:30:21.588: INFO: Number of nodes with available pods: 1
Sep  4 02:30:21.588: INFO: Number of running nodes: 1, number of available pods: 1
[1mSTEP[0m: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  4 02:30:21.617: INFO: Number of nodes with available pods: 0
Sep  4 02:30:21.617: INFO: Node node3 is running more than one daemon pod
Sep  4 02:30:22.628: INFO: Number of nodes with available pods: 0
Sep  4 02:30:22.628: INFO: Node node3 is running more than one daemon pod
Sep  4 02:30:23.628: INFO: Number of nodes with available pods: 0
Sep  4 02:30:23.628: INFO: Node node3 is running more than one daemon pod
Sep  4 02:30:24.628: INFO: Number of nodes with available pods: 1
Sep  4 02:30:24.628: INFO: Number of running nodes: 1, number of available pods: 1
[1mSTEP[0m: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-29wcb, will wait for the garbage collector to delete the pods
Sep  4 02:30:24.698: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.74216ms
Sep  4 02:30:24.798: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.25638ms
Sep  4 02:30:27.803: INFO: Number of nodes with available pods: 0
Sep  4 02:30:27.803: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 02:30:27.807: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-29wcb/daemonsets","resourceVersion":"174408"},"items":null}

Sep  4 02:30:27.812: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-29wcb/pods","resourceVersion":"174408"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:30:27.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-29wcb" for this suite.
Sep  4 02:30:33.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:30:33.978: INFO: namespace: e2e-tests-daemonsets-29wcb, resource: bindings, ignored listing per whitelist
Sep  4 02:30:33.982: INFO: namespace e2e-tests-daemonsets-29wcb deletion completed in 6.15421268s

[32mâ€¢ [SLOW TEST:14.600 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should retry creating failed daemon pods [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl rolling-update[0m 
  [1mshould support rolling-update to same image  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:30:33.982: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl rolling-update
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1276
[It] should support rolling-update to same image  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: running the image k8s.gcr.io/nginx-slim-arm64:0.26
Sep  4 02:30:34.151: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-arm64:0.26 --generator=run/v1 --namespace=e2e-tests-kubectl-d8hrc'
Sep  4 02:30:34.498: INFO: stderr: ""
Sep  4 02:30:34.498: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
[1mSTEP[0m: verifying the rc e2e-test-nginx-rc was created
[1mSTEP[0m: rolling-update to same image controller
Sep  4 02:30:34.507: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf rolling-update e2e-test-nginx-rc --update-period=1s --image=k8s.gcr.io/nginx-slim-arm64:0.26 --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-d8hrc'
Sep  4 02:30:50.456: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  4 02:30:50.456: INFO: stdout: "Created e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d\nScaling up e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  4 02:30:50.456: INFO: stdout: "Created e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d\nScaling up e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
[1mSTEP[0m: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  4 02:30:50.457: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-d8hrc'
Sep  4 02:30:50.784: INFO: stderr: ""
Sep  4 02:30:50.784: INFO: stdout: "e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d-mx2c9 "
Sep  4 02:30:50.784: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d-mx2c9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d8hrc'
Sep  4 02:30:51.106: INFO: stderr: ""
Sep  4 02:30:51.106: INFO: stdout: "true"
Sep  4 02:30:51.106: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d-mx2c9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d8hrc'
Sep  4 02:30:51.425: INFO: stderr: ""
Sep  4 02:30:51.426: INFO: stdout: "k8s.gcr.io/nginx-slim-arm64:0.26"
Sep  4 02:30:51.426: INFO: e2e-test-nginx-rc-0969b2a7298b1ee444dcddc01555ec2d-mx2c9 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
Sep  4 02:30:51.426: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-d8hrc'
Sep  4 02:30:51.762: INFO: stderr: ""
Sep  4 02:30:51.762: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:30:51.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-d8hrc" for this suite.
Sep  4 02:31:13.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:31:13.845: INFO: namespace: e2e-tests-kubectl-d8hrc, resource: bindings, ignored listing per whitelist
Sep  4 02:31:13.919: INFO: namespace e2e-tests-kubectl-d8hrc deletion completed in 22.14983044s

[32mâ€¢ [SLOW TEST:39.936 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl rolling-update
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should support rolling-update to same image  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0644,default) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:31:13.919: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0644 on node default medium
Sep  4 02:31:14.097: INFO: Waiting up to 5m0s for pod "pod-97ed0403-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-259q2" to be "success or failure"
Sep  4 02:31:14.102: INFO: Pod "pod-97ed0403-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.59736ms
Sep  4 02:31:16.108: INFO: Pod "pod-97ed0403-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01019606s
[1mSTEP[0m: Saw pod success
Sep  4 02:31:16.108: INFO: Pod "pod-97ed0403-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:31:16.112: INFO: Trying to get logs from node node3 pod pod-97ed0403-afea-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:31:16.135: INFO: Waiting for pod pod-97ed0403-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:31:16.140: INFO: Pod pod-97ed0403-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:31:16.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-259q2" for this suite.
Sep  4 02:31:22.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:31:22.175: INFO: namespace: e2e-tests-emptydir-259q2, resource: bindings, ignored listing per whitelist
Sep  4 02:31:22.296: INFO: namespace e2e-tests-emptydir-259q2 deletion completed in 6.15120136s

[32mâ€¢ [SLOW TEST:8.377 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:31:22.297: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:31:22.465: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ce9b43d-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-cmvvc" to be "success or failure"
Sep  4 02:31:22.470: INFO: Pod "downwardapi-volume-9ce9b43d-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.83494ms
Sep  4 02:31:24.475: INFO: Pod "downwardapi-volume-9ce9b43d-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01011366s
[1mSTEP[0m: Saw pod success
Sep  4 02:31:24.476: INFO: Pod "downwardapi-volume-9ce9b43d-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:31:24.480: INFO: Trying to get logs from node node3 pod downwardapi-volume-9ce9b43d-afea-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:31:24.505: INFO: Waiting for pod downwardapi-volume-9ce9b43d-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:31:24.509: INFO: Pod downwardapi-volume-9ce9b43d-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:31:24.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-cmvvc" for this suite.
Sep  4 02:31:30.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:31:30.556: INFO: namespace: e2e-tests-downward-api-cmvvc, resource: bindings, ignored listing per whitelist
Sep  4 02:31:30.667: INFO: namespace e2e-tests-downward-api-cmvvc deletion completed in 6.15198744s

[32mâ€¢ [SLOW TEST:8.370 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should provide container's cpu limit [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:31:30.667: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-a1e7c093-afea-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:31:30.846: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a1e88123-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-79p8q" to be "success or failure"
Sep  4 02:31:30.850: INFO: Pod "pod-projected-configmaps-a1e88123-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.69414ms
Sep  4 02:31:32.856: INFO: Pod "pod-projected-configmaps-a1e88123-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01002186s
[1mSTEP[0m: Saw pod success
Sep  4 02:31:32.856: INFO: Pod "pod-projected-configmaps-a1e88123-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:31:32.860: INFO: Trying to get logs from node node3 pod pod-projected-configmaps-a1e88123-afea-11e8-8336-00073e906c7f container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:31:32.883: INFO: Waiting for pod pod-projected-configmaps-a1e88123-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:31:32.887: INFO: Pod pod-projected-configmaps-a1e88123-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:31:32.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-79p8q" for this suite.
Sep  4 02:31:38.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:31:38.984: INFO: namespace: e2e-tests-projected-79p8q, resource: bindings, ignored listing per whitelist
Sep  4 02:31:39.042: INFO: namespace e2e-tests-projected-79p8q deletion completed in 6.14965504s

[32mâ€¢ [SLOW TEST:8.375 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:31:39.042: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:31:39.218: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a6e5bd32-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-9znqp" to be "success or failure"
Sep  4 02:31:39.224: INFO: Pod "downwardapi-volume-a6e5bd32-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.94092ms
Sep  4 02:31:41.229: INFO: Pod "downwardapi-volume-a6e5bd32-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01107628s
[1mSTEP[0m: Saw pod success
Sep  4 02:31:41.229: INFO: Pod "downwardapi-volume-a6e5bd32-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:31:41.234: INFO: Trying to get logs from node node3 pod downwardapi-volume-a6e5bd32-afea-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:31:41.265: INFO: Waiting for pod downwardapi-volume-a6e5bd32-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:31:41.270: INFO: Pod downwardapi-volume-a6e5bd32-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:31:41.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-9znqp" for this suite.
Sep  4 02:31:47.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:31:47.306: INFO: namespace: e2e-tests-downward-api-9znqp, resource: bindings, ignored listing per whitelist
Sep  4 02:31:47.428: INFO: namespace e2e-tests-downward-api-9znqp deletion completed in 6.15310402s

[32mâ€¢ [SLOW TEST:8.386 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow composing env vars into new env vars [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Variable Expansion
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:31:47.429: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test env composition
Sep  4 02:31:47.607: INFO: Waiting up to 5m0s for pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-var-expansion-kt54n" to be "success or failure"
Sep  4 02:31:47.611: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.5097ms
Sep  4 02:31:49.617: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00967488s
Sep  4 02:31:51.622: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01470258s
Sep  4 02:31:53.627: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01966064s
Sep  4 02:31:55.631: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02462672s
Sep  4 02:31:57.637: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02969604s
Sep  4 02:31:59.642: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.03483154s
Sep  4 02:32:01.647: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.04031922s
[1mSTEP[0m: Saw pod success
Sep  4 02:32:01.647: INFO: Pod "var-expansion-abe62342-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:32:01.651: INFO: Trying to get logs from node node3 pod var-expansion-abe62342-afea-11e8-8336-00073e906c7f container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:32:01.677: INFO: Waiting for pod var-expansion-abe62342-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:32:01.681: INFO: Pod var-expansion-abe62342-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:32:01.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-kt54n" for this suite.
Sep  4 02:32:07.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:32:07.737: INFO: namespace: e2e-tests-var-expansion-kt54n, resource: bindings, ignored listing per whitelist
Sep  4 02:32:07.837: INFO: namespace e2e-tests-var-expansion-kt54n deletion completed in 6.15041592s

[32mâ€¢ [SLOW TEST:20.409 seconds][0m
[k8s.io] Variable Expansion
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0777,tmpfs) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:32:07.838: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0777 on tmpfs
Sep  4 02:32:08.011: INFO: Waiting up to 5m0s for pod "pod-b80f99b6-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-44twn" to be "success or failure"
Sep  4 02:32:08.016: INFO: Pod "pod-b80f99b6-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.43246ms
Sep  4 02:32:10.021: INFO: Pod "pod-b80f99b6-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00966886s
[1mSTEP[0m: Saw pod success
Sep  4 02:32:10.021: INFO: Pod "pod-b80f99b6-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:32:10.025: INFO: Trying to get logs from node node3 pod pod-b80f99b6-afea-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:32:10.049: INFO: Waiting for pod pod-b80f99b6-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:32:10.053: INFO: Pod pod-b80f99b6-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:32:10.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-44twn" for this suite.
Sep  4 02:32:16.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:32:16.216: INFO: namespace: e2e-tests-emptydir-44twn, resource: bindings, ignored listing per whitelist
Sep  4 02:32:16.220: INFO: namespace e2e-tests-emptydir-44twn deletion completed in 6.16186596s

[32mâ€¢ [SLOW TEST:8.382 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:32:16.220: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:32:16.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd0d904c-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-g6jt7" to be "success or failure"
Sep  4 02:32:16.392: INFO: Pod "downwardapi-volume-bd0d904c-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.29384ms
Sep  4 02:32:18.398: INFO: Pod "downwardapi-volume-bd0d904c-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01041702s
[1mSTEP[0m: Saw pod success
Sep  4 02:32:18.398: INFO: Pod "downwardapi-volume-bd0d904c-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:32:18.402: INFO: Trying to get logs from node node3 pod downwardapi-volume-bd0d904c-afea-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:32:18.426: INFO: Waiting for pod downwardapi-volume-bd0d904c-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:32:18.431: INFO: Pod downwardapi-volume-bd0d904c-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:32:18.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-g6jt7" for this suite.
Sep  4 02:32:24.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:32:24.483: INFO: namespace: e2e-tests-downward-api-g6jt7, resource: bindings, ignored listing per whitelist
Sep  4 02:32:24.585: INFO: namespace e2e-tests-downward-api-g6jt7 deletion completed in 6.14885114s

[32mâ€¢ [SLOW TEST:8.365 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should provide container's memory request [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0777,default) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:32:24.585: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0777 on node default medium
Sep  4 02:32:24.774: INFO: Waiting up to 5m0s for pod "pod-c20d64d4-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-b7kj7" to be "success or failure"
Sep  4 02:32:24.780: INFO: Pod "pod-c20d64d4-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.88266ms
Sep  4 02:32:26.785: INFO: Pod "pod-c20d64d4-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0107305s
[1mSTEP[0m: Saw pod success
Sep  4 02:32:26.785: INFO: Pod "pod-c20d64d4-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:32:26.789: INFO: Trying to get logs from node node3 pod pod-c20d64d4-afea-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:32:26.811: INFO: Waiting for pod pod-c20d64d4-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:32:26.816: INFO: Pod pod-c20d64d4-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:32:26.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-b7kj7" for this suite.
Sep  4 02:32:32.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:32:32.941: INFO: namespace: e2e-tests-emptydir-b7kj7, resource: bindings, ignored listing per whitelist
Sep  4 02:32:32.972: INFO: namespace e2e-tests-emptydir-b7kj7 deletion completed in 6.15097426s

[32mâ€¢ [SLOW TEST:8.387 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:32:32.973: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name secret-test-c709cc9d-afea-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:32:33.144: INFO: Waiting up to 5m0s for pod "pod-secrets-c70aa81c-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-secrets-7k5jq" to be "success or failure"
Sep  4 02:32:33.149: INFO: Pod "pod-secrets-c70aa81c-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.22892ms
Sep  4 02:32:35.153: INFO: Pod "pod-secrets-c70aa81c-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00897758s
[1mSTEP[0m: Saw pod success
Sep  4 02:32:35.153: INFO: Pod "pod-secrets-c70aa81c-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:32:35.158: INFO: Trying to get logs from node node3 pod pod-secrets-c70aa81c-afea-11e8-8336-00073e906c7f container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:32:35.181: INFO: Waiting for pod pod-secrets-c70aa81c-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:32:35.185: INFO: Pod pod-secrets-c70aa81c-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:32:35.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-7k5jq" for this suite.
Sep  4 02:32:41.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:32:41.254: INFO: namespace: e2e-tests-secrets-7k5jq, resource: bindings, ignored listing per whitelist
Sep  4 02:32:41.340: INFO: namespace e2e-tests-secrets-7k5jq deletion completed in 6.15007928s

[32mâ€¢ [SLOW TEST:8.368 seconds][0m
[sig-storage] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould contain environment variables for services [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:32:41.341: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 02:32:45.557: INFO: Waiting up to 5m0s for pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f" in namespace "e2e-tests-pods-4j28m" to be "success or failure"
Sep  4 02:32:45.566: INFO: Pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.49446ms
Sep  4 02:32:47.571: INFO: Pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01359354s
Sep  4 02:32:49.576: INFO: Pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01882184s
Sep  4 02:32:51.582: INFO: Pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0240061s
Sep  4 02:32:53.587: INFO: Pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02920426s
Sep  4 02:32:55.592: INFO: Pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.03438628s
Sep  4 02:32:57.597: INFO: Pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03961074s
[1mSTEP[0m: Saw pod success
Sep  4 02:32:57.597: INFO: Pod "client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:32:57.601: INFO: Trying to get logs from node node3 pod client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f container env3cont: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:32:57.626: INFO: Waiting for pod client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f to disappear
Sep  4 02:32:57.632: INFO: Pod client-envvars-ce704ff3-afea-11e8-8336-00073e906c7f no longer exists
[AfterEach] [k8s.io] Pods
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:32:57.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-4j28m" for this suite.
Sep  4 02:33:19.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:33:19.721: INFO: namespace: e2e-tests-pods-4j28m, resource: bindings, ignored listing per whitelist
Sep  4 02:33:19.788: INFO: namespace e2e-tests-pods-4j28m deletion completed in 22.15013286s

[32mâ€¢ [SLOW TEST:38.447 seconds][0m
[k8s.io] Pods
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should contain environment variables for services [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:33:19.788: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name s-test-opt-del-e2f368be-afea-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating secret with name s-test-opt-upd-e2f36948-afea-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-e2f368be-afea-11e8-8336-00073e906c7f
[1mSTEP[0m: Updating secret s-test-opt-upd-e2f36948-afea-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating secret with name s-test-opt-create-e2f36984-afea-11e8-8336-00073e906c7f
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:34:34.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-45hnj" for this suite.
Sep  4 02:34:56.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:34:56.680: INFO: namespace: e2e-tests-projected-45hnj, resource: bindings, ignored listing per whitelist
Sep  4 02:34:56.775: INFO: namespace e2e-tests-projected-45hnj deletion completed in 22.1493998s

[32mâ€¢ [SLOW TEST:96.987 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould use the image defaults if command and args are blank [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Docker Containers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:34:56.776: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test use defaults
Sep  4 02:34:56.949: INFO: Waiting up to 5m0s for pod "client-containers-1cc177b8-afeb-11e8-8336-00073e906c7f" in namespace "e2e-tests-containers-zzsh5" to be "success or failure"
Sep  4 02:34:56.954: INFO: Pod "client-containers-1cc177b8-afeb-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52518ms
Sep  4 02:34:58.959: INFO: Pod "client-containers-1cc177b8-afeb-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01008228s
[1mSTEP[0m: Saw pod success
Sep  4 02:34:58.960: INFO: Pod "client-containers-1cc177b8-afeb-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:34:58.964: INFO: Trying to get logs from node node3 pod client-containers-1cc177b8-afeb-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:34:58.991: INFO: Waiting for pod client-containers-1cc177b8-afeb-11e8-8336-00073e906c7f to disappear
Sep  4 02:34:58.996: INFO: Pod client-containers-1cc177b8-afeb-11e8-8336-00073e906c7f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:34:58.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-zzsh5" for this suite.
Sep  4 02:35:05.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:35:05.121: INFO: namespace: e2e-tests-containers-zzsh5, resource: bindings, ignored listing per whitelist
Sep  4 02:35:05.147: INFO: namespace e2e-tests-containers-zzsh5 deletion completed in 6.14618612s

[32mâ€¢ [SLOW TEST:8.372 seconds][0m
[k8s.io] Docker Containers
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl cluster-info[0m 
  [1mshould check if Kubernetes master services is included in cluster-info  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:35:05.148: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: validating cluster-info
Sep  4 02:35:05.305: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf cluster-info'
Sep  4 02:35:05.635: INFO: stderr: ""
Sep  4 02:35:05.635: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://192.168.2.117:6443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://192.168.2.117:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:35:05.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-kl5fp" for this suite.
Sep  4 02:35:11.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:35:11.743: INFO: namespace: e2e-tests-kubectl-kl5fp, resource: bindings, ignored listing per whitelist
Sep  4 02:35:11.793: INFO: namespace e2e-tests-kubectl-kl5fp deletion completed in 6.15261264s

[32mâ€¢ [SLOW TEST:6.646 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl cluster-info
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node using proxy subresource  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] version v1
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:35:11.794: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 02:35:11.981: INFO: (0) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 10.30462ms)
Sep  4 02:35:11.988: INFO: (1) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.9579ms)
Sep  4 02:35:11.995: INFO: (2) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.93636ms)
Sep  4 02:35:12.002: INFO: (3) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.7574ms)
Sep  4 02:35:12.008: INFO: (4) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.6773ms)
Sep  4 02:35:12.016: INFO: (5) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 7.68478ms)
Sep  4 02:35:12.024: INFO: (6) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 7.70828ms)
Sep  4 02:35:12.031: INFO: (7) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 7.12592ms)
Sep  4 02:35:12.038: INFO: (8) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.94664ms)
Sep  4 02:35:12.045: INFO: (9) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.85086ms)
Sep  4 02:35:12.052: INFO: (10) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.79138ms)
Sep  4 02:35:12.059: INFO: (11) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.76126ms)
Sep  4 02:35:12.066: INFO: (12) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.85992ms)
Sep  4 02:35:12.073: INFO: (13) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.78978ms)
Sep  4 02:35:12.079: INFO: (14) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.64596ms)
Sep  4 02:35:12.086: INFO: (15) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.7894ms)
Sep  4 02:35:12.093: INFO: (16) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.96852ms)
Sep  4 02:35:12.100: INFO: (17) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.89758ms)
Sep  4 02:35:12.107: INFO: (18) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.7756ms)
Sep  4 02:35:12.114: INFO: (19) /api/v1/nodes/node3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.94816ms)
[AfterEach] version v1
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:35:12.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-jwzxr" for this suite.
Sep  4 02:35:18.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:35:18.150: INFO: namespace: e2e-tests-proxy-jwzxr, resource: bindings, ignored listing per whitelist
Sep  4 02:35:18.271: INFO: namespace e2e-tests-proxy-jwzxr deletion completed in 6.15182776s

[32mâ€¢ [SLOW TEST:6.478 seconds][0m
[sig-network] Proxy
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy logs on node using proxy subresource  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Guestbook application[0m 
  [1mshould create and stop a working application  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:35:18.272: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating all guestbook components
Sep  4 02:35:18.432: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  4 02:35:18.432: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:18.920: INFO: stderr: ""
Sep  4 02:35:18.921: INFO: stdout: "service/redis-slave created\n"
Sep  4 02:35:18.921: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  4 02:35:18.921: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:19.427: INFO: stderr: ""
Sep  4 02:35:19.427: INFO: stdout: "service/redis-master created\n"
Sep  4 02:35:19.428: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  4 02:35:19.428: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:19.932: INFO: stderr: ""
Sep  4 02:35:19.932: INFO: stdout: "service/frontend created\n"
Sep  4 02:35:19.933: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend-arm64:v5
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  4 02:35:19.933: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:20.428: INFO: stderr: ""
Sep  4 02:35:20.428: INFO: stdout: "deployment.extensions/frontend created\n"
Sep  4 02:35:20.429: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  4 02:35:20.429: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:20.933: INFO: stderr: ""
Sep  4 02:35:20.933: INFO: stdout: "deployment.extensions/redis-master created\n"
Sep  4 02:35:20.934: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave-arm64:v2
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  4 02:35:20.934: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:21.465: INFO: stderr: ""
Sep  4 02:35:21.465: INFO: stdout: "deployment.extensions/redis-slave created\n"
[1mSTEP[0m: validating guestbook app
Sep  4 02:35:21.465: INFO: Waiting for all frontend pods to be Running.
Sep  4 02:35:26.516: INFO: Waiting for frontend to serve content.
Sep  4 02:35:26.552: INFO: Trying to add a new entry to the guestbook.
Sep  4 02:35:26.575: INFO: Verifying that added entry can be retrieved.
Sep  4 02:35:26.592: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:35:31.613: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:31.964: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:35:31.964: INFO: stdout: "service \"redis-slave\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:35:31.964: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:32.322: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:35:32.322: INFO: stdout: "service \"redis-master\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:35:32.323: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:32.684: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:35:32.684: INFO: stdout: "service \"frontend\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:35:32.685: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:33.022: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:35:33.022: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:35:33.022: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:33.387: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:35:33.387: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:35:33.387: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ddgvd'
Sep  4 02:35:33.730: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:35:33.730: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:35:33.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-ddgvd" for this suite.
Sep  4 02:36:11.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:36:11.805: INFO: namespace: e2e-tests-kubectl-ddgvd, resource: bindings, ignored listing per whitelist
Sep  4 02:36:11.897: INFO: namespace e2e-tests-kubectl-ddgvd deletion completed in 38.15920174s

[32mâ€¢ [SLOW TEST:53.626 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Guestbook application
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create and stop a working application  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:36:11.898: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-7pvwc
Sep  4 02:36:14.091: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-7pvwc
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Sep  4 02:36:14.095: INFO: Initial restart count of pod liveness-http is 0
Sep  4 02:36:38.159: INFO: Restart count of pod e2e-tests-container-probe-7pvwc/liveness-http is now 1 (24.06352026s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:36:38.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-7pvwc" for this suite.
Sep  4 02:36:44.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:36:44.281: INFO: namespace: e2e-tests-container-probe-7pvwc, resource: bindings, ignored listing per whitelist
Sep  4 02:36:44.327: INFO: namespace e2e-tests-container-probe-7pvwc deletion completed in 6.14973254s

[32mâ€¢ [SLOW TEST:32.430 seconds][0m
[k8s.io] Probing container
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:36:44.328: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name projected-secret-test-5cddf1ff-afeb-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:36:44.515: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5cdeb5e2-afeb-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-cw4nn" to be "success or failure"
Sep  4 02:36:44.520: INFO: Pod "pod-projected-secrets-5cdeb5e2-afeb-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.81928ms
Sep  4 02:36:46.525: INFO: Pod "pod-projected-secrets-5cdeb5e2-afeb-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01011594s
[1mSTEP[0m: Saw pod success
Sep  4 02:36:46.525: INFO: Pod "pod-projected-secrets-5cdeb5e2-afeb-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:36:46.529: INFO: Trying to get logs from node node3 pod pod-projected-secrets-5cdeb5e2-afeb-11e8-8336-00073e906c7f container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:36:46.553: INFO: Waiting for pod pod-projected-secrets-5cdeb5e2-afeb-11e8-8336-00073e906c7f to disappear
Sep  4 02:36:46.557: INFO: Pod pod-projected-secrets-5cdeb5e2-afeb-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:36:46.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-cw4nn" for this suite.
Sep  4 02:36:52.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:36:52.631: INFO: namespace: e2e-tests-projected-cw4nn, resource: bindings, ignored listing per whitelist
Sep  4 02:36:52.747: INFO: namespace e2e-tests-projected-cw4nn deletion completed in 6.16616352s

[32mâ€¢ [SLOW TEST:8.419 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates that NodeSelector is respected if matching  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:36:52.748: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Sep  4 02:36:52.908: INFO: Waiting up to 1m0s for all nodes to be ready
Sep  4 02:37:52.940: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 02:37:52.949: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  4 02:37:52.972: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  4 02:37:52.972: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Sep  4 02:37:52.979: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Sep  4 02:37:52.979: INFO: 
Logging pods the kubelet thinks is on node node3 before test
Sep  4 02:37:52.996: INFO: coredns-78fcdf6894-vlxkz from kube-system started at 2018-09-01 03:57:03 +0000 UTC (1 container statuses recorded)
Sep  4 02:37:52.996: INFO: 	Container coredns ready: true, restart count 1
Sep  4 02:37:52.996: INFO: kube-proxy-d6xgq from kube-system started at 2018-09-01 03:55:38 +0000 UTC (1 container statuses recorded)
Sep  4 02:37:52.996: INFO: 	Container kube-proxy ready: true, restart count 1
Sep  4 02:37:52.996: INFO: kube-apiserver-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 02:37:52.996: INFO: kube-controller-manager-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 02:37:52.996: INFO: kube-scheduler-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 02:37:52.996: INFO: etcd-node3 from kube-system started at <nil> (0 container statuses recorded)
Sep  4 02:37:52.996: INFO: weave-net-qrwm8 from kube-system started at 2018-09-01 03:55:38 +0000 UTC (2 container statuses recorded)
Sep  4 02:37:52.996: INFO: 	Container weave ready: true, restart count 2
Sep  4 02:37:52.996: INFO: 	Container weave-npc ready: true, restart count 1
Sep  4 02:37:52.997: INFO: coredns-78fcdf6894-f55jj from kube-system started at 2018-09-01 03:57:03 +0000 UTC (1 container statuses recorded)
Sep  4 02:37:52.997: INFO: 	Container coredns ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Trying to launch a pod without a label to get a node which can launch it.
[1mSTEP[0m: Explicitly delete pod here to free the resource it takes.
[1mSTEP[0m: Trying to apply a random label on the found node.
[1mSTEP[0m: verifying the node has the label kubernetes.io/e2e-8819489e-afeb-11e8-8336-00073e906c7f 42
[1mSTEP[0m: Trying to relaunch the pod, now with labels.
[1mSTEP[0m: removing the label kubernetes.io/e2e-8819489e-afeb-11e8-8336-00073e906c7f off the node node3
[1mSTEP[0m: verifying the node doesn't have the label kubernetes.io/e2e-8819489e-afeb-11e8-8336-00073e906c7f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:37:59.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-kthf9" for this suite.
Sep  4 02:38:29.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:38:29.206: INFO: namespace: e2e-tests-sched-pred-kthf9, resource: bindings, ignored listing per whitelist
Sep  4 02:38:29.246: INFO: namespace e2e-tests-sched-pred-kthf9 deletion completed in 30.15338502s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

[32mâ€¢ [SLOW TEST:96.498 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates that NodeSelector is respected if matching  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy through a service and a pod  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] version v1
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:38:29.246: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: starting an echo server on multiple ports
[1mSTEP[0m: creating replication controller proxy-service-976t4 in namespace e2e-tests-proxy-spfwm
I0904 02:38:29.430644   10499 runners.go:177] Created replication controller with name: proxy-service-976t4, namespace: e2e-tests-proxy-spfwm, replica count: 1
I0904 02:38:30.481105   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 02:38:31.481325   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 02:38:32.481533   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 02:38:33.481748   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 02:38:34.481931   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 02:38:35.482168   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 02:38:36.482379   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 02:38:37.482613   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 02:38:38.482854   10499 runners.go:177] proxy-service-976t4 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  4 02:38:38.487: INFO: setup took 9.074852s, starting test cases
[1mSTEP[0m: running 16 cases, 20 attempts per case, 320 total attempts
Sep  4 02:38:38.498: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 11.4609ms)
Sep  4 02:38:38.499: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 11.71094ms)
Sep  4 02:38:38.499: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 12.23102ms)
Sep  4 02:38:38.499: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.23134ms)
Sep  4 02:38:38.500: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 12.90634ms)
Sep  4 02:38:38.500: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 12.94396ms)
Sep  4 02:38:38.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 14.29338ms)
Sep  4 02:38:38.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 14.60152ms)
Sep  4 02:38:38.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 14.4926ms)
Sep  4 02:38:38.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 14.60858ms)
Sep  4 02:38:38.502: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 14.4181ms)
Sep  4 02:38:38.576: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 88.70424ms)
Sep  4 02:38:38.577: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 90.26684ms)
Sep  4 02:38:38.578: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 91.1612ms)
Sep  4 02:38:38.579: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 92.04446ms)
Sep  4 02:38:38.579: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 92.38234ms)
Sep  4 02:38:38.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 7.88876ms)
Sep  4 02:38:38.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 8.23646ms)
Sep  4 02:38:38.592: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 12.22992ms)
Sep  4 02:38:38.593: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 12.42144ms)
Sep  4 02:38:38.593: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 12.43174ms)
Sep  4 02:38:38.593: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 11.81816ms)
Sep  4 02:38:38.593: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 12.77832ms)
Sep  4 02:38:38.594: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.15238ms)
Sep  4 02:38:38.594: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 12.30554ms)
Sep  4 02:38:38.594: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.76102ms)
Sep  4 02:38:38.594: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 13.60522ms)
Sep  4 02:38:38.594: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 12.78036ms)
Sep  4 02:38:38.594: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 13.30288ms)
Sep  4 02:38:38.594: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 13.80302ms)
Sep  4 02:38:38.595: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 14.10334ms)
Sep  4 02:38:38.595: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 13.95052ms)
Sep  4 02:38:38.605: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 10.33418ms)
Sep  4 02:38:38.605: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 10.57476ms)
Sep  4 02:38:38.606: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 10.82822ms)
Sep  4 02:38:38.606: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 10.65552ms)
Sep  4 02:38:38.606: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 11.24506ms)
Sep  4 02:38:38.606: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 10.9735ms)
Sep  4 02:38:38.607: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 11.6993ms)
Sep  4 02:38:38.607: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 11.85324ms)
Sep  4 02:38:38.607: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 11.93066ms)
Sep  4 02:38:38.607: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 11.93424ms)
Sep  4 02:38:38.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 12.61108ms)
Sep  4 02:38:38.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.7782ms)
Sep  4 02:38:38.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 12.54922ms)
Sep  4 02:38:38.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 12.58614ms)
Sep  4 02:38:38.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 13.33336ms)
Sep  4 02:38:38.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 13.48666ms)
Sep  4 02:38:38.615: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 6.1201ms)
Sep  4 02:38:38.620: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 9.46458ms)
Sep  4 02:38:38.620: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 10.35236ms)
Sep  4 02:38:38.620: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 10.81558ms)
Sep  4 02:38:38.620: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 10.74586ms)
Sep  4 02:38:38.621: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 10.1248ms)
Sep  4 02:38:38.622: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 12.22274ms)
Sep  4 02:38:38.622: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 12.20252ms)
Sep  4 02:38:38.623: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 13.62734ms)
Sep  4 02:38:38.623: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 12.67042ms)
Sep  4 02:38:38.623: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.83566ms)
Sep  4 02:38:38.623: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 13.94142ms)
Sep  4 02:38:38.623: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 13.3811ms)
Sep  4 02:38:38.623: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 13.21144ms)
Sep  4 02:38:38.623: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 13.60164ms)
Sep  4 02:38:38.623: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 13.53222ms)
Sep  4 02:38:38.631: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 7.48696ms)
Sep  4 02:38:38.635: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 11.26392ms)
Sep  4 02:38:38.635: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 11.46344ms)
Sep  4 02:38:38.635: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 11.55186ms)
Sep  4 02:38:38.635: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 11.32972ms)
Sep  4 02:38:38.635: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 11.79072ms)
Sep  4 02:38:38.635: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 11.48516ms)
Sep  4 02:38:38.636: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 11.72112ms)
Sep  4 02:38:38.636: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 11.86288ms)
Sep  4 02:38:38.636: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 12.7828ms)
Sep  4 02:38:38.639: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 15.54102ms)
Sep  4 02:38:38.639: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 15.10324ms)
Sep  4 02:38:38.639: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 15.29868ms)
Sep  4 02:38:38.639: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 15.46018ms)
Sep  4 02:38:38.639: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 15.57714ms)
Sep  4 02:38:38.639: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 15.62376ms)
Sep  4 02:38:38.648: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 8.36832ms)
Sep  4 02:38:38.649: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 9.01862ms)
Sep  4 02:38:38.650: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 10.32876ms)
Sep  4 02:38:38.651: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 10.4263ms)
Sep  4 02:38:38.651: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 10.44558ms)
Sep  4 02:38:38.652: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.4686ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 12.1453ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 12.158ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 12.34026ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 12.88518ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 13.05258ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 13.38134ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.8091ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 12.9986ms)
Sep  4 02:38:38.653: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 12.69824ms)
Sep  4 02:38:38.654: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 14.12526ms)
Sep  4 02:38:38.664: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 8.9554ms)
Sep  4 02:38:38.664: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 9.62008ms)
Sep  4 02:38:38.664: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 9.798ms)
Sep  4 02:38:38.664: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 9.6716ms)
Sep  4 02:38:38.664: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 9.79066ms)
Sep  4 02:38:38.665: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 10.22824ms)
Sep  4 02:38:38.665: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 10.63994ms)
Sep  4 02:38:38.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 11.106ms)
Sep  4 02:38:38.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 11.73372ms)
Sep  4 02:38:38.667: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 12.34448ms)
Sep  4 02:38:38.667: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 12.80332ms)
Sep  4 02:38:38.668: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 12.90376ms)
Sep  4 02:38:38.668: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 13.2905ms)
Sep  4 02:38:38.668: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 13.37496ms)
Sep  4 02:38:38.668: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 13.71854ms)
Sep  4 02:38:38.668: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 13.63032ms)
Sep  4 02:38:38.676: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 7.59328ms)
Sep  4 02:38:38.676: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 7.43126ms)
Sep  4 02:38:38.677: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 8.95584ms)
Sep  4 02:38:38.677: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 9.04522ms)
Sep  4 02:38:38.678: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 9.58906ms)
Sep  4 02:38:38.679: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 10.94744ms)
Sep  4 02:38:38.679: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 11.08248ms)
Sep  4 02:38:38.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 11.22212ms)
Sep  4 02:38:38.679: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 11.03462ms)
Sep  4 02:38:38.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 11.11856ms)
Sep  4 02:38:38.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 11.2257ms)
Sep  4 02:38:38.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 11.30058ms)
Sep  4 02:38:38.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 11.17134ms)
Sep  4 02:38:38.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 11.38342ms)
Sep  4 02:38:38.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 11.44842ms)
Sep  4 02:38:38.679: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 11.07414ms)
Sep  4 02:38:38.686: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 5.97652ms)
Sep  4 02:38:38.686: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 6.00532ms)
Sep  4 02:38:38.691: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 10.6195ms)
Sep  4 02:38:38.692: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.20782ms)
Sep  4 02:38:38.692: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.1142ms)
Sep  4 02:38:38.692: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 12.25148ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 13.6942ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 13.54204ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 13.60352ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 13.84946ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 13.8255ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 13.8259ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 13.85876ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 14.00672ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 14.03566ms)
Sep  4 02:38:38.694: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 14.33568ms)
Sep  4 02:38:38.704: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 9.45338ms)
Sep  4 02:38:38.704: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 9.47602ms)
Sep  4 02:38:38.704: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 9.51638ms)
Sep  4 02:38:38.704: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 9.60592ms)
Sep  4 02:38:38.704: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 9.59892ms)
Sep  4 02:38:38.704: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 9.4966ms)
Sep  4 02:38:38.705: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 10.5211ms)
Sep  4 02:38:38.705: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 10.75296ms)
Sep  4 02:38:38.705: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 10.61544ms)
Sep  4 02:38:38.705: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 10.74074ms)
Sep  4 02:38:38.705: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 10.80106ms)
Sep  4 02:38:38.705: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 10.83074ms)
Sep  4 02:38:38.706: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 11.01012ms)
Sep  4 02:38:38.706: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 10.8877ms)
Sep  4 02:38:38.706: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 11.01046ms)
Sep  4 02:38:38.706: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 10.99548ms)
Sep  4 02:38:38.712: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 6.09332ms)
Sep  4 02:38:38.713: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 7.08698ms)
Sep  4 02:38:38.714: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 6.72266ms)
Sep  4 02:38:38.719: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 12.23616ms)
Sep  4 02:38:38.719: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 12.80312ms)
Sep  4 02:38:38.719: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 11.689ms)
Sep  4 02:38:38.719: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 11.85552ms)
Sep  4 02:38:38.719: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 12.16824ms)
Sep  4 02:38:38.719: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.4919ms)
Sep  4 02:38:38.720: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 13.25886ms)
Sep  4 02:38:38.720: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 12.57822ms)
Sep  4 02:38:38.720: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 13.00028ms)
Sep  4 02:38:38.720: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 12.81512ms)
Sep  4 02:38:38.720: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 14.49446ms)
Sep  4 02:38:38.721: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 13.93764ms)
Sep  4 02:38:38.721: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 14.47212ms)
Sep  4 02:38:38.733: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 12.66694ms)
Sep  4 02:38:38.733: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.47618ms)
Sep  4 02:38:38.733: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 12.60492ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 12.77192ms)
Sep  4 02:38:38.733: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 12.7469ms)
Sep  4 02:38:38.733: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 12.62324ms)
Sep  4 02:38:38.733: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 12.83484ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.67342ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 12.77184ms)
Sep  4 02:38:38.733: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.57022ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 12.90954ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 13.3309ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 13.3863ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 13.3009ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 13.4825ms)
Sep  4 02:38:38.734: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 13.49456ms)
Sep  4 02:38:38.746: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 11.71784ms)
Sep  4 02:38:38.746: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 11.9093ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 12.29336ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.42588ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 12.3388ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 12.45858ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 12.4832ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.70144ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 12.57664ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 12.7087ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 12.42212ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 12.72164ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 12.42738ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 12.52672ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 12.73226ms)
Sep  4 02:38:38.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 12.95376ms)
Sep  4 02:38:38.756: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 8.25834ms)
Sep  4 02:38:38.757: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 9.5275ms)
Sep  4 02:38:38.758: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 10.14432ms)
Sep  4 02:38:38.758: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 10.0178ms)
Sep  4 02:38:38.758: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 9.91852ms)
Sep  4 02:38:38.758: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 10.2827ms)
Sep  4 02:38:38.758: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 10.03192ms)
Sep  4 02:38:38.758: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 9.91866ms)
Sep  4 02:38:38.759: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 10.97988ms)
Sep  4 02:38:38.759: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 10.82466ms)
Sep  4 02:38:38.759: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 11.01772ms)
Sep  4 02:38:38.759: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 11.24524ms)
Sep  4 02:38:38.759: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 11.1548ms)
Sep  4 02:38:38.759: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 11.16888ms)
Sep  4 02:38:38.759: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 11.106ms)
Sep  4 02:38:38.759: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 11.22642ms)
Sep  4 02:38:38.765: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 6.204ms)
Sep  4 02:38:38.769: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 9.52272ms)
Sep  4 02:38:38.769: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 9.71444ms)
Sep  4 02:38:38.769: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 9.65928ms)
Sep  4 02:38:38.770: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 9.95104ms)
Sep  4 02:38:38.771: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 11.399ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 12.19982ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 12.00452ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 11.7513ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 12.13354ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 11.59004ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 11.73638ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.6045ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 11.71324ms)
Sep  4 02:38:38.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 12.50788ms)
Sep  4 02:38:38.773: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 13.26718ms)
Sep  4 02:38:38.779: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 6.46282ms)
Sep  4 02:38:38.779: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 6.66848ms)
Sep  4 02:38:38.779: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 6.70984ms)
Sep  4 02:38:38.784: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 10.73338ms)
Sep  4 02:38:38.784: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 10.77122ms)
Sep  4 02:38:38.784: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 10.7326ms)
Sep  4 02:38:38.784: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 11.13524ms)
Sep  4 02:38:38.784: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 11.0743ms)
Sep  4 02:38:38.786: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 13.23712ms)
Sep  4 02:38:38.786: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 13.49022ms)
Sep  4 02:38:38.786: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 13.49588ms)
Sep  4 02:38:38.786: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 13.4794ms)
Sep  4 02:38:38.786: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 13.4122ms)
Sep  4 02:38:38.786: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 13.5283ms)
Sep  4 02:38:38.789: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 16.562ms)
Sep  4 02:38:38.805: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 32.09142ms)
Sep  4 02:38:38.822: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 15.79268ms)
Sep  4 02:38:38.822: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 17.32408ms)
Sep  4 02:38:38.826: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 20.89132ms)
Sep  4 02:38:38.828: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 21.05388ms)
Sep  4 02:38:38.828: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 22.24764ms)
Sep  4 02:38:38.829: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 21.81492ms)
Sep  4 02:38:38.829: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 22.4739ms)
Sep  4 02:38:38.829: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 22.70498ms)
Sep  4 02:38:38.829: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 23.05906ms)
Sep  4 02:38:38.829: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 23.43422ms)
Sep  4 02:38:38.829: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 22.0526ms)
Sep  4 02:38:38.833: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 26.17918ms)
Sep  4 02:38:38.833: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 26.06196ms)
Sep  4 02:38:38.834: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 27.0091ms)
Sep  4 02:38:38.834: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 27.04996ms)
Sep  4 02:38:38.834: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 28.8033ms)
Sep  4 02:38:38.842: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 6.70698ms)
Sep  4 02:38:38.842: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 6.77332ms)
Sep  4 02:38:38.842: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 6.6787ms)
Sep  4 02:38:38.843: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 8.58416ms)
Sep  4 02:38:38.843: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 8.1067ms)
Sep  4 02:38:38.844: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 8.59678ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 9.42538ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 9.43972ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 9.3767ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 10.19134ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 10.08928ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 10.19276ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 10.63042ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 10.2728ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 10.69524ms)
Sep  4 02:38:38.845: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 9.94054ms)
Sep  4 02:38:38.866: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 19.70734ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 20.64656ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 20.81376ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 21.4102ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 21.09564ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 21.7155ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 22.79186ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 22.50322ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 21.98696ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 21.64846ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 21.90854ms)
Sep  4 02:38:38.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 22.19714ms)
Sep  4 02:38:38.869: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 21.7907ms)
Sep  4 02:38:38.869: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 22.06768ms)
Sep  4 02:38:38.869: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 23.31068ms)
Sep  4 02:38:38.870: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 23.79284ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:1080/proxy/... (200; 8.87652ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:162/proxy/: bar (200; 8.88602ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:1080/proxy/rewri... (200; 8.51236ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw/proxy/rewriteme"... (200; 9.00132ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/proxy-service-976t4-xmszw:160/proxy/: foo (200; 8.7783ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:460/proxy/: tls baz (200; 8.68356ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:462/proxy/: tls qux (200; 8.94692ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:160/proxy/: foo (200; 8.71428ms)
Sep  4 02:38:38.879: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/http:proxy-service-976t4-xmszw:162/proxy/: bar (200; 9.14476ms)
Sep  4 02:38:38.880: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-spfwm/pods/https:proxy-service-976t4-xmszw:443/proxy/... (200; 9.49718ms)
Sep  4 02:38:38.882: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname1/proxy/: foo (200; 12.05992ms)
Sep  4 02:38:38.883: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname2/proxy/: tls qux (200; 12.63264ms)
Sep  4 02:38:38.883: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname2/proxy/: bar (200; 12.65246ms)
Sep  4 02:38:38.883: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/https:proxy-service-976t4:tlsportname1/proxy/: tls baz (200; 12.81678ms)
Sep  4 02:38:38.883: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/http:proxy-service-976t4:portname2/proxy/: bar (200; 12.44778ms)
Sep  4 02:38:38.883: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-spfwm/services/proxy-service-976t4:portname1/proxy/: foo (200; 12.64184ms)
[1mSTEP[0m: deleting { ReplicationController} proxy-service-976t4 in namespace e2e-tests-proxy-spfwm, will wait for the garbage collector to delete the pods
Sep  4 02:38:38.945: INFO: Deleting { ReplicationController} proxy-service-976t4 took: 7.64458ms
Sep  4 02:38:39.045: INFO: Terminating { ReplicationController} proxy-service-976t4 pods took: 100.24454ms
[AfterEach] version v1
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:38:40.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-spfwm" for this suite.
Sep  4 02:38:46.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:38:46.532: INFO: namespace: e2e-tests-proxy-spfwm, resource: bindings, ignored listing per whitelist
Sep  4 02:38:46.603: INFO: namespace e2e-tests-proxy-spfwm deletion completed in 6.1513833s

[32mâ€¢ [SLOW TEST:17.357 seconds][0m
[sig-network] Proxy
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy through a service and a pod  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl patch[0m 
  [1mshould add annotations for pods in rc  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:38:46.603: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating Redis RC
Sep  4 02:38:46.766: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-qljgx'
Sep  4 02:38:47.258: INFO: stderr: ""
Sep  4 02:38:47.259: INFO: stdout: "replicationcontroller/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
Sep  4 02:38:48.265: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:38:48.265: INFO: Found 0 / 1
Sep  4 02:38:49.264: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:38:49.264: INFO: Found 1 / 1
Sep  4 02:38:49.264: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
[1mSTEP[0m: patching all pods
Sep  4 02:38:49.269: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:38:49.269: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 02:38:49.269: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf patch pod redis-master-87mq7 --namespace=e2e-tests-kubectl-qljgx -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  4 02:38:49.606: INFO: stderr: ""
Sep  4 02:38:49.606: INFO: stdout: "pod/redis-master-87mq7 patched\n"
[1mSTEP[0m: checking annotations
Sep  4 02:38:49.611: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:38:49.611: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:38:49.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-qljgx" for this suite.
Sep  4 02:39:11.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:39:11.653: INFO: namespace: e2e-tests-kubectl-qljgx, resource: bindings, ignored listing per whitelist
Sep  4 02:39:11.768: INFO: namespace e2e-tests-kubectl-qljgx deletion completed in 22.15075012s

[32mâ€¢ [SLOW TEST:25.164 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl patch
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should add annotations for pods in rc  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:39:11.768: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-b4bf0ec7-afeb-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:39:11.953: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b4bfdb35-afeb-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-6cz49" to be "success or failure"
Sep  4 02:39:11.957: INFO: Pod "pod-projected-configmaps-b4bfdb35-afeb-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.56224ms
Sep  4 02:39:13.962: INFO: Pod "pod-projected-configmaps-b4bfdb35-afeb-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00954854s
[1mSTEP[0m: Saw pod success
Sep  4 02:39:13.963: INFO: Pod "pod-projected-configmaps-b4bfdb35-afeb-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:39:13.967: INFO: Trying to get logs from node node3 pod pod-projected-configmaps-b4bfdb35-afeb-11e8-8336-00073e906c7f container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:39:13.990: INFO: Waiting for pod pod-projected-configmaps-b4bfdb35-afeb-11e8-8336-00073e906c7f to disappear
Sep  4 02:39:13.994: INFO: Pod pod-projected-configmaps-b4bfdb35-afeb-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:39:13.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-6cz49" for this suite.
Sep  4 02:39:20.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:39:20.136: INFO: namespace: e2e-tests-projected-6cz49, resource: bindings, ignored listing per whitelist
Sep  4 02:39:20.152: INFO: namespace e2e-tests-projected-6cz49 deletion completed in 6.15210042s

[32mâ€¢ [SLOW TEST:8.384 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] KubeletManagedEtcHosts[0m 
  [1mshould test kubelet managed /etc/hosts file [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:39:20.152: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Setting up the test
[1mSTEP[0m: Creating hostNetwork=false pod
[1mSTEP[0m: Creating hostNetwork=true pod
[1mSTEP[0m: Running the test
[1mSTEP[0m: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  4 02:39:26.359: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:26.359: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:26.714: INFO: Exec stderr: ""
Sep  4 02:39:26.714: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:26.714: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:27.073: INFO: Exec stderr: ""
Sep  4 02:39:27.073: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:27.073: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:27.437: INFO: Exec stderr: ""
Sep  4 02:39:27.437: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:27.437: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:27.806: INFO: Exec stderr: ""
[1mSTEP[0m: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  4 02:39:27.806: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:27.806: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:28.146: INFO: Exec stderr: ""
Sep  4 02:39:28.146: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:28.146: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:28.520: INFO: Exec stderr: ""
[1mSTEP[0m: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  4 02:39:28.520: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:28.520: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:28.868: INFO: Exec stderr: ""
Sep  4 02:39:28.868: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:28.868: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:29.224: INFO: Exec stderr: ""
Sep  4 02:39:29.224: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:29.224: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:29.578: INFO: Exec stderr: ""
Sep  4 02:39:29.578: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-b98xf PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:39:29.578: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:39:29.920: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:39:29.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-b98xf" for this suite.
Sep  4 02:40:21.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:40:22.005: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-b98xf, resource: bindings, ignored listing per whitelist
Sep  4 02:40:22.081: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-b98xf deletion completed in 52.15437352s

[32mâ€¢ [SLOW TEST:61.929 seconds][0m
[k8s.io] KubeletManagedEtcHosts
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould set DefaultMode on files [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:40:22.081: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:40:22.296: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dead4e7c-afeb-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-dpcrm" to be "success or failure"
Sep  4 02:40:22.300: INFO: Pod "downwardapi-volume-dead4e7c-afeb-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.60836ms
Sep  4 02:40:24.305: INFO: Pod "downwardapi-volume-dead4e7c-afeb-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00968868s
[1mSTEP[0m: Saw pod success
Sep  4 02:40:24.305: INFO: Pod "downwardapi-volume-dead4e7c-afeb-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:40:24.310: INFO: Trying to get logs from node node3 pod downwardapi-volume-dead4e7c-afeb-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:40:24.336: INFO: Waiting for pod downwardapi-volume-dead4e7c-afeb-11e8-8336-00073e906c7f to disappear
Sep  4 02:40:24.340: INFO: Pod downwardapi-volume-dead4e7c-afeb-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:40:24.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-dpcrm" for this suite.
Sep  4 02:40:30.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:40:30.441: INFO: namespace: e2e-tests-downward-api-dpcrm, resource: bindings, ignored listing per whitelist
Sep  4 02:40:30.501: INFO: namespace e2e-tests-downward-api-dpcrm deletion completed in 6.15576064s

[32mâ€¢ [SLOW TEST:8.420 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should set DefaultMode on files [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mvolume on default medium should have the correct mode [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:40:30.501: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir volume type on node default medium
Sep  4 02:40:30.670: INFO: Waiting up to 5m0s for pod "pod-e3ab2038-afeb-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-gwmqs" to be "success or failure"
Sep  4 02:40:30.675: INFO: Pod "pod-e3ab2038-afeb-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.4622ms
Sep  4 02:40:32.680: INFO: Pod "pod-e3ab2038-afeb-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0094113s
[1mSTEP[0m: Saw pod success
Sep  4 02:40:32.680: INFO: Pod "pod-e3ab2038-afeb-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:40:32.684: INFO: Trying to get logs from node node3 pod pod-e3ab2038-afeb-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:40:32.706: INFO: Waiting for pod pod-e3ab2038-afeb-11e8-8336-00073e906c7f to disappear
Sep  4 02:40:32.711: INFO: Pod pod-e3ab2038-afeb-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:40:32.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-gwmqs" for this suite.
Sep  4 02:40:38.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:40:38.814: INFO: namespace: e2e-tests-emptydir-gwmqs, resource: bindings, ignored listing per whitelist
Sep  4 02:40:38.863: INFO: namespace e2e-tests-emptydir-gwmqs deletion completed in 6.14750032s

[32mâ€¢ [SLOW TEST:8.362 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:40:38.864: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-test-volume-e8a7d35c-afeb-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:40:39.042: INFO: Waiting up to 5m0s for pod "pod-configmaps-e8a89a4b-afeb-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-77f95" to be "success or failure"
Sep  4 02:40:39.046: INFO: Pod "pod-configmaps-e8a89a4b-afeb-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.4465ms
Sep  4 02:40:41.051: INFO: Pod "pod-configmaps-e8a89a4b-afeb-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00954014s
[1mSTEP[0m: Saw pod success
Sep  4 02:40:41.051: INFO: Pod "pod-configmaps-e8a89a4b-afeb-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:40:41.056: INFO: Trying to get logs from node node3 pod pod-configmaps-e8a89a4b-afeb-11e8-8336-00073e906c7f container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:40:41.079: INFO: Waiting for pod pod-configmaps-e8a89a4b-afeb-11e8-8336-00073e906c7f to disappear
Sep  4 02:40:41.083: INFO: Pod pod-configmaps-e8a89a4b-afeb-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:40:41.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-77f95" for this suite.
Sep  4 02:40:47.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:40:47.179: INFO: namespace: e2e-tests-configmap-77f95, resource: bindings, ignored listing per whitelist
Sep  4 02:40:47.237: INFO: namespace e2e-tests-configmap-77f95 deletion completed in 6.14823622s

[32mâ€¢ [SLOW TEST:8.373 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:40:47.237: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:40:47.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eda46c3d-afeb-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-mfpg8" to be "success or failure"
Sep  4 02:40:47.408: INFO: Pod "downwardapi-volume-eda46c3d-afeb-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.61358ms
Sep  4 02:40:49.414: INFO: Pod "downwardapi-volume-eda46c3d-afeb-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01025346s
Sep  4 02:40:51.419: INFO: Pod "downwardapi-volume-eda46c3d-afeb-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01498992s
[1mSTEP[0m: Saw pod success
Sep  4 02:40:51.419: INFO: Pod "downwardapi-volume-eda46c3d-afeb-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:40:51.423: INFO: Trying to get logs from node node3 pod downwardapi-volume-eda46c3d-afeb-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:40:51.447: INFO: Waiting for pod downwardapi-volume-eda46c3d-afeb-11e8-8336-00073e906c7f to disappear
Sep  4 02:40:51.452: INFO: Pod downwardapi-volume-eda46c3d-afeb-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:40:51.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-mfpg8" for this suite.
Sep  4 02:40:57.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:40:57.494: INFO: namespace: e2e-tests-downward-api-mfpg8, resource: bindings, ignored listing per whitelist
Sep  4 02:40:57.608: INFO: namespace e2e-tests-downward-api-mfpg8 deletion completed in 6.15071034s

[32mâ€¢ [SLOW TEST:10.371 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should provide container's memory limit [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: udp [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] Networking
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:40:57.608: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-d9lqv
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Sep  4 02:40:57.773: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Sep  4 02:41:17.840: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.9:8080/dial?request=hostName&protocol=udp&host=10.32.0.8&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-d9lqv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:41:17.840: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:41:18.192: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:41:18.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-d9lqv" for this suite.
Sep  4 02:41:40.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:41:40.313: INFO: namespace: e2e-tests-pod-network-test-d9lqv, resource: bindings, ignored listing per whitelist
Sep  4 02:41:40.354: INFO: namespace e2e-tests-pod-network-test-d9lqv deletion completed in 22.1500589s

[32mâ€¢ [SLOW TEST:42.746 seconds][0m
[sig-network] Networking
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Pods Extended[0m [90m[k8s.io] Delete Grace Period[0m 
  [1mshould be submitted and removed  [Flaky] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:41:40.354: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed  [Flaky] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating the pod
[1mSTEP[0m: setting up watch
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: verifying pod creation was observed
Sep  4 02:41:42.551: INFO: Asynchronously running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf proxy -p 0'
[1mSTEP[0m: deleting the pod gracefully
[1mSTEP[0m: verifying the kubelet observed the termination notice
Sep  4 02:41:47.885: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[1mSTEP[0m: verifying pod deletion was observed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:41:47.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-t45tf" for this suite.
Sep  4 02:41:53.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:41:53.937: INFO: namespace: e2e-tests-pods-t45tf, resource: bindings, ignored listing per whitelist
Sep  4 02:41:54.046: INFO: namespace e2e-tests-pods-t45tf deletion completed in 6.14991552s

[32mâ€¢ [SLOW TEST:13.692 seconds][0m
[k8s.io] [sig-node] Pods Extended
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  [k8s.io] Delete Grace Period
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should be submitted and removed  [Flaky] [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:41:54.046: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
[1mSTEP[0m: Gathering metrics
W0904 02:42:24.755895   10499 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 02:42:24.755: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:42:24.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-dtvtd" for this suite.
Sep  4 02:42:30.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:42:30.872: INFO: namespace: e2e-tests-gc-dtvtd, resource: bindings, ignored listing per whitelist
Sep  4 02:42:30.914: INFO: namespace e2e-tests-gc-dtvtd deletion completed in 6.1528988s

[32mâ€¢ [SLOW TEST:36.867 seconds][0m
[sig-api-machinery] Garbage collector
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] CustomResourceDefinition resources[0m [90mSimple CustomResourceDefinition[0m 
  [1mcreating/deleting custom resource definition objects works  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:42:30.914: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 02:42:31.081: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:42:32.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-custom-resource-definition-kv4dr" for this suite.
Sep  4 02:42:38.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:42:38.358: INFO: namespace: e2e-tests-custom-resource-definition-kv4dr, resource: bindings, ignored listing per whitelist
Sep  4 02:42:38.440: INFO: namespace e2e-tests-custom-resource-definition-kv4dr deletion completed in 6.1542489s

[32mâ€¢ [SLOW TEST:7.526 seconds][0m
[sig-api-machinery] CustomResourceDefinition resources
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  Simple CustomResourceDefinition
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35[0m
    creating/deleting custom resource definition objects works  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:42:38.440: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-2fed4065-afec-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:42:38.616: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2fee09c8-afec-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-9gm88" to be "success or failure"
Sep  4 02:42:38.621: INFO: Pod "pod-projected-configmaps-2fee09c8-afec-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.16828ms
Sep  4 02:42:40.626: INFO: Pod "pod-projected-configmaps-2fee09c8-afec-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01037854s
[1mSTEP[0m: Saw pod success
Sep  4 02:42:40.626: INFO: Pod "pod-projected-configmaps-2fee09c8-afec-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:42:40.630: INFO: Trying to get logs from node node3 pod pod-projected-configmaps-2fee09c8-afec-11e8-8336-00073e906c7f container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:42:40.654: INFO: Waiting for pod pod-projected-configmaps-2fee09c8-afec-11e8-8336-00073e906c7f to disappear
Sep  4 02:42:40.659: INFO: Pod pod-projected-configmaps-2fee09c8-afec-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:42:40.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-9gm88" for this suite.
Sep  4 02:42:46.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:42:46.779: INFO: namespace: e2e-tests-projected-9gm88, resource: bindings, ignored listing per whitelist
Sep  4 02:42:46.826: INFO: namespace e2e-tests-projected-9gm88 deletion completed in 6.16086326s

[32mâ€¢ [SLOW TEST:8.386 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl logs[0m 
  [1mshould be able to retrieve and filter logs  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:42:46.826: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl logs
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
[1mSTEP[0m: creating an rc
Sep  4 02:42:46.992: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-wl2hl'
Sep  4 02:42:47.606: INFO: stderr: ""
Sep  4 02:42:47.606: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Waiting for Redis master to start.
Sep  4 02:42:48.612: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:42:48.612: INFO: Found 0 / 1
Sep  4 02:42:49.611: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:42:49.611: INFO: Found 1 / 1
Sep  4 02:42:49.611: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 02:42:49.616: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:42:49.616: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[1mSTEP[0m: checking for a matching strings
Sep  4 02:42:49.616: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf logs redis-master-82cxq redis-master --namespace=e2e-tests-kubectl-wl2hl'
Sep  4 02:42:49.976: INFO: stderr: ""
Sep  4 02:42:49.976: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 02:42:48.742 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 02:42:48.742 # Server started, Redis version 3.2.12\n1:M 04 Sep 02:42:48.742 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Sep 02:42:48.742 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: limiting log lines
Sep  4 02:42:49.976: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf log redis-master-82cxq redis-master --namespace=e2e-tests-kubectl-wl2hl --tail=1'
Sep  4 02:42:50.334: INFO: stderr: ""
Sep  4 02:42:50.334: INFO: stdout: "1:M 04 Sep 02:42:48.742 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: limiting log bytes
Sep  4 02:42:50.334: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf log redis-master-82cxq redis-master --namespace=e2e-tests-kubectl-wl2hl --limit-bytes=1'
Sep  4 02:42:50.744: INFO: stderr: ""
Sep  4 02:42:50.744: INFO: stdout: " "
[1mSTEP[0m: exposing timestamps
Sep  4 02:42:50.744: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf log redis-master-82cxq redis-master --namespace=e2e-tests-kubectl-wl2hl --tail=1 --timestamps'
Sep  4 02:42:51.118: INFO: stderr: ""
Sep  4 02:42:51.118: INFO: stdout: "2018-09-04T02:42:48.742943Z 1:M 04 Sep 02:42:48.742 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: restricting to a time range
Sep  4 02:42:53.618: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf log redis-master-82cxq redis-master --namespace=e2e-tests-kubectl-wl2hl --since=1s'
Sep  4 02:42:53.971: INFO: stderr: ""
Sep  4 02:42:53.971: INFO: stdout: ""
Sep  4 02:42:53.971: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf log redis-master-82cxq redis-master --namespace=e2e-tests-kubectl-wl2hl --since=24h'
Sep  4 02:42:54.331: INFO: stderr: ""
Sep  4 02:42:54.331: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 02:42:48.742 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 02:42:48.742 # Server started, Redis version 3.2.12\n1:M 04 Sep 02:42:48.742 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Sep 02:42:48.742 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1058
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:42:54.331: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wl2hl'
Sep  4 02:42:54.660: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:42:54.660: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  4 02:42:54.660: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-wl2hl'
Sep  4 02:42:55.012: INFO: stderr: "No resources found.\n"
Sep  4 02:42:55.012: INFO: stdout: ""
Sep  4 02:42:55.012: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -l name=nginx --namespace=e2e-tests-kubectl-wl2hl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 02:42:55.342: INFO: stderr: ""
Sep  4 02:42:55.342: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:42:55.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-wl2hl" for this suite.
Sep  4 02:43:17.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:43:17.381: INFO: namespace: e2e-tests-kubectl-wl2hl, resource: bindings, ignored listing per whitelist
Sep  4 02:43:17.498: INFO: namespace e2e-tests-kubectl-wl2hl deletion completed in 22.1502608s

[32mâ€¢ [SLOW TEST:30.672 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl logs
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should be able to retrieve and filter logs  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl expose[0m 
  [1mshould create services for rc  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:43:17.499: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating Redis RC
Sep  4 02:43:17.664: INFO: namespace e2e-tests-kubectl-hdt9q
Sep  4 02:43:17.664: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-hdt9q'
Sep  4 02:43:18.144: INFO: stderr: ""
Sep  4 02:43:18.144: INFO: stdout: "replicationcontroller/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
Sep  4 02:43:19.150: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:43:19.151: INFO: Found 0 / 1
Sep  4 02:43:20.149: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:43:20.149: INFO: Found 1 / 1
Sep  4 02:43:20.149: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 02:43:20.154: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 02:43:20.154: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 02:43:20.154: INFO: wait on redis-master startup in e2e-tests-kubectl-hdt9q 
Sep  4 02:43:20.154: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf logs redis-master-g5l7f redis-master --namespace=e2e-tests-kubectl-hdt9q'
Sep  4 02:43:20.514: INFO: stderr: ""
Sep  4 02:43:20.514: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 02:43:19.132 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 02:43:19.132 # Server started, Redis version 3.2.12\n1:M 04 Sep 02:43:19.132 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Sep 02:43:19.133 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: exposing RC
Sep  4 02:43:20.514: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-hdt9q'
Sep  4 02:43:20.877: INFO: stderr: ""
Sep  4 02:43:20.877: INFO: stdout: "service/rm2 exposed\n"
Sep  4 02:43:20.881: INFO: Service rm2 in namespace e2e-tests-kubectl-hdt9q found.
[1mSTEP[0m: exposing service
Sep  4 02:43:22.890: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-hdt9q'
Sep  4 02:43:23.247: INFO: stderr: ""
Sep  4 02:43:23.247: INFO: stdout: "service/rm3 exposed\n"
Sep  4 02:43:23.253: INFO: Service rm3 in namespace e2e-tests-kubectl-hdt9q found.
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:43:25.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-hdt9q" for this suite.
Sep  4 02:43:47.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:43:47.368: INFO: namespace: e2e-tests-kubectl-hdt9q, resource: bindings, ignored listing per whitelist
Sep  4 02:43:47.424: INFO: namespace e2e-tests-kubectl-hdt9q deletion completed in 22.15737802s

[32mâ€¢ [SLOW TEST:29.925 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl expose
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create services for rc  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0777,tmpfs) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:43:47.424: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0777 on tmpfs
Sep  4 02:43:47.596: INFO: Waiting up to 5m0s for pod "pod-590bda68-afec-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-c9p56" to be "success or failure"
Sep  4 02:43:47.601: INFO: Pod "pod-590bda68-afec-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.60588ms
Sep  4 02:43:49.606: INFO: Pod "pod-590bda68-afec-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00991602s
[1mSTEP[0m: Saw pod success
Sep  4 02:43:49.607: INFO: Pod "pod-590bda68-afec-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:43:49.611: INFO: Trying to get logs from node node3 pod pod-590bda68-afec-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:43:49.635: INFO: Waiting for pod pod-590bda68-afec-11e8-8336-00073e906c7f to disappear
Sep  4 02:43:49.639: INFO: Pod pod-590bda68-afec-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:43:49.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-c9p56" for this suite.
Sep  4 02:43:55.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:43:55.722: INFO: namespace: e2e-tests-emptydir-c9p56, resource: bindings, ignored listing per whitelist
Sep  4 02:43:55.794: INFO: namespace e2e-tests-emptydir-c9p56 deletion completed in 6.14936866s

[32mâ€¢ [SLOW TEST:8.370 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:43:55.794: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:43:55.960: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e07fe03-afec-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-rtzkx" to be "success or failure"
Sep  4 02:43:55.965: INFO: Pod "downwardapi-volume-5e07fe03-afec-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.4811ms
Sep  4 02:43:57.970: INFO: Pod "downwardapi-volume-5e07fe03-afec-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00965836s
[1mSTEP[0m: Saw pod success
Sep  4 02:43:57.970: INFO: Pod "downwardapi-volume-5e07fe03-afec-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:43:57.974: INFO: Trying to get logs from node node3 pod downwardapi-volume-5e07fe03-afec-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:43:57.998: INFO: Waiting for pod downwardapi-volume-5e07fe03-afec-11e8-8336-00073e906c7f to disappear
Sep  4 02:43:58.003: INFO: Pod downwardapi-volume-5e07fe03-afec-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:43:58.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-rtzkx" for this suite.
Sep  4 02:44:04.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:44:04.075: INFO: namespace: e2e-tests-projected-rtzkx, resource: bindings, ignored listing per whitelist
Sep  4 02:44:04.159: INFO: namespace e2e-tests-projected-rtzkx deletion completed in 6.15022426s

[32mâ€¢ [SLOW TEST:8.365 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] ReplicationController
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:44:04.159: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating replication controller my-hostname-basic-6305f2db-afec-11e8-8336-00073e906c7f
Sep  4 02:44:04.337: INFO: Pod name my-hostname-basic-6305f2db-afec-11e8-8336-00073e906c7f: Found 0 pods out of 1
Sep  4 02:44:09.343: INFO: Pod name my-hostname-basic-6305f2db-afec-11e8-8336-00073e906c7f: Found 1 pods out of 1
Sep  4 02:44:09.343: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6305f2db-afec-11e8-8336-00073e906c7f" are running
Sep  4 02:44:09.348: INFO: Pod "my-hostname-basic-6305f2db-afec-11e8-8336-00073e906c7f-thst8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-09-04 02:44:04 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-09-04 02:44:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-09-04 02:44:04 +0000 UTC Reason: Message:}])
Sep  4 02:44:09.348: INFO: Trying to dial the pod
Sep  4 02:44:14.364: INFO: Controller my-hostname-basic-6305f2db-afec-11e8-8336-00073e906c7f: Got expected result from replica 1 [my-hostname-basic-6305f2db-afec-11e8-8336-00073e906c7f-thst8]: "my-hostname-basic-6305f2db-afec-11e8-8336-00073e906c7f-thst8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:44:14.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replication-controller-j2nv7" for this suite.
Sep  4 02:44:20.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:44:20.503: INFO: namespace: e2e-tests-replication-controller-j2nv7, resource: bindings, ignored listing per whitelist
Sep  4 02:44:20.518: INFO: namespace e2e-tests-replication-controller-j2nv7 deletion completed in 6.14854878s

[32mâ€¢ [SLOW TEST:16.358 seconds][0m
[sig-apps] ReplicationController
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should serve a basic image on each replica with a public image  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:44:20.518: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: create the rc1
[1mSTEP[0m: create the rc2
[1mSTEP[0m: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
[1mSTEP[0m: delete the rc simpletest-rc-to-be-deleted
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
W0904 02:44:30.772629   10499 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 02:44:30.772: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:44:30.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-5rrlc" for this suite.
Sep  4 02:44:36.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:44:36.850: INFO: namespace: e2e-tests-gc-5rrlc, resource: bindings, ignored listing per whitelist
Sep  4 02:44:36.937: INFO: namespace e2e-tests-gc-5rrlc deletion completed in 6.1599962s

[32mâ€¢ [SLOW TEST:16.420 seconds][0m
[sig-api-machinery] Garbage collector
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:44:36.938: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
W0904 02:44:43.141286   10499 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 02:44:43.141: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:44:43.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-d564j" for this suite.
Sep  4 02:44:49.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:44:49.294: INFO: namespace: e2e-tests-gc-d564j, resource: bindings, ignored listing per whitelist
Sep  4 02:44:49.305: INFO: namespace e2e-tests-gc-d564j deletion completed in 6.15888652s

[32mâ€¢ [SLOW TEST:12.367 seconds][0m
[sig-api-machinery] Garbage collector
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:44:49.305: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-7dee67a2-afec-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 02:44:49.485: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7def48a7-afec-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-pv2wj" to be "success or failure"
Sep  4 02:44:49.490: INFO: Pod "pod-projected-secrets-7def48a7-afec-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.75416ms
Sep  4 02:44:51.495: INFO: Pod "pod-projected-secrets-7def48a7-afec-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00973956s
[1mSTEP[0m: Saw pod success
Sep  4 02:44:51.495: INFO: Pod "pod-projected-secrets-7def48a7-afec-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:44:51.500: INFO: Trying to get logs from node node3 pod pod-projected-secrets-7def48a7-afec-11e8-8336-00073e906c7f container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:44:51.528: INFO: Waiting for pod pod-projected-secrets-7def48a7-afec-11e8-8336-00073e906c7f to disappear
Sep  4 02:44:51.532: INFO: Pod pod-projected-secrets-7def48a7-afec-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:44:51.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-pv2wj" for this suite.
Sep  4 02:44:57.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:44:57.585: INFO: namespace: e2e-tests-projected-pv2wj, resource: bindings, ignored listing per whitelist
Sep  4 02:44:57.691: INFO: namespace e2e-tests-projected-pv2wj deletion completed in 6.15218884s

[32mâ€¢ [SLOW TEST:8.386 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run default[0m 
  [1mshould create an rc or deployment from an image  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:44:57.691: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run default
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1180
[It] should create an rc or deployment from an image  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: running the image k8s.gcr.io/nginx-slim-arm64:0.26
Sep  4 02:44:57.850: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-arm64:0.26 --namespace=e2e-tests-kubectl-vw4rr'
Sep  4 02:44:58.211: INFO: stderr: ""
Sep  4 02:44:58.211: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
[1mSTEP[0m: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1186
Sep  4 02:44:58.218: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-vw4rr'
Sep  4 02:44:58.563: INFO: stderr: ""
Sep  4 02:44:58.563: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:44:58.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-vw4rr" for this suite.
Sep  4 02:45:04.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:45:04.615: INFO: namespace: e2e-tests-kubectl-vw4rr, resource: bindings, ignored listing per whitelist
Sep  4 02:45:04.734: INFO: namespace e2e-tests-kubectl-vw4rr deletion completed in 6.16475112s

[32mâ€¢ [SLOW TEST:7.043 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run default
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create an rc or deployment from an image  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Proxy server[0m 
  [1mshould support proxy with --port 0  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:45:04.734: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: starting the proxy server
Sep  4 02:45:04.899: INFO: Asynchronously running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf proxy -p 0 --disable-filter'
[1mSTEP[0m: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:45:05.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-5wbnp" for this suite.
Sep  4 02:45:11.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:45:11.311: INFO: namespace: e2e-tests-kubectl-5wbnp, resource: bindings, ignored listing per whitelist
Sep  4 02:45:11.360: INFO: namespace e2e-tests-kubectl-5wbnp deletion completed in 6.14997478s

[32mâ€¢ [SLOW TEST:6.626 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Proxy server
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should support proxy with --port 0  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould do a rolling update of a replication controller  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:45:11.361: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should do a rolling update of a replication controller  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating the initial replication controller
Sep  4 02:45:11.521: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:11.994: INFO: stderr: ""
Sep  4 02:45:11.994: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Sep  4 02:45:11.994: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:12.339: INFO: stderr: ""
Sep  4 02:45:12.339: INFO: stdout: "update-demo-nautilus-fv759 update-demo-nautilus-lnnzk "
Sep  4 02:45:12.339: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-fv759 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:12.673: INFO: stderr: ""
Sep  4 02:45:12.673: INFO: stdout: ""
Sep  4 02:45:12.673: INFO: update-demo-nautilus-fv759 is created but not running
Sep  4 02:45:17.674: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:18.006: INFO: stderr: ""
Sep  4 02:45:18.006: INFO: stdout: "update-demo-nautilus-fv759 update-demo-nautilus-lnnzk "
Sep  4 02:45:18.006: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-fv759 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:18.333: INFO: stderr: ""
Sep  4 02:45:18.333: INFO: stdout: "true"
Sep  4 02:45:18.333: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-fv759 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:18.660: INFO: stderr: ""
Sep  4 02:45:18.660: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:45:18.660: INFO: validating pod update-demo-nautilus-fv759
Sep  4 02:45:18.673: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:45:18.673: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:45:18.673: INFO: update-demo-nautilus-fv759 is verified up and running
Sep  4 02:45:18.673: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-lnnzk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:19.000: INFO: stderr: ""
Sep  4 02:45:19.000: INFO: stdout: "true"
Sep  4 02:45:19.001: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-lnnzk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:19.324: INFO: stderr: ""
Sep  4 02:45:19.324: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:45:19.324: INFO: validating pod update-demo-nautilus-lnnzk
Sep  4 02:45:19.330: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:45:19.330: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:45:19.330: INFO: update-demo-nautilus-lnnzk is verified up and running
[1mSTEP[0m: rolling-update to new replication controller
Sep  4 02:45:19.331: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:42.115: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  4 02:45:42.115: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Sep  4 02:45:42.115: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:42.450: INFO: stderr: ""
Sep  4 02:45:42.451: INFO: stdout: "update-demo-kitten-54vns update-demo-kitten-clb9f "
Sep  4 02:45:42.451: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-kitten-54vns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:42.781: INFO: stderr: ""
Sep  4 02:45:42.781: INFO: stdout: "true"
Sep  4 02:45:42.781: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-kitten-54vns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:43.109: INFO: stderr: ""
Sep  4 02:45:43.109: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-arm64:1.0"
Sep  4 02:45:43.109: INFO: validating pod update-demo-kitten-54vns
Sep  4 02:45:43.117: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  4 02:45:43.117: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  4 02:45:43.117: INFO: update-demo-kitten-54vns is verified up and running
Sep  4 02:45:43.117: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-kitten-clb9f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:43.450: INFO: stderr: ""
Sep  4 02:45:43.450: INFO: stdout: "true"
Sep  4 02:45:43.450: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-kitten-clb9f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kbnq5'
Sep  4 02:45:43.780: INFO: stderr: ""
Sep  4 02:45:43.780: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-arm64:1.0"
Sep  4 02:45:43.780: INFO: validating pod update-demo-kitten-clb9f
Sep  4 02:45:43.787: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  4 02:45:43.787: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  4 02:45:43.787: INFO: update-demo-kitten-clb9f is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:45:43.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-kbnq5" for this suite.
Sep  4 02:46:05.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:46:05.908: INFO: namespace: e2e-tests-kubectl-kbnq5, resource: bindings, ignored listing per whitelist
Sep  4 02:46:05.949: INFO: namespace e2e-tests-kubectl-kbnq5 deletion completed in 22.15605538s

[32mâ€¢ [SLOW TEST:54.588 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should do a rolling update of a replication controller  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan pods created by rc if delete options say so [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:46:05.949: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
[1mSTEP[0m: Gathering metrics
W0904 02:46:46.152579   10499 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 02:46:46.152: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:46:46.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-4pgmp" for this suite.
Sep  4 02:46:52.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:46:52.301: INFO: namespace: e2e-tests-gc-4pgmp, resource: bindings, ignored listing per whitelist
Sep  4 02:46:52.351: INFO: namespace e2e-tests-gc-4pgmp deletion completed in 6.1934045s

[32mâ€¢ [SLOW TEST:46.402 seconds][0m
[sig-api-machinery] Garbage collector
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should orphan pods created by rc if delete options say so [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete RS created by deployment when not orphaning [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:46:52.351: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for all rs to be garbage collected
[1mSTEP[0m: expected 0 rs, got 1 rs
[1mSTEP[0m: expected 0 Pods, got 2 Pods
[1mSTEP[0m: Gathering metrics
W0904 02:46:53.588701   10499 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 02:46:53.588: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:46:53.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-6bprt" for this suite.
Sep  4 02:46:59.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:46:59.675: INFO: namespace: e2e-tests-gc-6bprt, resource: bindings, ignored listing per whitelist
Sep  4 02:46:59.743: INFO: namespace e2e-tests-gc-6bprt deletion completed in 6.14978322s

[32mâ€¢ [SLOW TEST:7.392 seconds][0m
[sig-api-machinery] Garbage collector
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should delete RS created by deployment when not orphaning [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:46:59.744: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating the pod
Sep  4 02:47:02.454: INFO: Successfully updated pod "annotationupdatecbac6444-afec-11e8-8336-00073e906c7f"
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:47:06.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-kkl7p" for this suite.
Sep  4 02:47:28.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:47:28.644: INFO: namespace: e2e-tests-projected-kkl7p, resource: bindings, ignored listing per whitelist
Sep  4 02:47:28.652: INFO: namespace e2e-tests-projected-kkl7p deletion completed in 22.14907618s

[32mâ€¢ [SLOW TEST:28.908 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should update annotations on modification [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: udp [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] Networking
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:47:28.652: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-x77zt
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Sep  4 02:47:28.817: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Sep  4 02:47:46.886: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.32.0.8 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-x77zt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:47:46.886: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:47:48.252: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:47:48.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-x77zt" for this suite.
Sep  4 02:48:10.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:48:10.352: INFO: namespace: e2e-tests-pod-network-test-x77zt, resource: bindings, ignored listing per whitelist
Sep  4 02:48:10.419: INFO: namespace e2e-tests-pod-network-test-x77zt deletion completed in 22.1612112s

[32mâ€¢ [SLOW TEST:41.767 seconds][0m
[sig-network] Networking
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Docker Containers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:48:10.419: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test override command
Sep  4 02:48:10.592: INFO: Waiting up to 5m0s for pod "client-containers-f5cdb233-afec-11e8-8336-00073e906c7f" in namespace "e2e-tests-containers-jmkt2" to be "success or failure"
Sep  4 02:48:10.596: INFO: Pod "client-containers-f5cdb233-afec-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.53838ms
Sep  4 02:48:12.602: INFO: Pod "client-containers-f5cdb233-afec-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0099181s
[1mSTEP[0m: Saw pod success
Sep  4 02:48:12.602: INFO: Pod "client-containers-f5cdb233-afec-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:48:12.606: INFO: Trying to get logs from node node3 pod client-containers-f5cdb233-afec-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:48:12.633: INFO: Waiting for pod client-containers-f5cdb233-afec-11e8-8336-00073e906c7f to disappear
Sep  4 02:48:12.637: INFO: Pod client-containers-f5cdb233-afec-11e8-8336-00073e906c7f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:48:12.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-jmkt2" for this suite.
Sep  4 02:48:18.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:48:18.703: INFO: namespace: e2e-tests-containers-jmkt2, resource: bindings, ignored listing per whitelist
Sep  4 02:48:18.796: INFO: namespace e2e-tests-containers-jmkt2 deletion completed in 6.1529098s

[32mâ€¢ [SLOW TEST:8.377 seconds][0m
[k8s.io] Docker Containers
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe add, update, and delete watch notifications on configmaps [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Watchers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:48:18.796: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating a watch on configmaps with label A
[1mSTEP[0m: creating a watch on configmaps with label B
[1mSTEP[0m: creating a watch on configmaps with label A or B
[1mSTEP[0m: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  4 02:48:18.970: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-a,UID:faccc9c5-afec-11e8-97fd-00073e906c7f,ResourceVersion:177954,Generation:0,CreationTimestamp:2018-09-04 02:48:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 02:48:18.970: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-a,UID:faccc9c5-afec-11e8-97fd-00073e906c7f,ResourceVersion:177954,Generation:0,CreationTimestamp:2018-09-04 02:48:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A and ensuring the correct watchers observe the notification
Sep  4 02:48:28.980: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-a,UID:faccc9c5-afec-11e8-97fd-00073e906c7f,ResourceVersion:177967,Generation:0,CreationTimestamp:2018-09-04 02:48:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  4 02:48:28.980: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-a,UID:faccc9c5-afec-11e8-97fd-00073e906c7f,ResourceVersion:177967,Generation:0,CreationTimestamp:2018-09-04 02:48:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  4 02:48:38.990: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-a,UID:faccc9c5-afec-11e8-97fd-00073e906c7f,ResourceVersion:177980,Generation:0,CreationTimestamp:2018-09-04 02:48:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 02:48:38.990: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-a,UID:faccc9c5-afec-11e8-97fd-00073e906c7f,ResourceVersion:177980,Generation:0,CreationTimestamp:2018-09-04 02:48:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap A and ensuring the correct watchers observe the notification
Sep  4 02:48:48.998: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-a,UID:faccc9c5-afec-11e8-97fd-00073e906c7f,ResourceVersion:177993,Generation:0,CreationTimestamp:2018-09-04 02:48:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 02:48:48.998: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-a,UID:faccc9c5-afec-11e8-97fd-00073e906c7f,ResourceVersion:177993,Generation:0,CreationTimestamp:2018-09-04 02:48:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  4 02:48:59.006: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-b,UID:12a9915e-afed-11e8-97fd-00073e906c7f,ResourceVersion:178006,Generation:0,CreationTimestamp:2018-09-04 02:48:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 02:48:59.006: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-b,UID:12a9915e-afed-11e8-97fd-00073e906c7f,ResourceVersion:178006,Generation:0,CreationTimestamp:2018-09-04 02:48:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap B and ensuring the correct watchers observe the notification
Sep  4 02:49:09.014: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-b,UID:12a9915e-afed-11e8-97fd-00073e906c7f,ResourceVersion:178019,Generation:0,CreationTimestamp:2018-09-04 02:48:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 02:49:09.014: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-stmlv,SelfLink:/api/v1/namespaces/e2e-tests-watch-stmlv/configmaps/e2e-watch-test-configmap-b,UID:12a9915e-afed-11e8-97fd-00073e906c7f,ResourceVersion:178019,Generation:0,CreationTimestamp:2018-09-04 02:48:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:49:19.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-stmlv" for this suite.
Sep  4 02:49:25.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:49:25.110: INFO: namespace: e2e-tests-watch-stmlv, resource: bindings, ignored listing per whitelist
Sep  4 02:49:25.168: INFO: namespace e2e-tests-watch-stmlv deletion completed in 6.14833174s

[32mâ€¢ [SLOW TEST:66.372 seconds][0m
[sig-api-machinery] Watchers
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:49:25.168: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-225bad21-afed-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 02:49:25.347: INFO: Waiting up to 5m0s for pod "pod-configmaps-225c6e34-afed-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-64fqs" to be "success or failure"
Sep  4 02:49:25.352: INFO: Pod "pod-configmaps-225c6e34-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.83688ms
Sep  4 02:49:27.357: INFO: Pod "pod-configmaps-225c6e34-afed-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0096729s
[1mSTEP[0m: Saw pod success
Sep  4 02:49:27.357: INFO: Pod "pod-configmaps-225c6e34-afed-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:49:27.361: INFO: Trying to get logs from node node3 pod pod-configmaps-225c6e34-afed-11e8-8336-00073e906c7f container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:49:27.392: INFO: Waiting for pod pod-configmaps-225c6e34-afed-11e8-8336-00073e906c7f to disappear
Sep  4 02:49:27.397: INFO: Pod pod-configmaps-225c6e34-afed-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:49:27.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-64fqs" for this suite.
Sep  4 02:49:33.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:49:33.488: INFO: namespace: e2e-tests-configmap-64fqs, resource: bindings, ignored listing per whitelist
Sep  4 02:49:33.553: INFO: namespace e2e-tests-configmap-64fqs deletion completed in 6.15097796s

[32mâ€¢ [SLOW TEST:8.385 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:49:33.554: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:49:33.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-275a1864-afed-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-sw787" to be "success or failure"
Sep  4 02:49:33.726: INFO: Pod "downwardapi-volume-275a1864-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01346ms
Sep  4 02:49:35.732: INFO: Pod "downwardapi-volume-275a1864-afed-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01138296s
[1mSTEP[0m: Saw pod success
Sep  4 02:49:35.732: INFO: Pod "downwardapi-volume-275a1864-afed-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:49:35.736: INFO: Trying to get logs from node node3 pod downwardapi-volume-275a1864-afed-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:49:35.762: INFO: Waiting for pod downwardapi-volume-275a1864-afed-11e8-8336-00073e906c7f to disappear
Sep  4 02:49:35.766: INFO: Pod downwardapi-volume-275a1864-afed-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:49:35.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-sw787" for this suite.
Sep  4 02:49:41.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:49:41.847: INFO: namespace: e2e-tests-downward-api-sw787, resource: bindings, ignored listing per whitelist
Sep  4 02:49:41.922: INFO: namespace e2e-tests-downward-api-sw787 deletion completed in 6.1514377s

[32mâ€¢ [SLOW TEST:8.369 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should provide podname only [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould update pod when spec was updated and update strategy is RollingUpdate [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:49:41.923: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 02:49:42.098: INFO: Creating simple daemon set daemon-set
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Sep  4 02:49:42.114: INFO: Number of nodes with available pods: 0
Sep  4 02:49:42.114: INFO: Node node3 is running more than one daemon pod
Sep  4 02:49:43.125: INFO: Number of nodes with available pods: 0
Sep  4 02:49:43.125: INFO: Node node3 is running more than one daemon pod
Sep  4 02:49:44.125: INFO: Number of nodes with available pods: 1
Sep  4 02:49:44.125: INFO: Number of running nodes: 1, number of available pods: 1
[1mSTEP[0m: Update daemon pods image.
[1mSTEP[0m: Check that daemon pods images are updated.
Sep  4 02:49:44.156: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:45.167: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:46.166: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:46.166: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:47.166: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:47.166: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:48.166: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:48.167: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:49.166: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:49.166: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:50.167: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:50.167: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:51.167: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:51.167: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:52.167: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:52.167: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:53.166: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:53.166: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:54.167: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:54.167: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:55.166: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:55.166: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:56.167: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:56.167: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:57.167: INFO: Wrong image for pod: daemon-set-drkxb. Expected: gcr.io/kubernetes-e2e-test-images/redis-arm64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-arm64:1.0.
Sep  4 02:49:57.167: INFO: Pod daemon-set-drkxb is not available
Sep  4 02:49:58.167: INFO: Pod daemon-set-cgkx4 is not available
[1mSTEP[0m: Check that daemon pods are still running on every node of the cluster.
Sep  4 02:49:58.182: INFO: Number of nodes with available pods: 0
Sep  4 02:49:58.182: INFO: Node node3 is running more than one daemon pod
Sep  4 02:49:59.193: INFO: Number of nodes with available pods: 0
Sep  4 02:49:59.193: INFO: Node node3 is running more than one daemon pod
Sep  4 02:50:00.192: INFO: Number of nodes with available pods: 1
Sep  4 02:50:00.192: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-zr9fg, will wait for the garbage collector to delete the pods
Sep  4 02:50:00.276: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.80958ms
Sep  4 02:50:00.376: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.2381ms
Sep  4 02:50:07.581: INFO: Number of nodes with available pods: 0
Sep  4 02:50:07.581: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 02:50:07.585: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zr9fg/daemonsets","resourceVersion":"178187"},"items":null}

Sep  4 02:50:07.589: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zr9fg/pods","resourceVersion":"178187"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:50:07.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-zr9fg" for this suite.
Sep  4 02:50:13.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:50:13.727: INFO: namespace: e2e-tests-daemonsets-zr9fg, resource: bindings, ignored listing per whitelist
Sep  4 02:50:13.754: INFO: namespace e2e-tests-daemonsets-zr9fg deletion completed in 6.14981854s

[32mâ€¢ [SLOW TEST:31.832 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:50:13.755: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward api env vars
Sep  4 02:50:13.929: INFO: Waiting up to 5m0s for pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f" in namespace "e2e-tests-downward-api-6p8rf" to be "success or failure"
Sep  4 02:50:13.934: INFO: Pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.03788ms
Sep  4 02:50:15.939: INFO: Pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0100137s
Sep  4 02:50:17.944: INFO: Pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01514778s
Sep  4 02:50:19.949: INFO: Pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0202142s
Sep  4 02:50:21.955: INFO: Pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02554252s
Sep  4 02:50:23.960: INFO: Pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.03067982s
Sep  4 02:50:25.965: INFO: Pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03606114s
[1mSTEP[0m: Saw pod success
Sep  4 02:50:25.965: INFO: Pod "downward-api-3f517269-afed-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:50:25.970: INFO: Trying to get logs from node node3 pod downward-api-3f517269-afed-11e8-8336-00073e906c7f container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:50:25.994: INFO: Waiting for pod downward-api-3f517269-afed-11e8-8336-00073e906c7f to disappear
Sep  4 02:50:25.999: INFO: Pod downward-api-3f517269-afed-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:50:25.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-6p8rf" for this suite.
Sep  4 02:50:32.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:50:32.116: INFO: namespace: e2e-tests-downward-api-6p8rf, resource: bindings, ignored listing per whitelist
Sep  4 02:50:32.170: INFO: namespace e2e-tests-downward-api-6p8rf deletion completed in 6.16547164s

[32mâ€¢ [SLOW TEST:18.415 seconds][0m
[sig-api-machinery] Downward API
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37[0m
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Service endpoints latency[0m 
  [1mshould not be very high  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] Service endpoints latency
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:50:32.171: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-fvv2p
I0904 02:50:32.350366   10499 runners.go:177] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-fvv2p, replica count: 1
I0904 02:50:33.400792   10499 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 02:50:34.400996   10499 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  4 02:50:34.515: INFO: Created: latency-svc-w9hdl
Sep  4 02:50:34.530: INFO: Got endpoints: latency-svc-w9hdl [29.2614ms]
Sep  4 02:50:34.558: INFO: Created: latency-svc-4dkvf
Sep  4 02:50:34.563: INFO: Got endpoints: latency-svc-4dkvf [32.46056ms]
Sep  4 02:50:34.576: INFO: Created: latency-svc-4jc27
Sep  4 02:50:34.580: INFO: Got endpoints: latency-svc-4jc27 [49.50356ms]
Sep  4 02:50:34.590: INFO: Created: latency-svc-fcswr
Sep  4 02:50:34.595: INFO: Got endpoints: latency-svc-fcswr [64.12102ms]
Sep  4 02:50:34.611: INFO: Created: latency-svc-mw4f7
Sep  4 02:50:34.616: INFO: Got endpoints: latency-svc-mw4f7 [85.51624ms]
Sep  4 02:50:34.637: INFO: Created: latency-svc-kwbdb
Sep  4 02:50:34.641: INFO: Got endpoints: latency-svc-kwbdb [109.81356ms]
Sep  4 02:50:34.662: INFO: Created: latency-svc-d98tk
Sep  4 02:50:34.666: INFO: Got endpoints: latency-svc-d98tk [134.75918ms]
Sep  4 02:50:34.681: INFO: Created: latency-svc-5tl59
Sep  4 02:50:34.685: INFO: Got endpoints: latency-svc-5tl59 [154.01426ms]
Sep  4 02:50:34.700: INFO: Created: latency-svc-zmrvq
Sep  4 02:50:34.703: INFO: Got endpoints: latency-svc-zmrvq [172.01684ms]
Sep  4 02:50:34.715: INFO: Created: latency-svc-q5m29
Sep  4 02:50:34.719: INFO: Got endpoints: latency-svc-q5m29 [187.85896ms]
Sep  4 02:50:34.731: INFO: Created: latency-svc-c8mh4
Sep  4 02:50:34.741: INFO: Got endpoints: latency-svc-c8mh4 [209.47478ms]
Sep  4 02:50:34.747: INFO: Created: latency-svc-6dxb4
Sep  4 02:50:34.752: INFO: Got endpoints: latency-svc-6dxb4 [220.48054ms]
Sep  4 02:50:34.765: INFO: Created: latency-svc-cbhh9
Sep  4 02:50:34.777: INFO: Got endpoints: latency-svc-cbhh9 [245.67876ms]
Sep  4 02:50:34.789: INFO: Created: latency-svc-tvlh5
Sep  4 02:50:34.794: INFO: Got endpoints: latency-svc-tvlh5 [263.30974ms]
Sep  4 02:50:34.805: INFO: Created: latency-svc-f5jqz
Sep  4 02:50:34.808: INFO: Got endpoints: latency-svc-f5jqz [277.06414ms]
Sep  4 02:50:34.820: INFO: Created: latency-svc-ws7ch
Sep  4 02:50:34.824: INFO: Got endpoints: latency-svc-ws7ch [293.27492ms]
Sep  4 02:50:34.836: INFO: Created: latency-svc-c27mx
Sep  4 02:50:34.848: INFO: Got endpoints: latency-svc-c27mx [285.1717ms]
Sep  4 02:50:34.853: INFO: Created: latency-svc-k26sr
Sep  4 02:50:34.858: INFO: Got endpoints: latency-svc-k26sr [278.19534ms]
Sep  4 02:50:34.869: INFO: Created: latency-svc-pwrhn
Sep  4 02:50:34.874: INFO: Got endpoints: latency-svc-pwrhn [279.28202ms]
Sep  4 02:50:34.885: INFO: Created: latency-svc-jb9qf
Sep  4 02:50:34.889: INFO: Got endpoints: latency-svc-jb9qf [272.7326ms]
Sep  4 02:50:34.903: INFO: Created: latency-svc-gdmz2
Sep  4 02:50:34.906: INFO: Got endpoints: latency-svc-gdmz2 [265.65326ms]
Sep  4 02:50:34.918: INFO: Created: latency-svc-fxd26
Sep  4 02:50:34.922: INFO: Got endpoints: latency-svc-fxd26 [256.17172ms]
Sep  4 02:50:34.934: INFO: Created: latency-svc-rxrlz
Sep  4 02:50:34.937: INFO: Got endpoints: latency-svc-rxrlz [252.01118ms]
Sep  4 02:50:34.958: INFO: Created: latency-svc-cr9p7
Sep  4 02:50:34.963: INFO: Got endpoints: latency-svc-cr9p7 [260.12344ms]
Sep  4 02:50:34.973: INFO: Created: latency-svc-qpr7v
Sep  4 02:50:34.977: INFO: Got endpoints: latency-svc-qpr7v [258.42952ms]
Sep  4 02:50:34.989: INFO: Created: latency-svc-xf97j
Sep  4 02:50:34.994: INFO: Got endpoints: latency-svc-xf97j [252.89296ms]
Sep  4 02:50:35.009: INFO: Created: latency-svc-k95s7
Sep  4 02:50:35.013: INFO: Got endpoints: latency-svc-k95s7 [261.49ms]
Sep  4 02:50:35.027: INFO: Created: latency-svc-lmpnb
Sep  4 02:50:35.031: INFO: Got endpoints: latency-svc-lmpnb [253.71458ms]
Sep  4 02:50:35.103: INFO: Created: latency-svc-j87lz
Sep  4 02:50:35.109: INFO: Got endpoints: latency-svc-j87lz [314.30114ms]
Sep  4 02:50:35.147: INFO: Created: latency-svc-x8xxb
Sep  4 02:50:35.152: INFO: Got endpoints: latency-svc-x8xxb [344.06524ms]
Sep  4 02:50:35.157: INFO: Created: latency-svc-86r4s
Sep  4 02:50:35.161: INFO: Got endpoints: latency-svc-86r4s [336.87244ms]
Sep  4 02:50:35.173: INFO: Created: latency-svc-lhrk4
Sep  4 02:50:35.178: INFO: Got endpoints: latency-svc-lhrk4 [329.66798ms]
Sep  4 02:50:35.188: INFO: Created: latency-svc-r8tm7
Sep  4 02:50:35.192: INFO: Got endpoints: latency-svc-r8tm7 [334.21086ms]
Sep  4 02:50:35.206: INFO: Created: latency-svc-wsmx6
Sep  4 02:50:35.210: INFO: Got endpoints: latency-svc-wsmx6 [336.01366ms]
Sep  4 02:50:35.221: INFO: Created: latency-svc-v6fdv
Sep  4 02:50:35.226: INFO: Got endpoints: latency-svc-v6fdv [337.26742ms]
Sep  4 02:50:35.239: INFO: Created: latency-svc-pc8j7
Sep  4 02:50:35.242: INFO: Got endpoints: latency-svc-pc8j7 [335.10136ms]
Sep  4 02:50:35.252: INFO: Created: latency-svc-plvwr
Sep  4 02:50:35.256: INFO: Got endpoints: latency-svc-plvwr [334.05942ms]
Sep  4 02:50:35.268: INFO: Created: latency-svc-5klvb
Sep  4 02:50:35.272: INFO: Got endpoints: latency-svc-5klvb [334.76476ms]
Sep  4 02:50:35.284: INFO: Created: latency-svc-d7hnn
Sep  4 02:50:35.289: INFO: Got endpoints: latency-svc-d7hnn [325.90186ms]
Sep  4 02:50:35.299: INFO: Created: latency-svc-pnxzt
Sep  4 02:50:35.304: INFO: Got endpoints: latency-svc-pnxzt [326.13922ms]
Sep  4 02:50:35.315: INFO: Created: latency-svc-4f8fs
Sep  4 02:50:35.320: INFO: Got endpoints: latency-svc-4f8fs [325.88256ms]
Sep  4 02:50:35.331: INFO: Created: latency-svc-jf5zt
Sep  4 02:50:35.335: INFO: Got endpoints: latency-svc-jf5zt [321.58122ms]
Sep  4 02:50:35.345: INFO: Created: latency-svc-zdqc9
Sep  4 02:50:35.350: INFO: Got endpoints: latency-svc-zdqc9 [319.02298ms]
Sep  4 02:50:35.361: INFO: Created: latency-svc-g6qnb
Sep  4 02:50:35.366: INFO: Got endpoints: latency-svc-g6qnb [256.9848ms]
Sep  4 02:50:35.376: INFO: Created: latency-svc-hxh8b
Sep  4 02:50:35.381: INFO: Got endpoints: latency-svc-hxh8b [228.23896ms]
Sep  4 02:50:35.397: INFO: Created: latency-svc-s5ssc
Sep  4 02:50:35.402: INFO: Got endpoints: latency-svc-s5ssc [240.30952ms]
Sep  4 02:50:35.422: INFO: Created: latency-svc-xgr9t
Sep  4 02:50:35.426: INFO: Got endpoints: latency-svc-xgr9t [248.2696ms]
Sep  4 02:50:35.436: INFO: Created: latency-svc-xx4g6
Sep  4 02:50:35.441: INFO: Got endpoints: latency-svc-xx4g6 [248.26698ms]
Sep  4 02:50:35.452: INFO: Created: latency-svc-dsbqh
Sep  4 02:50:35.466: INFO: Created: latency-svc-zfbhw
Sep  4 02:50:35.470: INFO: Got endpoints: latency-svc-dsbqh [260.16848ms]
Sep  4 02:50:35.481: INFO: Created: latency-svc-lfcq4
Sep  4 02:50:35.497: INFO: Created: latency-svc-2f97v
Sep  4 02:50:35.511: INFO: Created: latency-svc-qxhbq
Sep  4 02:50:35.520: INFO: Got endpoints: latency-svc-zfbhw [292.98878ms]
Sep  4 02:50:35.533: INFO: Created: latency-svc-l7r9k
Sep  4 02:50:35.547: INFO: Created: latency-svc-c94hh
Sep  4 02:50:35.563: INFO: Created: latency-svc-4jcbp
Sep  4 02:50:35.569: INFO: Got endpoints: latency-svc-lfcq4 [327.72422ms]
Sep  4 02:50:35.577: INFO: Created: latency-svc-6njs6
Sep  4 02:50:35.594: INFO: Created: latency-svc-l7p2s
Sep  4 02:50:35.610: INFO: Created: latency-svc-27cdb
Sep  4 02:50:35.619: INFO: Got endpoints: latency-svc-2f97v [363.11816ms]
Sep  4 02:50:35.625: INFO: Created: latency-svc-jfs7x
Sep  4 02:50:35.642: INFO: Created: latency-svc-rzxll
Sep  4 02:50:35.659: INFO: Created: latency-svc-sdk9c
Sep  4 02:50:35.670: INFO: Got endpoints: latency-svc-qxhbq [397.54712ms]
Sep  4 02:50:35.678: INFO: Created: latency-svc-hf6b7
Sep  4 02:50:35.709: INFO: Created: latency-svc-t8hbq
Sep  4 02:50:35.720: INFO: Got endpoints: latency-svc-l7r9k [431.40168ms]
Sep  4 02:50:35.732: INFO: Created: latency-svc-kwvtt
Sep  4 02:50:35.748: INFO: Created: latency-svc-2pk6r
Sep  4 02:50:35.764: INFO: Created: latency-svc-7zvv8
Sep  4 02:50:35.769: INFO: Got endpoints: latency-svc-c94hh [465.586ms]
Sep  4 02:50:35.778: INFO: Created: latency-svc-tsmm7
Sep  4 02:50:35.794: INFO: Created: latency-svc-mtnl6
Sep  4 02:50:35.810: INFO: Created: latency-svc-r5x4x
Sep  4 02:50:35.820: INFO: Got endpoints: latency-svc-4jcbp [499.91762ms]
Sep  4 02:50:35.840: INFO: Created: latency-svc-g56mx
Sep  4 02:50:35.869: INFO: Got endpoints: latency-svc-6njs6 [534.30396ms]
Sep  4 02:50:35.889: INFO: Created: latency-svc-xkr69
Sep  4 02:50:35.919: INFO: Got endpoints: latency-svc-l7p2s [569.2291ms]
Sep  4 02:50:35.940: INFO: Created: latency-svc-dzc8p
Sep  4 02:50:35.969: INFO: Got endpoints: latency-svc-27cdb [603.29226ms]
Sep  4 02:50:35.990: INFO: Created: latency-svc-bglqv
Sep  4 02:50:36.019: INFO: Got endpoints: latency-svc-jfs7x [638.24988ms]
Sep  4 02:50:36.041: INFO: Created: latency-svc-5mfqg
Sep  4 02:50:36.069: INFO: Got endpoints: latency-svc-rzxll [449.84058ms]
Sep  4 02:50:36.090: INFO: Created: latency-svc-xqnfp
Sep  4 02:50:36.120: INFO: Got endpoints: latency-svc-sdk9c [717.82666ms]
Sep  4 02:50:36.141: INFO: Created: latency-svc-k2g44
Sep  4 02:50:36.170: INFO: Got endpoints: latency-svc-hf6b7 [743.27946ms]
Sep  4 02:50:36.190: INFO: Created: latency-svc-4nvpd
Sep  4 02:50:36.219: INFO: Got endpoints: latency-svc-t8hbq [778.35004ms]
Sep  4 02:50:36.241: INFO: Created: latency-svc-db9bq
Sep  4 02:50:36.270: INFO: Got endpoints: latency-svc-kwvtt [799.126ms]
Sep  4 02:50:36.291: INFO: Created: latency-svc-jl7c9
Sep  4 02:50:36.319: INFO: Got endpoints: latency-svc-2pk6r [799.65422ms]
Sep  4 02:50:36.342: INFO: Created: latency-svc-slnsn
Sep  4 02:50:36.372: INFO: Got endpoints: latency-svc-7zvv8 [802.62424ms]
Sep  4 02:50:36.403: INFO: Created: latency-svc-p9pzw
Sep  4 02:50:36.420: INFO: Got endpoints: latency-svc-tsmm7 [749.73566ms]
Sep  4 02:50:36.440: INFO: Created: latency-svc-klx86
Sep  4 02:50:36.470: INFO: Got endpoints: latency-svc-mtnl6 [749.41172ms]
Sep  4 02:50:36.493: INFO: Created: latency-svc-h9phn
Sep  4 02:50:36.520: INFO: Got endpoints: latency-svc-r5x4x [750.2466ms]
Sep  4 02:50:36.540: INFO: Created: latency-svc-l2wvj
Sep  4 02:50:36.569: INFO: Got endpoints: latency-svc-g56mx [749.76772ms]
Sep  4 02:50:36.591: INFO: Created: latency-svc-4bndq
Sep  4 02:50:36.619: INFO: Got endpoints: latency-svc-xkr69 [750.0435ms]
Sep  4 02:50:36.641: INFO: Created: latency-svc-z2667
Sep  4 02:50:36.669: INFO: Got endpoints: latency-svc-dzc8p [750.32504ms]
Sep  4 02:50:36.690: INFO: Created: latency-svc-hcn86
Sep  4 02:50:36.719: INFO: Got endpoints: latency-svc-bglqv [749.87504ms]
Sep  4 02:50:36.741: INFO: Created: latency-svc-f7nhq
Sep  4 02:50:36.769: INFO: Got endpoints: latency-svc-5mfqg [749.98158ms]
Sep  4 02:50:36.792: INFO: Created: latency-svc-k2x4k
Sep  4 02:50:36.820: INFO: Got endpoints: latency-svc-xqnfp [750.231ms]
Sep  4 02:50:36.843: INFO: Created: latency-svc-zq6ph
Sep  4 02:50:36.870: INFO: Got endpoints: latency-svc-k2g44 [749.80296ms]
Sep  4 02:50:36.897: INFO: Created: latency-svc-7xdmt
Sep  4 02:50:36.919: INFO: Got endpoints: latency-svc-4nvpd [749.46518ms]
Sep  4 02:50:36.941: INFO: Created: latency-svc-w2bmw
Sep  4 02:50:36.969: INFO: Got endpoints: latency-svc-db9bq [749.8823ms]
Sep  4 02:50:37.023: INFO: Got endpoints: latency-svc-jl7c9 [753.63532ms]
Sep  4 02:50:37.026: INFO: Created: latency-svc-9hzq2
Sep  4 02:50:37.071: INFO: Got endpoints: latency-svc-slnsn [751.63018ms]
Sep  4 02:50:37.076: INFO: Created: latency-svc-7w7vx
Sep  4 02:50:37.091: INFO: Created: latency-svc-sbhmn
Sep  4 02:50:37.119: INFO: Got endpoints: latency-svc-p9pzw [747.00722ms]
Sep  4 02:50:37.139: INFO: Created: latency-svc-59zbp
Sep  4 02:50:37.170: INFO: Got endpoints: latency-svc-klx86 [750.1246ms]
Sep  4 02:50:37.190: INFO: Created: latency-svc-b54wf
Sep  4 02:50:37.219: INFO: Got endpoints: latency-svc-h9phn [749.38308ms]
Sep  4 02:50:37.239: INFO: Created: latency-svc-vpdw9
Sep  4 02:50:37.269: INFO: Got endpoints: latency-svc-l2wvj [749.63464ms]
Sep  4 02:50:37.289: INFO: Created: latency-svc-jxt7j
Sep  4 02:50:37.319: INFO: Got endpoints: latency-svc-4bndq [749.67102ms]
Sep  4 02:50:37.351: INFO: Created: latency-svc-wvxwc
Sep  4 02:50:37.369: INFO: Got endpoints: latency-svc-z2667 [749.78716ms]
Sep  4 02:50:37.389: INFO: Created: latency-svc-9gf95
Sep  4 02:50:37.420: INFO: Got endpoints: latency-svc-hcn86 [750.43576ms]
Sep  4 02:50:37.443: INFO: Created: latency-svc-shq9h
Sep  4 02:50:37.470: INFO: Got endpoints: latency-svc-f7nhq [750.65468ms]
Sep  4 02:50:37.490: INFO: Created: latency-svc-lhhmz
Sep  4 02:50:37.522: INFO: Got endpoints: latency-svc-k2x4k [753.0514ms]
Sep  4 02:50:37.542: INFO: Created: latency-svc-hrbk7
Sep  4 02:50:37.570: INFO: Got endpoints: latency-svc-zq6ph [749.94518ms]
Sep  4 02:50:37.589: INFO: Created: latency-svc-mkplf
Sep  4 02:50:37.620: INFO: Got endpoints: latency-svc-7xdmt [749.92622ms]
Sep  4 02:50:37.641: INFO: Created: latency-svc-lh5bs
Sep  4 02:50:37.669: INFO: Got endpoints: latency-svc-w2bmw [750.13824ms]
Sep  4 02:50:37.691: INFO: Created: latency-svc-8s4rn
Sep  4 02:50:37.719: INFO: Got endpoints: latency-svc-9hzq2 [749.87904ms]
Sep  4 02:50:37.741: INFO: Created: latency-svc-6795z
Sep  4 02:50:37.769: INFO: Got endpoints: latency-svc-7w7vx [745.78866ms]
Sep  4 02:50:37.789: INFO: Created: latency-svc-k7nrx
Sep  4 02:50:37.819: INFO: Got endpoints: latency-svc-sbhmn [748.00074ms]
Sep  4 02:50:37.841: INFO: Created: latency-svc-4mptt
Sep  4 02:50:37.870: INFO: Got endpoints: latency-svc-59zbp [750.17914ms]
Sep  4 02:50:37.889: INFO: Created: latency-svc-sqv58
Sep  4 02:50:37.919: INFO: Got endpoints: latency-svc-b54wf [749.2532ms]
Sep  4 02:50:37.941: INFO: Created: latency-svc-x8fpq
Sep  4 02:50:37.970: INFO: Got endpoints: latency-svc-vpdw9 [750.20316ms]
Sep  4 02:50:37.989: INFO: Created: latency-svc-8jltw
Sep  4 02:50:38.020: INFO: Got endpoints: latency-svc-jxt7j [750.15492ms]
Sep  4 02:50:38.043: INFO: Created: latency-svc-8khzl
Sep  4 02:50:38.069: INFO: Got endpoints: latency-svc-wvxwc [750.11616ms]
Sep  4 02:50:38.088: INFO: Created: latency-svc-hbh56
Sep  4 02:50:38.119: INFO: Got endpoints: latency-svc-9gf95 [750.01972ms]
Sep  4 02:50:38.139: INFO: Created: latency-svc-q5lhh
Sep  4 02:50:38.170: INFO: Got endpoints: latency-svc-shq9h [749.52404ms]
Sep  4 02:50:38.189: INFO: Created: latency-svc-bc6mr
Sep  4 02:50:38.219: INFO: Got endpoints: latency-svc-lhhmz [748.94074ms]
Sep  4 02:50:38.239: INFO: Created: latency-svc-l689s
Sep  4 02:50:38.269: INFO: Got endpoints: latency-svc-hrbk7 [746.78336ms]
Sep  4 02:50:38.289: INFO: Created: latency-svc-ws4gf
Sep  4 02:50:38.319: INFO: Got endpoints: latency-svc-mkplf [749.59382ms]
Sep  4 02:50:38.348: INFO: Created: latency-svc-sjtm8
Sep  4 02:50:38.370: INFO: Got endpoints: latency-svc-lh5bs [750.4005ms]
Sep  4 02:50:38.389: INFO: Created: latency-svc-z8jvx
Sep  4 02:50:38.419: INFO: Got endpoints: latency-svc-8s4rn [749.70646ms]
Sep  4 02:50:38.439: INFO: Created: latency-svc-cmlcq
Sep  4 02:50:38.470: INFO: Got endpoints: latency-svc-6795z [750.3799ms]
Sep  4 02:50:38.489: INFO: Created: latency-svc-ljvlm
Sep  4 02:50:38.520: INFO: Got endpoints: latency-svc-k7nrx [750.25254ms]
Sep  4 02:50:38.541: INFO: Created: latency-svc-cr9px
Sep  4 02:50:38.569: INFO: Got endpoints: latency-svc-4mptt [750.02108ms]
Sep  4 02:50:38.589: INFO: Created: latency-svc-spgzg
Sep  4 02:50:38.620: INFO: Got endpoints: latency-svc-sqv58 [749.83316ms]
Sep  4 02:50:38.640: INFO: Created: latency-svc-xth4f
Sep  4 02:50:38.669: INFO: Got endpoints: latency-svc-x8fpq [750.10136ms]
Sep  4 02:50:38.690: INFO: Created: latency-svc-4l4pf
Sep  4 02:50:38.719: INFO: Got endpoints: latency-svc-8jltw [749.23376ms]
Sep  4 02:50:38.740: INFO: Created: latency-svc-7r64x
Sep  4 02:50:38.771: INFO: Got endpoints: latency-svc-8khzl [751.6671ms]
Sep  4 02:50:38.791: INFO: Created: latency-svc-drsfm
Sep  4 02:50:38.819: INFO: Got endpoints: latency-svc-hbh56 [749.98718ms]
Sep  4 02:50:38.840: INFO: Created: latency-svc-fxlsj
Sep  4 02:50:38.869: INFO: Got endpoints: latency-svc-q5lhh [749.92048ms]
Sep  4 02:50:38.889: INFO: Created: latency-svc-ts8ww
Sep  4 02:50:38.920: INFO: Got endpoints: latency-svc-bc6mr [749.9071ms]
Sep  4 02:50:38.938: INFO: Created: latency-svc-8jm88
Sep  4 02:50:38.970: INFO: Got endpoints: latency-svc-l689s [750.76228ms]
Sep  4 02:50:38.994: INFO: Created: latency-svc-6w4cn
Sep  4 02:50:39.020: INFO: Got endpoints: latency-svc-ws4gf [750.51306ms]
Sep  4 02:50:39.041: INFO: Created: latency-svc-ksx2q
Sep  4 02:50:39.070: INFO: Got endpoints: latency-svc-sjtm8 [750.33868ms]
Sep  4 02:50:39.091: INFO: Created: latency-svc-8599b
Sep  4 02:50:39.119: INFO: Got endpoints: latency-svc-z8jvx [749.00208ms]
Sep  4 02:50:39.142: INFO: Created: latency-svc-jgthh
Sep  4 02:50:39.169: INFO: Got endpoints: latency-svc-cmlcq [749.97044ms]
Sep  4 02:50:39.193: INFO: Created: latency-svc-5pl8l
Sep  4 02:50:39.220: INFO: Got endpoints: latency-svc-ljvlm [750.07842ms]
Sep  4 02:50:39.240: INFO: Created: latency-svc-p7dxt
Sep  4 02:50:39.269: INFO: Got endpoints: latency-svc-cr9px [749.58584ms]
Sep  4 02:50:39.295: INFO: Created: latency-svc-jt48p
Sep  4 02:50:39.320: INFO: Got endpoints: latency-svc-spgzg [750.03778ms]
Sep  4 02:50:39.340: INFO: Created: latency-svc-jk2pl
Sep  4 02:50:39.369: INFO: Got endpoints: latency-svc-xth4f [749.71692ms]
Sep  4 02:50:39.402: INFO: Created: latency-svc-vvgx6
Sep  4 02:50:39.419: INFO: Got endpoints: latency-svc-4l4pf [749.8227ms]
Sep  4 02:50:39.440: INFO: Created: latency-svc-8h85z
Sep  4 02:50:39.469: INFO: Got endpoints: latency-svc-7r64x [749.95744ms]
Sep  4 02:50:39.489: INFO: Created: latency-svc-799g8
Sep  4 02:50:39.519: INFO: Got endpoints: latency-svc-drsfm [747.97664ms]
Sep  4 02:50:39.541: INFO: Created: latency-svc-hg6wd
Sep  4 02:50:39.569: INFO: Got endpoints: latency-svc-fxlsj [749.62554ms]
Sep  4 02:50:39.590: INFO: Created: latency-svc-jl57j
Sep  4 02:50:39.619: INFO: Got endpoints: latency-svc-ts8ww [749.71648ms]
Sep  4 02:50:39.638: INFO: Created: latency-svc-z5m52
Sep  4 02:50:39.669: INFO: Got endpoints: latency-svc-8jm88 [749.5135ms]
Sep  4 02:50:39.689: INFO: Created: latency-svc-lcnvl
Sep  4 02:50:39.720: INFO: Got endpoints: latency-svc-6w4cn [749.424ms]
Sep  4 02:50:39.739: INFO: Created: latency-svc-fppq6
Sep  4 02:50:39.769: INFO: Got endpoints: latency-svc-ksx2q [749.40574ms]
Sep  4 02:50:39.788: INFO: Created: latency-svc-7ntxf
Sep  4 02:50:39.819: INFO: Got endpoints: latency-svc-8599b [749.30126ms]
Sep  4 02:50:39.840: INFO: Created: latency-svc-9lncj
Sep  4 02:50:39.870: INFO: Got endpoints: latency-svc-jgthh [750.66808ms]
Sep  4 02:50:39.889: INFO: Created: latency-svc-9mrzl
Sep  4 02:50:39.920: INFO: Got endpoints: latency-svc-5pl8l [750.12702ms]
Sep  4 02:50:39.941: INFO: Created: latency-svc-b9xbw
Sep  4 02:50:39.970: INFO: Got endpoints: latency-svc-p7dxt [749.55986ms]
Sep  4 02:50:39.990: INFO: Created: latency-svc-5nngx
Sep  4 02:50:40.023: INFO: Got endpoints: latency-svc-jt48p [753.08626ms]
Sep  4 02:50:40.044: INFO: Created: latency-svc-xfmjb
Sep  4 02:50:40.069: INFO: Got endpoints: latency-svc-jk2pl [749.73382ms]
Sep  4 02:50:40.090: INFO: Created: latency-svc-hcsk8
Sep  4 02:50:40.120: INFO: Got endpoints: latency-svc-vvgx6 [749.98708ms]
Sep  4 02:50:40.140: INFO: Created: latency-svc-g9jhn
Sep  4 02:50:40.169: INFO: Got endpoints: latency-svc-8h85z [749.96888ms]
Sep  4 02:50:40.189: INFO: Created: latency-svc-jdv2k
Sep  4 02:50:40.264: INFO: Got endpoints: latency-svc-799g8 [794.51046ms]
Sep  4 02:50:40.270: INFO: Got endpoints: latency-svc-hg6wd [750.55718ms]
Sep  4 02:50:40.287: INFO: Created: latency-svc-sgs8t
Sep  4 02:50:40.314: INFO: Created: latency-svc-jbg8q
Sep  4 02:50:40.319: INFO: Got endpoints: latency-svc-jl57j [750.08674ms]
Sep  4 02:50:40.340: INFO: Created: latency-svc-t2825
Sep  4 02:50:40.369: INFO: Got endpoints: latency-svc-z5m52 [749.94984ms]
Sep  4 02:50:40.389: INFO: Created: latency-svc-64qrj
Sep  4 02:50:40.419: INFO: Got endpoints: latency-svc-lcnvl [749.94056ms]
Sep  4 02:50:40.441: INFO: Created: latency-svc-cnxml
Sep  4 02:50:40.469: INFO: Got endpoints: latency-svc-fppq6 [749.66686ms]
Sep  4 02:50:40.491: INFO: Created: latency-svc-2h5d2
Sep  4 02:50:40.519: INFO: Got endpoints: latency-svc-7ntxf [749.66096ms]
Sep  4 02:50:40.547: INFO: Created: latency-svc-t79bc
Sep  4 02:50:40.570: INFO: Got endpoints: latency-svc-9lncj [750.46208ms]
Sep  4 02:50:40.589: INFO: Created: latency-svc-bd5nr
Sep  4 02:50:40.620: INFO: Got endpoints: latency-svc-9mrzl [749.76786ms]
Sep  4 02:50:40.642: INFO: Created: latency-svc-hbl2k
Sep  4 02:50:40.671: INFO: Got endpoints: latency-svc-b9xbw [751.215ms]
Sep  4 02:50:40.692: INFO: Created: latency-svc-g2kfn
Sep  4 02:50:40.720: INFO: Got endpoints: latency-svc-5nngx [749.97818ms]
Sep  4 02:50:40.739: INFO: Created: latency-svc-dcch9
Sep  4 02:50:40.769: INFO: Got endpoints: latency-svc-xfmjb [746.48034ms]
Sep  4 02:50:40.790: INFO: Created: latency-svc-hpxwx
Sep  4 02:50:40.819: INFO: Got endpoints: latency-svc-hcsk8 [749.80832ms]
Sep  4 02:50:40.838: INFO: Created: latency-svc-bn7wt
Sep  4 02:50:40.869: INFO: Got endpoints: latency-svc-g9jhn [749.75872ms]
Sep  4 02:50:40.893: INFO: Created: latency-svc-7z7zt
Sep  4 02:50:40.920: INFO: Got endpoints: latency-svc-jdv2k [750.19318ms]
Sep  4 02:50:40.940: INFO: Created: latency-svc-ssd9w
Sep  4 02:50:40.969: INFO: Got endpoints: latency-svc-sgs8t [705.39362ms]
Sep  4 02:50:40.992: INFO: Created: latency-svc-7gjr2
Sep  4 02:50:41.019: INFO: Got endpoints: latency-svc-jbg8q [749.12922ms]
Sep  4 02:50:41.040: INFO: Created: latency-svc-5q844
Sep  4 02:50:41.069: INFO: Got endpoints: latency-svc-t2825 [749.95898ms]
Sep  4 02:50:41.094: INFO: Created: latency-svc-6wd9s
Sep  4 02:50:41.119: INFO: Got endpoints: latency-svc-64qrj [749.95092ms]
Sep  4 02:50:41.139: INFO: Created: latency-svc-kgnpn
Sep  4 02:50:41.170: INFO: Got endpoints: latency-svc-cnxml [750.0758ms]
Sep  4 02:50:41.188: INFO: Created: latency-svc-pwbgk
Sep  4 02:50:41.219: INFO: Got endpoints: latency-svc-2h5d2 [749.83956ms]
Sep  4 02:50:41.240: INFO: Created: latency-svc-dkcfr
Sep  4 02:50:41.269: INFO: Got endpoints: latency-svc-t79bc [750.10562ms]
Sep  4 02:50:41.289: INFO: Created: latency-svc-r6bc8
Sep  4 02:50:41.319: INFO: Got endpoints: latency-svc-bd5nr [749.61432ms]
Sep  4 02:50:41.338: INFO: Created: latency-svc-x24zt
Sep  4 02:50:41.369: INFO: Got endpoints: latency-svc-hbl2k [749.09464ms]
Sep  4 02:50:41.388: INFO: Created: latency-svc-wjng8
Sep  4 02:50:41.419: INFO: Got endpoints: latency-svc-g2kfn [748.16876ms]
Sep  4 02:50:41.439: INFO: Created: latency-svc-pr686
Sep  4 02:50:41.470: INFO: Got endpoints: latency-svc-dcch9 [749.93812ms]
Sep  4 02:50:41.489: INFO: Created: latency-svc-r6mtv
Sep  4 02:50:41.519: INFO: Got endpoints: latency-svc-hpxwx [749.94882ms]
Sep  4 02:50:41.538: INFO: Created: latency-svc-qgl7n
Sep  4 02:50:41.569: INFO: Got endpoints: latency-svc-bn7wt [749.7841ms]
Sep  4 02:50:41.589: INFO: Created: latency-svc-p4xhf
Sep  4 02:50:41.619: INFO: Got endpoints: latency-svc-7z7zt [749.96758ms]
Sep  4 02:50:41.641: INFO: Created: latency-svc-knx8r
Sep  4 02:50:41.670: INFO: Got endpoints: latency-svc-ssd9w [749.80026ms]
Sep  4 02:50:41.691: INFO: Created: latency-svc-dztjn
Sep  4 02:50:41.720: INFO: Got endpoints: latency-svc-7gjr2 [751.05364ms]
Sep  4 02:50:41.747: INFO: Created: latency-svc-bpjxx
Sep  4 02:50:41.769: INFO: Got endpoints: latency-svc-5q844 [749.7942ms]
Sep  4 02:50:41.789: INFO: Created: latency-svc-h5rjj
Sep  4 02:50:41.820: INFO: Got endpoints: latency-svc-6wd9s [750.0819ms]
Sep  4 02:50:41.840: INFO: Created: latency-svc-8nwv5
Sep  4 02:50:41.870: INFO: Got endpoints: latency-svc-kgnpn [750.1345ms]
Sep  4 02:50:41.890: INFO: Created: latency-svc-84zgl
Sep  4 02:50:41.920: INFO: Got endpoints: latency-svc-pwbgk [749.95562ms]
Sep  4 02:50:41.940: INFO: Created: latency-svc-c4vqr
Sep  4 02:50:41.969: INFO: Got endpoints: latency-svc-dkcfr [749.98028ms]
Sep  4 02:50:41.990: INFO: Created: latency-svc-mkvlj
Sep  4 02:50:42.020: INFO: Got endpoints: latency-svc-r6bc8 [750.48276ms]
Sep  4 02:50:42.042: INFO: Created: latency-svc-9jnnl
Sep  4 02:50:42.069: INFO: Got endpoints: latency-svc-x24zt [749.68518ms]
Sep  4 02:50:42.089: INFO: Created: latency-svc-gfsw7
Sep  4 02:50:42.119: INFO: Got endpoints: latency-svc-wjng8 [750.062ms]
Sep  4 02:50:42.141: INFO: Created: latency-svc-z8qz7
Sep  4 02:50:42.170: INFO: Got endpoints: latency-svc-pr686 [750.33008ms]
Sep  4 02:50:42.190: INFO: Created: latency-svc-zrwcr
Sep  4 02:50:42.219: INFO: Got endpoints: latency-svc-r6mtv [749.26678ms]
Sep  4 02:50:42.239: INFO: Created: latency-svc-cc2qp
Sep  4 02:50:42.269: INFO: Got endpoints: latency-svc-qgl7n [749.99234ms]
Sep  4 02:50:42.288: INFO: Created: latency-svc-9v6pq
Sep  4 02:50:42.319: INFO: Got endpoints: latency-svc-p4xhf [750.22716ms]
Sep  4 02:50:42.341: INFO: Created: latency-svc-hkpzl
Sep  4 02:50:42.369: INFO: Got endpoints: latency-svc-knx8r [749.80296ms]
Sep  4 02:50:42.419: INFO: Got endpoints: latency-svc-dztjn [749.27088ms]
Sep  4 02:50:42.469: INFO: Got endpoints: latency-svc-bpjxx [748.63282ms]
Sep  4 02:50:42.519: INFO: Got endpoints: latency-svc-h5rjj [750.0715ms]
Sep  4 02:50:42.569: INFO: Got endpoints: latency-svc-8nwv5 [749.26054ms]
Sep  4 02:50:42.619: INFO: Got endpoints: latency-svc-84zgl [749.46864ms]
Sep  4 02:50:42.669: INFO: Got endpoints: latency-svc-c4vqr [749.6861ms]
Sep  4 02:50:42.719: INFO: Got endpoints: latency-svc-mkvlj [749.7254ms]
Sep  4 02:50:42.769: INFO: Got endpoints: latency-svc-9jnnl [749.16644ms]
Sep  4 02:50:42.819: INFO: Got endpoints: latency-svc-gfsw7 [749.78148ms]
Sep  4 02:50:42.869: INFO: Got endpoints: latency-svc-z8qz7 [750.09404ms]
Sep  4 02:50:42.920: INFO: Got endpoints: latency-svc-zrwcr [750.31744ms]
Sep  4 02:50:42.970: INFO: Got endpoints: latency-svc-cc2qp [750.7843ms]
Sep  4 02:50:43.020: INFO: Got endpoints: latency-svc-9v6pq [750.17844ms]
Sep  4 02:50:43.069: INFO: Got endpoints: latency-svc-hkpzl [749.6741ms]
Sep  4 02:50:43.069: INFO: Latencies: [32.46056ms 49.50356ms 64.12102ms 85.51624ms 109.81356ms 134.75918ms 154.01426ms 172.01684ms 187.85896ms 209.47478ms 220.48054ms 228.23896ms 240.30952ms 245.67876ms 248.26698ms 248.2696ms 252.01118ms 252.89296ms 253.71458ms 256.17172ms 256.9848ms 258.42952ms 260.12344ms 260.16848ms 261.49ms 263.30974ms 265.65326ms 272.7326ms 277.06414ms 278.19534ms 279.28202ms 285.1717ms 292.98878ms 293.27492ms 314.30114ms 319.02298ms 321.58122ms 325.88256ms 325.90186ms 326.13922ms 327.72422ms 329.66798ms 334.05942ms 334.21086ms 334.76476ms 335.10136ms 336.01366ms 336.87244ms 337.26742ms 344.06524ms 363.11816ms 397.54712ms 431.40168ms 449.84058ms 465.586ms 499.91762ms 534.30396ms 569.2291ms 603.29226ms 638.24988ms 705.39362ms 717.82666ms 743.27946ms 745.78866ms 746.48034ms 746.78336ms 747.00722ms 747.97664ms 748.00074ms 748.16876ms 748.63282ms 748.94074ms 749.00208ms 749.09464ms 749.12922ms 749.16644ms 749.23376ms 749.2532ms 749.26054ms 749.26678ms 749.27088ms 749.30126ms 749.38308ms 749.40574ms 749.41172ms 749.424ms 749.46518ms 749.46864ms 749.5135ms 749.52404ms 749.55986ms 749.58584ms 749.59382ms 749.61432ms 749.62554ms 749.63464ms 749.66096ms 749.66686ms 749.67102ms 749.6741ms 749.68518ms 749.6861ms 749.70646ms 749.71648ms 749.71692ms 749.7254ms 749.73382ms 749.73566ms 749.75872ms 749.76772ms 749.76786ms 749.78148ms 749.7841ms 749.78716ms 749.7942ms 749.80026ms 749.80296ms 749.80296ms 749.80832ms 749.8227ms 749.83316ms 749.83956ms 749.87504ms 749.87904ms 749.8823ms 749.9071ms 749.92048ms 749.92622ms 749.93812ms 749.94056ms 749.94518ms 749.94882ms 749.94984ms 749.95092ms 749.95562ms 749.95744ms 749.95898ms 749.96758ms 749.96888ms 749.97044ms 749.97818ms 749.98028ms 749.98158ms 749.98708ms 749.98718ms 749.99234ms 750.01972ms 750.02108ms 750.03778ms 750.0435ms 750.062ms 750.0715ms 750.0758ms 750.07842ms 750.0819ms 750.08674ms 750.09404ms 750.10136ms 750.10562ms 750.11616ms 750.1246ms 750.12702ms 750.1345ms 750.13824ms 750.15492ms 750.17844ms 750.17914ms 750.19318ms 750.20316ms 750.22716ms 750.231ms 750.2466ms 750.25254ms 750.31744ms 750.32504ms 750.33008ms 750.33868ms 750.3799ms 750.4005ms 750.43576ms 750.46208ms 750.48276ms 750.51306ms 750.55718ms 750.65468ms 750.66808ms 750.76228ms 750.7843ms 751.05364ms 751.215ms 751.63018ms 751.6671ms 753.0514ms 753.08626ms 753.63532ms 778.35004ms 794.51046ms 799.126ms 799.65422ms 802.62424ms]
Sep  4 02:50:43.070: INFO: 50 %ile: 749.68518ms
Sep  4 02:50:43.070: INFO: 90 %ile: 750.46208ms
Sep  4 02:50:43.070: INFO: 99 %ile: 799.65422ms
Sep  4 02:50:43.070: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:50:43.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svc-latency-fvv2p" for this suite.
Sep  4 02:50:59.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:50:59.171: INFO: namespace: e2e-tests-svc-latency-fvv2p, resource: bindings, ignored listing per whitelist
Sep  4 02:50:59.226: INFO: namespace e2e-tests-svc-latency-fvv2p deletion completed in 16.15069512s

[32mâ€¢ [SLOW TEST:27.056 seconds][0m
[sig-network] Service endpoints latency
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should not be very high  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to start watching from a specific resource version [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Watchers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:50:59.227: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: creating a watch on configmaps from the resource version returned by the first update
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap after the first update
Sep  4 02:50:59.427: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wc7m8,SelfLink:/api/v1/namespaces/e2e-tests-watch-wc7m8/configmaps/e2e-watch-test-resource-version,UID:5a6cbbc1-afed-11e8-97fd-00073e906c7f,ResourceVersion:179535,Generation:0,CreationTimestamp:2018-09-04 02:50:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 02:50:59.428: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wc7m8,SelfLink:/api/v1/namespaces/e2e-tests-watch-wc7m8/configmaps/e2e-watch-test-resource-version,UID:5a6cbbc1-afed-11e8-97fd-00073e906c7f,ResourceVersion:179536,Generation:0,CreationTimestamp:2018-09-04 02:50:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:50:59.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-wc7m8" for this suite.
Sep  4 02:51:05.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:51:05.519: INFO: namespace: e2e-tests-watch-wc7m8, resource: bindings, ignored listing per whitelist
Sep  4 02:51:05.589: INFO: namespace e2e-tests-watch-wc7m8 deletion completed in 6.15578178s

[32mâ€¢ [SLOW TEST:6.362 seconds][0m
[sig-api-machinery] Watchers
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should be able to start watching from a specific resource version [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:51:05.589: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name s-test-opt-del-5e36ce2b-afed-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating secret with name s-test-opt-upd-5e36ceae-afed-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-5e36ce2b-afed-11e8-8336-00073e906c7f
[1mSTEP[0m: Updating secret s-test-opt-upd-5e36ceae-afed-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating secret with name s-test-opt-create-5e36cef0-afed-11e8-8336-00073e906c7f
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:52:20.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-fnhjx" for this suite.
Sep  4 02:52:42.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:52:42.499: INFO: namespace: e2e-tests-secrets-fnhjx, resource: bindings, ignored listing per whitelist
Sep  4 02:52:42.580: INFO: namespace e2e-tests-secrets-fnhjx deletion completed in 22.14983092s

[32mâ€¢ [SLOW TEST:96.991 seconds][0m
[sig-storage] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: http [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] Networking
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:52:42.581: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-8g4h2
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Sep  4 02:52:42.748: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Sep  4 02:53:02.817: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.9:8080/dial?request=hostName&protocol=http&host=10.32.0.8&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-8g4h2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 02:53:02.817: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 02:53:03.191: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:53:03.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-8g4h2" for this suite.
Sep  4 02:53:25.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:53:25.288: INFO: namespace: e2e-tests-pod-network-test-8g4h2, resource: bindings, ignored listing per whitelist
Sep  4 02:53:25.349: INFO: namespace e2e-tests-pod-network-test-8g4h2 deletion completed in 22.15141654s

[32mâ€¢ [SLOW TEST:42.768 seconds][0m
[sig-network] Networking
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] HostPath[0m 
  [1mshould give a volume the correct mode [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] HostPath
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:53:25.349: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:36
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test hostPath mode
Sep  4 02:53:25.522: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-rwz6m" to be "success or failure"
Sep  4 02:53:25.527: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.89934ms
Sep  4 02:53:27.532: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0097879s
Sep  4 02:53:29.537: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01523816s
[1mSTEP[0m: Saw pod success
Sep  4 02:53:29.537: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  4 02:53:29.542: INFO: Trying to get logs from node node3 pod pod-host-path-test container test-container-1: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:53:29.566: INFO: Waiting for pod pod-host-path-test to disappear
Sep  4 02:53:29.570: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:53:29.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-hostpath-rwz6m" for this suite.
Sep  4 02:53:35.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:53:35.710: INFO: namespace: e2e-tests-hostpath-rwz6m, resource: bindings, ignored listing per whitelist
Sep  4 02:53:35.732: INFO: namespace e2e-tests-hostpath-rwz6m deletion completed in 6.15698318s

[32mâ€¢ [SLOW TEST:10.383 seconds][0m
[sig-storage] HostPath
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:33[0m
  should give a volume the correct mode [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould create and stop a replication controller  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:53:35.733: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should create and stop a replication controller  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating a replication controller
Sep  4 02:53:35.899: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:36.523: INFO: stderr: ""
Sep  4 02:53:36.523: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Sep  4 02:53:36.523: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:36.867: INFO: stderr: ""
Sep  4 02:53:36.867: INFO: stdout: "update-demo-nautilus-d7j6f update-demo-nautilus-zgs5x "
Sep  4 02:53:36.867: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-d7j6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:37.211: INFO: stderr: ""
Sep  4 02:53:37.212: INFO: stdout: ""
Sep  4 02:53:37.212: INFO: update-demo-nautilus-d7j6f is created but not running
Sep  4 02:53:42.212: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:42.552: INFO: stderr: ""
Sep  4 02:53:42.552: INFO: stdout: "update-demo-nautilus-d7j6f update-demo-nautilus-zgs5x "
Sep  4 02:53:42.552: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-d7j6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:42.878: INFO: stderr: ""
Sep  4 02:53:42.878: INFO: stdout: "true"
Sep  4 02:53:42.879: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-d7j6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:43.213: INFO: stderr: ""
Sep  4 02:53:43.213: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:53:43.213: INFO: validating pod update-demo-nautilus-d7j6f
Sep  4 02:53:43.220: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:53:43.220: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:53:43.220: INFO: update-demo-nautilus-d7j6f is verified up and running
Sep  4 02:53:43.220: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-zgs5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:43.550: INFO: stderr: ""
Sep  4 02:53:43.550: INFO: stdout: "true"
Sep  4 02:53:43.550: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-zgs5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:43.876: INFO: stderr: ""
Sep  4 02:53:43.876: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:53:43.876: INFO: validating pod update-demo-nautilus-zgs5x
Sep  4 02:53:43.882: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:53:43.882: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:53:43.882: INFO: update-demo-nautilus-zgs5x is verified up and running
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:53:43.882: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:44.211: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:53:44.211: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  4 02:53:44.211: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-447fn'
Sep  4 02:53:44.583: INFO: stderr: "No resources found.\n"
Sep  4 02:53:44.583: INFO: stdout: ""
Sep  4 02:53:44.584: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -l name=update-demo --namespace=e2e-tests-kubectl-447fn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 02:53:44.936: INFO: stderr: ""
Sep  4 02:53:44.936: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:53:44.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-447fn" for this suite.
Sep  4 02:53:50.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:53:50.989: INFO: namespace: e2e-tests-kubectl-447fn, resource: bindings, ignored listing per whitelist
Sep  4 02:53:51.095: INFO: namespace e2e-tests-kubectl-447fn deletion completed in 6.15257146s

[32mâ€¢ [SLOW TEST:15.363 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should create and stop a replication controller  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:53:51.096: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 02:53:51.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0dd1ab6-afed-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-nmln4" to be "success or failure"
Sep  4 02:53:51.276: INFO: Pod "downwardapi-volume-c0dd1ab6-afed-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.87882ms
Sep  4 02:53:53.281: INFO: Pod "downwardapi-volume-c0dd1ab6-afed-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00988978s
[1mSTEP[0m: Saw pod success
Sep  4 02:53:53.281: INFO: Pod "downwardapi-volume-c0dd1ab6-afed-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 02:53:53.285: INFO: Trying to get logs from node node3 pod downwardapi-volume-c0dd1ab6-afed-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 02:53:53.309: INFO: Waiting for pod downwardapi-volume-c0dd1ab6-afed-11e8-8336-00073e906c7f to disappear
Sep  4 02:53:53.313: INFO: Pod downwardapi-volume-c0dd1ab6-afed-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:53:53.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-nmln4" for this suite.
Sep  4 02:53:59.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:53:59.375: INFO: namespace: e2e-tests-projected-nmln4, resource: bindings, ignored listing per whitelist
Sep  4 02:53:59.469: INFO: namespace e2e-tests-projected-nmln4 deletion completed in 6.15052362s

[32mâ€¢ [SLOW TEST:8.373 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should provide podname only [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould scale a replication controller  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:53:59.469: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should scale a replication controller  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: creating a replication controller
Sep  4 02:53:59.630: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf create -f - --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:00.116: INFO: stderr: ""
Sep  4 02:54:00.116: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Sep  4 02:54:00.116: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:00.456: INFO: stderr: ""
Sep  4 02:54:00.456: INFO: stdout: "update-demo-nautilus-bzj96 update-demo-nautilus-f9f4n "
Sep  4 02:54:00.457: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-bzj96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:00.798: INFO: stderr: ""
Sep  4 02:54:00.798: INFO: stdout: ""
Sep  4 02:54:00.798: INFO: update-demo-nautilus-bzj96 is created but not running
Sep  4 02:54:05.799: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:06.134: INFO: stderr: ""
Sep  4 02:54:06.134: INFO: stdout: "update-demo-nautilus-bzj96 update-demo-nautilus-f9f4n "
Sep  4 02:54:06.134: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-bzj96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:06.462: INFO: stderr: ""
Sep  4 02:54:06.462: INFO: stdout: "true"
Sep  4 02:54:06.462: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-bzj96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:06.790: INFO: stderr: ""
Sep  4 02:54:06.790: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:54:06.791: INFO: validating pod update-demo-nautilus-bzj96
Sep  4 02:54:06.797: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:54:06.797: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:54:06.797: INFO: update-demo-nautilus-bzj96 is verified up and running
Sep  4 02:54:06.797: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-f9f4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:07.126: INFO: stderr: ""
Sep  4 02:54:07.126: INFO: stdout: "true"
Sep  4 02:54:07.126: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-f9f4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:07.449: INFO: stderr: ""
Sep  4 02:54:07.449: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:54:07.449: INFO: validating pod update-demo-nautilus-f9f4n
Sep  4 02:54:07.455: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:54:07.455: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:54:07.455: INFO: update-demo-nautilus-f9f4n is verified up and running
[1mSTEP[0m: scaling down the replication controller
Sep  4 02:54:07.455: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:08.831: INFO: stderr: ""
Sep  4 02:54:08.831: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Sep  4 02:54:08.831: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:09.169: INFO: stderr: ""
Sep  4 02:54:09.169: INFO: stdout: "update-demo-nautilus-bzj96 update-demo-nautilus-f9f4n "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
Sep  4 02:54:14.170: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:14.510: INFO: stderr: ""
Sep  4 02:54:14.510: INFO: stdout: "update-demo-nautilus-bzj96 update-demo-nautilus-f9f4n "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
Sep  4 02:54:19.510: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:19.847: INFO: stderr: ""
Sep  4 02:54:19.847: INFO: stdout: "update-demo-nautilus-f9f4n "
Sep  4 02:54:19.847: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-f9f4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:20.182: INFO: stderr: ""
Sep  4 02:54:20.182: INFO: stdout: "true"
Sep  4 02:54:20.182: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-f9f4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:20.508: INFO: stderr: ""
Sep  4 02:54:20.508: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:54:20.508: INFO: validating pod update-demo-nautilus-f9f4n
Sep  4 02:54:20.513: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:54:20.513: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:54:20.513: INFO: update-demo-nautilus-f9f4n is verified up and running
[1mSTEP[0m: scaling up the replication controller
Sep  4 02:54:20.513: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:21.899: INFO: stderr: ""
Sep  4 02:54:21.899: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Sep  4 02:54:21.899: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:22.248: INFO: stderr: ""
Sep  4 02:54:22.248: INFO: stdout: "update-demo-nautilus-c2fb2 update-demo-nautilus-f9f4n "
Sep  4 02:54:22.249: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-c2fb2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:22.577: INFO: stderr: ""
Sep  4 02:54:22.577: INFO: stdout: ""
Sep  4 02:54:22.577: INFO: update-demo-nautilus-c2fb2 is created but not running
Sep  4 02:54:27.578: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:27.920: INFO: stderr: ""
Sep  4 02:54:27.920: INFO: stdout: "update-demo-nautilus-c2fb2 update-demo-nautilus-f9f4n "
Sep  4 02:54:27.920: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-c2fb2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:28.249: INFO: stderr: ""
Sep  4 02:54:28.249: INFO: stdout: "true"
Sep  4 02:54:28.249: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-c2fb2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:28.577: INFO: stderr: ""
Sep  4 02:54:28.577: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:54:28.577: INFO: validating pod update-demo-nautilus-c2fb2
Sep  4 02:54:28.583: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:54:28.583: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:54:28.583: INFO: update-demo-nautilus-c2fb2 is verified up and running
Sep  4 02:54:28.583: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-f9f4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:28.909: INFO: stderr: ""
Sep  4 02:54:28.909: INFO: stdout: "true"
Sep  4 02:54:28.909: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods update-demo-nautilus-f9f4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:29.241: INFO: stderr: ""
Sep  4 02:54:29.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-arm64:1.0"
Sep  4 02:54:29.241: INFO: validating pod update-demo-nautilus-f9f4n
Sep  4 02:54:29.246: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 02:54:29.246: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 02:54:29.246: INFO: update-demo-nautilus-f9f4n is verified up and running
[1mSTEP[0m: using delete to clean up resources
Sep  4 02:54:29.246: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:29.577: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 02:54:29.577: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  4 02:54:29.578: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bdkz7'
Sep  4 02:54:29.927: INFO: stderr: "No resources found.\n"
Sep  4 02:54:29.927: INFO: stdout: ""
Sep  4 02:54:29.927: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf get pods -l name=update-demo --namespace=e2e-tests-kubectl-bdkz7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 02:54:30.274: INFO: stderr: ""
Sep  4 02:54:30.274: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 02:54:30.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-bdkz7" for this suite.
Sep  4 02:54:36.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 02:54:36.395: INFO: namespace: e2e-tests-kubectl-bdkz7, resource: bindings, ignored listing per whitelist
Sep  4 02:54:36.436: INFO: namespace e2e-tests-kubectl-bdkz7 deletion completed in 6.1562217s

[32mâ€¢ [SLOW TEST:36.967 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should scale a replication controller  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform rolling updates and roll backs of template modifications [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 02:54:36.436: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-gs6xr
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a new StatefulSet
Sep  4 02:54:36.619: INFO: Found 0 stateful pods, waiting for 3
Sep  4 02:54:46.626: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 02:54:46.626: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 02:54:46.626: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 02:54:46.640: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-gs6xr ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 02:54:47.315: INFO: stderr: ""
Sep  4 02:54:47.315: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 02:54:47.315: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

[1mSTEP[0m: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-arm64:0.26 to k8s.gcr.io/nginx-slim-arm64:0.27
Sep  4 02:54:57.357: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Updating Pods in reverse ordinal order
Sep  4 02:55:07.383: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf exec --namespace=e2e-tests-statefulset-gs6xr ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 02:55:08.056: INFO: stderr: ""
Sep  4 02:55:08.056: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 02:55:08.056: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 03:05:08.086: INFO: Failed waiting for state update: timed out waiting for the condition
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Sep  4 03:05:08.093: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe po ss2-0 --namespace=e2e-tests-statefulset-gs6xr'
Sep  4 03:05:08.510: INFO: stderr: ""
Sep  4 03:05:08.510: INFO: stdout: "Name:               ss2-0\nNamespace:          e2e-tests-statefulset-gs6xr\nPriority:           0\nPriorityClassName:  <none>\nNode:               node3/192.168.2.117\nStart Time:         Tue, 04 Sep 2018 02:54:36 +0000\nLabels:             baz=blah\n                    controller-revision-hash=ss2-866457fcf7\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-0\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.32.0.8\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   hyper://8d155e8b3a26d53cd97802f67904ff0e005d12e6723653175fe22540e2391d68\n    Image:          k8s.gcr.io/nginx-slim-arm64:0.26\n    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 04 Sep 2018 02:54:37 +0000\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-r9m9g (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-r9m9g:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-r9m9g\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  10m   default-scheduler  Successfully assigned e2e-tests-statefulset-gs6xr/ss2-0 to node3\n  Normal  Pulled     10m   kubelet, node3     Container image \"k8s.gcr.io/nginx-slim-arm64:0.26\" already present on machine\n  Normal  Created    10m   kubelet, node3     Created container\n  Normal  Started    10m   kubelet, node3     Started container\n"
Sep  4 03:05:08.510: INFO: 
Output of kubectl describe ss2-0:
Name:               ss2-0
Namespace:          e2e-tests-statefulset-gs6xr
Priority:           0
PriorityClassName:  <none>
Node:               node3/192.168.2.117
Start Time:         Tue, 04 Sep 2018 02:54:36 +0000
Labels:             baz=blah
                    controller-revision-hash=ss2-866457fcf7
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-0
Annotations:        <none>
Status:             Running
IP:                 10.32.0.8
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   hyper://8d155e8b3a26d53cd97802f67904ff0e005d12e6723653175fe22540e2391d68
    Image:          k8s.gcr.io/nginx-slim-arm64:0.26
    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 04 Sep 2018 02:54:37 +0000
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-r9m9g (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-r9m9g:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-r9m9g
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  10m   default-scheduler  Successfully assigned e2e-tests-statefulset-gs6xr/ss2-0 to node3
  Normal  Pulled     10m   kubelet, node3     Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
  Normal  Created    10m   kubelet, node3     Created container
  Normal  Started    10m   kubelet, node3     Started container

Sep  4 03:05:08.510: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf logs ss2-0 --namespace=e2e-tests-statefulset-gs6xr --tail=100'
Sep  4 03:05:08.866: INFO: stderr: ""
Sep  4 03:05:08.866: INFO: stdout: "10.32.0.1 - - [04/Sep/2018:03:03:29 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:30 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:31 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:32 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:33 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:34 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:35 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:36 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:37 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:38 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:39 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:40 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:41 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:42 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:43 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:44 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:45 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:46 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:47 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:48 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:49 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:50 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:51 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:52 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:53 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:54 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:55 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:56 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:57 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:58 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:59 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:00 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:01 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:02 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:03 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:04 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:05 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:06 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:07 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:08 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:09 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:10 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:11 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:12 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:13 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:14 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:15 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:16 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:17 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:18 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:19 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:20 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:21 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:22 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:23 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:24 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:25 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:26 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:27 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:28 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:29 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:30 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:31 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:32 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:33 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:34 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:35 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:36 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:37 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:38 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:39 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:40 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:41 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:42 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:43 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:44 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:45 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:46 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:47 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:48 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:49 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:50 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:51 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:52 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:53 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:54 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:55 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:56 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:57 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:58 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:59 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:00 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:01 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:02 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:03 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:04 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:05 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:06 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:07 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:08 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n"
Sep  4 03:05:08.866: INFO: 
Last 100 log lines of ss2-0:
10.32.0.1 - - [04/Sep/2018:03:03:29 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:30 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:31 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:32 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:33 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:34 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:35 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:36 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:37 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:38 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:39 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:40 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:41 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:42 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:43 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:44 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:45 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:46 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:47 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:48 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:49 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:50 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:51 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:52 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:53 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:54 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:55 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:56 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:57 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:58 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:59 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:00 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:01 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:02 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:03 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:04 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:05 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:06 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:07 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:08 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:09 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:10 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:11 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:12 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:13 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:14 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:15 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:16 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:17 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:18 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:19 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:20 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:21 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:22 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:23 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:24 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:25 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:26 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:27 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:28 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:29 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:30 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:31 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:32 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:33 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:34 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:35 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:36 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:37 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:38 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:39 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:40 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:41 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:42 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:43 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:44 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:45 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:46 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:47 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:48 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:49 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:50 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:51 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:52 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:53 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:54 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:55 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:56 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:57 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:58 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:59 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:00 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:01 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:02 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:03 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:04 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:05 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:06 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:07 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:08 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"

Sep  4 03:05:08.867: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe po ss2-1 --namespace=e2e-tests-statefulset-gs6xr'
Sep  4 03:05:09.220: INFO: stderr: ""
Sep  4 03:05:09.220: INFO: stdout: "Name:               ss2-1\nNamespace:          e2e-tests-statefulset-gs6xr\nPriority:           0\nPriorityClassName:  <none>\nNode:               node3/192.168.2.117\nStart Time:         Tue, 04 Sep 2018 02:55:17 +0000\nLabels:             baz=blah\n                    controller-revision-hash=ss2-758959485b\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-1\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.32.0.9\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   hyper://4c341a35983857200fb46252af96a074013310a44705a44951336a80c20f843b\n    Image:          k8s.gcr.io/nginx-slim-arm64:0.27\n    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:b95f8bebdc6d8a7b65f5954aa5aaea3209ad8a6af5261cf3c8cae0c0a1c0fb79\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 04 Sep 2018 02:55:18 +0000\n    Ready:          False\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-r9m9g (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  default-token-r9m9g:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-r9m9g\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type     Reason     Age                From               Message\n  ----     ------     ----               ----               -------\n  Normal   Scheduled  9m                 default-scheduler  Successfully assigned e2e-tests-statefulset-gs6xr/ss2-1 to node3\n  Normal   Pulled     9m                 kubelet, node3     Container image \"k8s.gcr.io/nginx-slim-arm64:0.27\" already present on machine\n  Normal   Created    9m                 kubelet, node3     Created container\n  Normal   Started    9m                 kubelet, node3     Started container\n  Warning  Unhealthy  4m (x300 over 9m)  kubelet, node3     Readiness probe failed: Get http://10.32.0.9:80/index.html: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n"
Sep  4 03:05:09.220: INFO: 
Output of kubectl describe ss2-1:
Name:               ss2-1
Namespace:          e2e-tests-statefulset-gs6xr
Priority:           0
PriorityClassName:  <none>
Node:               node3/192.168.2.117
Start Time:         Tue, 04 Sep 2018 02:55:17 +0000
Labels:             baz=blah
                    controller-revision-hash=ss2-758959485b
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-1
Annotations:        <none>
Status:             Running
IP:                 10.32.0.9
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   hyper://4c341a35983857200fb46252af96a074013310a44705a44951336a80c20f843b
    Image:          k8s.gcr.io/nginx-slim-arm64:0.27
    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:b95f8bebdc6d8a7b65f5954aa5aaea3209ad8a6af5261cf3c8cae0c0a1c0fb79
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 04 Sep 2018 02:55:18 +0000
    Ready:          False
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-r9m9g (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  default-token-r9m9g:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-r9m9g
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  9m                 default-scheduler  Successfully assigned e2e-tests-statefulset-gs6xr/ss2-1 to node3
  Normal   Pulled     9m                 kubelet, node3     Container image "k8s.gcr.io/nginx-slim-arm64:0.27" already present on machine
  Normal   Created    9m                 kubelet, node3     Created container
  Normal   Started    9m                 kubelet, node3     Started container
  Warning  Unhealthy  4m (x300 over 9m)  kubelet, node3     Readiness probe failed: Get http://10.32.0.9:80/index.html: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)

Sep  4 03:05:09.221: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf logs ss2-1 --namespace=e2e-tests-statefulset-gs6xr --tail=100'
Sep  4 03:05:09.570: INFO: stderr: ""
Sep  4 03:05:09.571: INFO: stdout: ""
Sep  4 03:05:09.571: INFO: 
Last 100 log lines of ss2-1:

Sep  4 03:05:09.571: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf describe po ss2-2 --namespace=e2e-tests-statefulset-gs6xr'
Sep  4 03:05:09.930: INFO: stderr: ""
Sep  4 03:05:09.930: INFO: stdout: "Name:               ss2-2\nNamespace:          e2e-tests-statefulset-gs6xr\nPriority:           0\nPriorityClassName:  <none>\nNode:               node3/192.168.2.117\nStart Time:         Tue, 04 Sep 2018 02:55:10 +0000\nLabels:             baz=blah\n                    controller-revision-hash=ss2-758959485b\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-2\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.32.0.10\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   hyper://3fae86cff5ed22466f1108eeec618526456dff4dc3f72d767dd12ffc775a071c\n    Image:          k8s.gcr.io/nginx-slim-arm64:0.27\n    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:b95f8bebdc6d8a7b65f5954aa5aaea3209ad8a6af5261cf3c8cae0c0a1c0fb79\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 04 Sep 2018 02:55:11 +0000\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-r9m9g (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-r9m9g:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-r9m9g\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  9m    default-scheduler  Successfully assigned e2e-tests-statefulset-gs6xr/ss2-2 to node3\n  Normal  Pulled     9m    kubelet, node3     Container image \"k8s.gcr.io/nginx-slim-arm64:0.27\" already present on machine\n  Normal  Created    9m    kubelet, node3     Created container\n  Normal  Started    9m    kubelet, node3     Started container\n"
Sep  4 03:05:09.930: INFO: 
Output of kubectl describe ss2-2:
Name:               ss2-2
Namespace:          e2e-tests-statefulset-gs6xr
Priority:           0
PriorityClassName:  <none>
Node:               node3/192.168.2.117
Start Time:         Tue, 04 Sep 2018 02:55:10 +0000
Labels:             baz=blah
                    controller-revision-hash=ss2-758959485b
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-2
Annotations:        <none>
Status:             Running
IP:                 10.32.0.10
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   hyper://3fae86cff5ed22466f1108eeec618526456dff4dc3f72d767dd12ffc775a071c
    Image:          k8s.gcr.io/nginx-slim-arm64:0.27
    Image ID:       docker-pullable://k8s.gcr.io/nginx-slim-arm64@sha256:b95f8bebdc6d8a7b65f5954aa5aaea3209ad8a6af5261cf3c8cae0c0a1c0fb79
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 04 Sep 2018 02:55:11 +0000
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-r9m9g (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-r9m9g:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-r9m9g
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  9m    default-scheduler  Successfully assigned e2e-tests-statefulset-gs6xr/ss2-2 to node3
  Normal  Pulled     9m    kubelet, node3     Container image "k8s.gcr.io/nginx-slim-arm64:0.27" already present on machine
  Normal  Created    9m    kubelet, node3     Created container
  Normal  Started    9m    kubelet, node3     Started container

Sep  4 03:05:09.930: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf logs ss2-2 --namespace=e2e-tests-statefulset-gs6xr --tail=100'
Sep  4 03:05:10.286: INFO: stderr: ""
Sep  4 03:05:10.286: INFO: stdout: "10.32.0.1 - - [04/Sep/2018:03:03:31 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:32 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:33 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:34 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:35 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:36 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:37 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:38 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:39 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:40 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:41 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:42 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:43 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:44 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:45 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:46 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:47 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:48 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:49 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:50 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:51 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:52 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:53 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:54 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:55 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:56 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:57 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:58 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:03:59 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:00 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:01 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:02 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:03 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:04 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:05 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:06 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:07 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:08 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:09 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:10 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:11 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:12 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:13 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:14 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:15 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:16 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:17 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:18 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:19 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:20 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:21 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:22 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:23 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:24 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:25 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:26 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:27 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:28 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:29 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:30 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:31 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:32 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:33 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:34 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:35 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:36 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:37 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:38 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:39 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:40 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:41 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:42 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:43 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:44 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:45 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:46 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:47 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:48 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:49 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:50 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:51 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:52 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:53 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:54 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:55 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:56 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:57 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:58 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:04:59 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:00 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:01 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:02 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:03 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:04 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:05 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:06 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:07 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:08 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:09 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n10.32.0.1 - - [04/Sep/2018:03:05:10 +0000] \"GET /index.html HTTP/1.1\" 200 612 \"-\" \"kube-probe/1.11\"\n"
Sep  4 03:05:10.287: INFO: 
Last 100 log lines of ss2-2:
10.32.0.1 - - [04/Sep/2018:03:03:31 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:32 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:33 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:34 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:35 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:36 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:37 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:38 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:39 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:40 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:41 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:42 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:43 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:44 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:45 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:46 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:47 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:48 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:49 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:50 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:51 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:52 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:53 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:54 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:55 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:56 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:57 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:58 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:03:59 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:00 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:01 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:02 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:03 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:04 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:05 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:06 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:07 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:08 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:09 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:10 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:11 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:12 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:13 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:14 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:15 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:16 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:17 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:18 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:19 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:20 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:21 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:22 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:23 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:24 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:25 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:26 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:27 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:28 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:29 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:30 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:31 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:32 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:33 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:34 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:35 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:36 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:37 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:38 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:39 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:40 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:41 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:42 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:43 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:44 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:45 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:46 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:47 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:48 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:49 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:50 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:51 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:52 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:53 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:54 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:55 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:56 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:57 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:58 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:04:59 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:00 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:01 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:02 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:03 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:04 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:05 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:06 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:07 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:08 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:09 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"
10.32.0.1 - - [04/Sep/2018:03:05:10 +0000] "GET /index.html HTTP/1.1" 200 612 "-" "kube-probe/1.11"

Sep  4 03:05:10.287: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gs6xr
Sep  4 03:05:10.292: INFO: Scaling statefulset ss2 to 0
Sep  4 03:05:20.314: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 03:05:20.318: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
[1mSTEP[0m: Collecting events from namespace "e2e-tests-statefulset-gs6xr".
[1mSTEP[0m: Found 33 events.
Sep  4 03:05:20.341: INFO: At 2018-09-04 02:54:36 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-0 in StatefulSet ss2 successful
Sep  4 03:05:20.341: INFO: At 2018-09-04 02:54:36 +0000 UTC - event for ss2-0: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-gs6xr/ss2-0 to node3
Sep  4 03:05:20.341: INFO: At 2018-09-04 02:54:37 +0000 UTC - event for ss2-0: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
Sep  4 03:05:20.341: INFO: At 2018-09-04 02:54:37 +0000 UTC - event for ss2-0: {kubelet node3} Created: Created container
Sep  4 03:05:20.341: INFO: At 2018-09-04 02:54:37 +0000 UTC - event for ss2-0: {kubelet node3} Started: Started container
Sep  4 03:05:20.341: INFO: At 2018-09-04 02:54:39 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-1 in StatefulSet ss2 successful
Sep  4 03:05:20.341: INFO: At 2018-09-04 02:54:39 +0000 UTC - event for ss2-1: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-gs6xr/ss2-1 to node3
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:39 +0000 UTC - event for ss2-1: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:39 +0000 UTC - event for ss2-1: {kubelet node3} Created: Created container
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:40 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-2 in StatefulSet ss2 successful
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:40 +0000 UTC - event for ss2-1: {kubelet node3} Started: Started container
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:40 +0000 UTC - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-gs6xr/ss2-2 to node3
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:41 +0000 UTC - event for ss2-2: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.26" already present on machine
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:41 +0000 UTC - event for ss2-2: {kubelet node3} Created: Created container
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:41 +0000 UTC - event for ss2-2: {kubelet node3} Started: Started container
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:54:47 +0000 UTC - event for ss2-1: {kubelet node3} Unhealthy: Readiness probe failed: HTTP probe failed with statuscode: 404
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:08 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-2 in StatefulSet ss2 successful
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:08 +0000 UTC - event for ss2-2: {kubelet node3} Killing: Killing container with id hyper://nginx:Need to kill Pod
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:10 +0000 UTC - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-gs6xr/ss2-2 to node3
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:11 +0000 UTC - event for ss2-2: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.27" already present on machine
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:11 +0000 UTC - event for ss2-2: {kubelet node3} Created: Created container
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:11 +0000 UTC - event for ss2-2: {kubelet node3} Started: Started container
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:12 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-1 in StatefulSet ss2 successful
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:12 +0000 UTC - event for ss2-1: {kubelet node3} Killing: Killing container with id hyper://nginx:Need to kill Pod
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:17 +0000 UTC - event for ss2-1: {default-scheduler } Scheduled: Successfully assigned e2e-tests-statefulset-gs6xr/ss2-1 to node3
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:18 +0000 UTC - event for ss2-1: {kubelet node3} Started: Started container
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:18 +0000 UTC - event for ss2-1: {kubelet node3} Pulled: Container image "k8s.gcr.io/nginx-slim-arm64:0.27" already present on machine
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:18 +0000 UTC - event for ss2-1: {kubelet node3} Created: Created container
Sep  4 03:05:20.342: INFO: At 2018-09-04 02:55:19 +0000 UTC - event for ss2-1: {kubelet node3} Unhealthy: Readiness probe failed: Get http://10.32.0.9:80/index.html: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Sep  4 03:05:20.342: INFO: At 2018-09-04 03:05:10 +0000 UTC - event for ss2-2: {kubelet node3} Killing: Killing container with id hyper://nginx:Need to kill Pod
Sep  4 03:05:20.342: INFO: At 2018-09-04 03:05:13 +0000 UTC - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-0 in StatefulSet ss2 successful
Sep  4 03:05:20.342: INFO: At 2018-09-04 03:05:14 +0000 UTC - event for ss2-0: {kubelet node3} Killing: Killing container with id hyper://nginx:Need to kill Pod
Sep  4 03:05:20.343: INFO: At 2018-09-04 03:05:14 +0000 UTC - event for ss2-0: {kubelet node3} Unhealthy: Readiness probe failed: Get http://10.32.0.8:80/index.html: dial tcp 10.32.0.8:80: connect: connection refused
Sep  4 03:05:20.357: INFO: POD                            NODE   PHASE    GRACE  CONDITIONS
Sep  4 03:05:20.357: INFO: coredns-78fcdf6894-f55jj       node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:57:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:46:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:57:03 +0000 UTC  }]
Sep  4 03:05:20.357: INFO: coredns-78fcdf6894-vlxkz       node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:57:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:46:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:57:03 +0000 UTC  }]
Sep  4 03:05:20.358: INFO: etcd-node3                     node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  }]
Sep  4 03:05:20.358: INFO: kube-apiserver-node3           node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  }]
Sep  4 03:05:20.358: INFO: kube-controller-manager-node3  node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  }]
Sep  4 03:05:20.358: INFO: kube-proxy-d6xgq               node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:55:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:46:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:55:38 +0000 UTC  }]
Sep  4 03:05:20.358: INFO: kube-scheduler-node3           node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:45:25 +0000 UTC  }]
Sep  4 03:05:20.358: INFO: weave-net-qrwm8                node3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:55:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-09-03 03:46:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-09-01 03:55:38 +0000 UTC  }]
Sep  4 03:05:20.358: INFO: 
Sep  4 03:05:20.363: INFO: 
Logging node info for node node3
Sep  4 03:05:20.368: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:node3,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/node3,UID:d76c0c97-ad9a-11e8-a7d7-1e59e086a4f1,ResourceVersion:181008,Generation:0,CreationTimestamp:2018-09-01 03:55:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: arm64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: node3,node-role.kubernetes.io/master: ,},Annotations:map[string]string{kubeadm.alpha.kubernetes.io/cri-socket: /var/run/frakti.sock,node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:10.244.0.0/24,DoNotUse_ExternalID:,ProviderID:,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{82538430464 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{67535159296 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{74284587295 0} {<nil>} 74284587295 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{67430301696 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2018-09-03 03:46:46 +0000 UTC 2018-09-03 03:46:46 +0000 UTC WeaveIsUp Weave pod has set this} {OutOfDisk False 2018-09-04 03:05:11 +0000 UTC 2018-09-01 03:55:11 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-09-04 03:05:11 +0000 UTC 2018-09-01 03:55:11 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-09-04 03:05:11 +0000 UTC 2018-09-01 03:55:11 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-09-04 03:05:11 +0000 UTC 2018-09-01 03:55:11 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-09-04 03:05:11 +0000 UTC 2018-09-04 01:30:47 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 192.168.2.117} {Hostname node3}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:373be5c264ac4b78a49077a4b4ded99c,SystemUUID:373be5c264ac4b78a49077a4b4ded99c,BootID:c3229fda-d628-476e-9988-7af0bb46b762,KernelVersion:4.4.58-20171215.kylin.server.YUN+-generic,OSImage:Kylin 4.0.2,ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.11.2,KubeProxyVersion:v1.11.2,OperatingSystem:linux,Architecture:arm64,},Images:[{[k8s.gcr.io/kube-cross@sha256:0c5809a727c38458e9a63b486cf83c504a24ff561d63a031d31e613f6ad50282 k8s.gcr.io/kube-cross:v1.10.2-1] 2076524551} {[mrdreambot/arm64-mysql@sha256:872464bd31f5db2ecfce15824c80a0b78ace914e80e78a0e98d2d9ef7e8bbb79 mrdreambot/arm64-mysql:latest] 529883867} {[bobsense/mysql@sha256:a20cd35207c46b0400ac48fdf21ebb8e432fa5b597eb5f4b6ec6a634ecc26a8a bobsense/mysql:latest] 529882429} {[mariadb@sha256:358f6b50afd9c25707e97869f0c57de802c53973a90a2ff49e283501fccce1b2 mariadb:10.1.14] 387643618} {[wordpress@sha256:b0460dba11737144b232a7794403d4052982f2332caeea82f618fc98d0547387 wordpress:latest] 367973768} {[mariadb@sha256:edef80de393cf4a79504168c663f8b0c6b15060333e5a7d7aee3dc0a4de6e927 mariadb:latest] 348940495} {[hyperhq/mariadb-arm64v8@sha256:bcf8c747e35eddfcd36ffc6011b00ececb56fe467afb290280d80709299fd80d hyperhq/mariadb-arm64v8:10.3-1] 348507360} {[hyperhq/mariadb-arm64v8:10.3] 348507300} {[hyperhq/mariadb-arm64v8@sha256:720d233b09adbea084c15cfa4909008a2df201b300b10c9fd39464bce60af0db hyperhq/mariadb-arm64v8:10.3-2] 348507153} {[bobsense/nginx-arm64@sha256:224f3b5fd469754e5e701bedd28c633c92ba21c00d2b0e9376eaa4adb38b5603 bobsense/nginx-arm64:latest] 338655564} {[gcr.io/google-samples/gb-frontend-arm64@sha256:9587be21f54a9dc04e1f37b83a9d120231b205385d8deba0682d6fb22088e7c9 gcr.io/google-samples/gb-frontend-arm64:v5] 337228898} {[lsioarmhf/mariadb-aarch64@sha256:b2a1bd89d60c579f07ae1837280a2b3b5f35f11f756b9aa61e6a025af03ddf87 lsioarmhf/mariadb-aarch64:latest] 327268490} {[ebspace/aarch64-mysql@sha256:d9f5f5d222a155c930e3837976b5b457e48c000cf34e6919d0f8a0b73dc39965 ebspace/aarch64-mysql:latest] 262591608} {[tobi312/rpi-mysql@sha256:2f0b069765901afbb162838359778088b8d9fdba30b201d5cf51381ec008802a tobi312/rpi-mysql:latest] 256067342} {[k8s.gcr.io/volume-nfs@sha256:83ba87be13a6f74361601c8614527e186ca67f49091e2d0d4ae8a8da67c403ee k8s.gcr.io/volume-nfs:0.8] 247146979} {[postgres@sha256:d9c44f9fc460dd8962c388eacf88a0e252b858ccdf33bc223f68112617e81fc9 postgres:10] 233845668} {[k8s.gcr.io/etcd-arm64@sha256:f0b7368ebb28e6226ab3b4dbce4b5c6d77dab7b5f6579b08fd645c00f7b100ff k8s.gcr.io/etcd-arm64:3.2.18] 229927444} {[k8s.gcr.io/kube-apiserver-arm64@sha256:5c77134dc174453fc0d900ee5cdcb7b488131a0edb934ae8e859a263f8ee55da k8s.gcr.io/kube-apiserver-arm64:v1.10.4] 218561963} {[k8s.gcr.io/kube-apiserver-arm64@sha256:ab41e3e38792750fa122dbeacf7d0d3d52b7ccc466f254c460733846da0ce0c9 k8s.gcr.io/kube-apiserver-arm64:v1.10.3] 218559018} {[hypriot/rpi-mysql@sha256:c1567c885cf560da66a647f91f7e16bfeea2968895f859b5732583a8db3570ea hypriot/rpi-mysql:latest] 209339591} {[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils-arm64@sha256:92105b23ab1bcc1f72b7deeb4b7d72b27b4ba9a47b292fbd4f58f4080f0621a2 gcr.io/kubernetes-e2e-test-images/jessie-dnsutils-arm64:1.0] 193983470} {[k8s.gcr.io/kube-apiserver-arm64@sha256:31fa4a96f582953034fb2906bd2e557620943ebaa2c2f74ee719c89a9bffb0d4 k8s.gcr.io/kube-apiserver-arm64:v1.11.2] 185805939} {[k8s.gcr.io/etcd-arm64@sha256:c6418130352f3632f3858ff466f7fdcde5c2867d9471f40dbb99227ccbb6d458 k8s.gcr.io/etcd-arm64:3.1.12] 180941491} {[functions/faas-netesd@sha256:05072b13c8127d53b48466f6b16beae997ff008e13a74cdb5da64ca2f5708062 functions/faas-netesd:arm64-0.3-alpha6] 154407667} {[k8s.gcr.io/kube-controller-manager-arm64@sha256:af5e55e15e5ab06999716ef72792b0abed63c9fc972db99120b2c40febaf69a7 k8s.gcr.io/kube-controller-manager-arm64:v1.11.2] 153069058} {[functions/faas-netesd@sha256:0903fd0a2c6010fcef6f42eda8fdc22bf4aecc31571b7ab6f461041497f34aa4 functions/faas-netesd:0.4.3-arm64] 148751197} {[k8s.gcr.io/kube-controller-manager-arm64@sha256:138de23ccbdfab3f4e76e05c290aab26c9127a853db8a0cbc2d816b31d5aebbd k8s.gcr.io/kube-controller-manager-arm64:v1.10.4] 142046988} {[k8s.gcr.io/kube-controller-manager-arm64@sha256:4f99bac50d84f8757ef06d06e68eee0aa042fdb5969c300d23ad1ae3b1f914f5 k8s.gcr.io/kube-controller-manager-arm64:v1.10.3] 142046537} {[weaveworks/weave-kube@sha256:3c45b339ab2dc9c11c9c745e44afce27806dc1d8ecd1da84a88deb36756ac713 weaveworks/weave-kube:2.4.0] 131119125} {[k8s.gcr.io/nginx-slim-arm64@sha256:b95f8bebdc6d8a7b65f5954aa5aaea3209ad8a6af5261cf3c8cae0c0a1c0fb79 k8s.gcr.io/nginx-slim-arm64:0.27] 126129565} {[k8s.gcr.io/nginx-slim-arm64@sha256:ef47cf0719891fe4b84467af77f8e13618b05965b6663945411e1e11c15ffa14 k8s.gcr.io/nginx-slim-arm64:0.26] 126125347} {[hyperhq/postgres-wordpress-arm:latest] 110592210} {[wordpress@sha256:3c22b14d0269bd50b2011f6d749d8bee68e328167f774bef8bf11f5878a6035d wordpress:4.9-fpm-alpine] 107828983} {[functions/gateway@sha256:01aea2775bb40d69588d2c6e83e8b9ea5009b9f405b140e643eb4be2a775814d functions/gateway:arm64-0.6.6-beta2] 106004910} {[k8s.gcr.io/kube-proxy-arm64@sha256:3bb2bfdc016ae46d131af74040bec2c48134c733ae90fead4da3568014fb450a k8s.gcr.io/kube-proxy-arm64:v1.11.2] 102835336} {[nginx@sha256:3e2ffcf0edca2a4e9b24ca442d227baea7b7f0e33ad654ef1eb806fbd9bedcf0 nginx:latest] 102594503} {[k8s.gcr.io/kube-proxy-arm64@sha256:f024ad81abe8b9bf473c0b8ff5c96723505b8a592379d606038499f8a77f663b k8s.gcr.io/kube-proxy-arm64:v1.10.4] 100601489} {[k8s.gcr.io/kube-proxy-arm64@sha256:b21badcd0799bb7495ebcbc17557861384da1eac42d6527937a8aaed0c329d6c k8s.gcr.io/kube-proxy-arm64:v1.10.3] 100598796} {[k8s.gcr.io/echoserver@sha256:d2a8af33e4e6dc7f18fc8d0cd345b2c893922083c6e2c2cbf24a2efcaa7aa3ba k8s.gcr.io/echoserver:1.6] 95247805} {[gcr.io/google-samples/gb-redisslave-arm64@sha256:2420127acd816ebbdbaa33cab372493859c1d40b3a2d5d6fc05bc38887ad9511 gcr.io/google-samples/gb-redisslave-arm64:v2] 94082700} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91641000} {[<none>@<none> <none>:<none>] 76567645} {[ubuntu@sha256:3f119dc0737f57f704ebecac8a6d8477b0f6ca1ca0332c7ee1395ed2c6a82be7 ubuntu:bionic] 76171071} {[k8s.gcr.io/kube-scheduler-arm64@sha256:3ece3012cc6fedf5193fd1c80aee4b6da2835098b7799d4940fb4a79fc1be0ee k8s.gcr.io/kube-scheduler-arm64:v1.11.2] 56216691} {[weaveworks/weave-npc@sha256:715b03e14874355f1f793f7bc11d843a00b390b2806bd996f1e47e8acb1020aa weaveworks/weave-npc:2.4.0] 51096437} {[k8s.gcr.io/k8s-dns-kube-dns-arm64@sha256:9bcc8fda237765f8b8f8fdf5af220b856adbc8b56d72dc4f336d44510d1749d9 k8s.gcr.io/k8s-dns-kube-dns-arm64:1.14.8] 49350613} {[k8s.gcr.io/kube-scheduler-arm64@sha256:fbff009828de95e14856325ebcfc6e1c0cdb456a052c62ba0c64221773c68686 k8s.gcr.io/kube-scheduler-arm64:v1.10.4] 48502539} {[k8s.gcr.io/kube-scheduler-arm64@sha256:6847ebb67c5a2928d8997d98001eb107a50601e85e07c3245f72b14df4518616 k8s.gcr.io/kube-scheduler-arm64:v1.10.3] 48434682} {[k8s.gcr.io/k8s-dns-dnsmasq-nanny-arm64@sha256:35ac228d45ab5f4209f25317506fa53b762f6d8ad333d1ff795393fa6e97b29c k8s.gcr.io/k8s-dns-dnsmasq-nanny-arm64:1.14.8] 42547598} {[k8s.gcr.io/k8s-dns-sidecar-arm64@sha256:b2c1e4e04d77ed564e918ebd16443dfb2217653b58293e616e36f034068d6da3 k8s.gcr.io/k8s-dns-sidecar-arm64:1.14.8] 41256276}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Sep  4 03:05:20.369: INFO: 
Logging kubelet events for node node3
Sep  4 03:05:20.374: INFO: 
Logging pods the kubelet thinks is on node node3
Sep  4 03:05:20.386: INFO: coredns-78fcdf6894-vlxkz started at 2018-09-01 03:57:03 +0000 UTC (0+1 container statuses recorded)
Sep  4 03:05:20.386: INFO: 	Container coredns ready: true, restart count 1
Sep  4 03:05:20.386: INFO: kube-proxy-d6xgq started at 2018-09-01 03:55:38 +0000 UTC (0+1 container statuses recorded)
Sep  4 03:05:20.386: INFO: 	Container kube-proxy ready: true, restart count 1
Sep  4 03:05:20.386: INFO: kube-apiserver-node3 started at <nil> (0+0 container statuses recorded)
Sep  4 03:05:20.386: INFO: kube-controller-manager-node3 started at <nil> (0+0 container statuses recorded)
Sep  4 03:05:20.386: INFO: kube-scheduler-node3 started at <nil> (0+0 container statuses recorded)
Sep  4 03:05:20.386: INFO: etcd-node3 started at <nil> (0+0 container statuses recorded)
Sep  4 03:05:20.386: INFO: weave-net-qrwm8 started at 2018-09-01 03:55:38 +0000 UTC (0+2 container statuses recorded)
Sep  4 03:05:20.386: INFO: 	Container weave ready: true, restart count 2
Sep  4 03:05:20.386: INFO: 	Container weave-npc ready: true, restart count 1
Sep  4 03:05:20.386: INFO: coredns-78fcdf6894-f55jj started at 2018-09-01 03:57:03 +0000 UTC (0+1 container statuses recorded)
Sep  4 03:05:20.386: INFO: 	Container coredns ready: true, restart count 1
W0904 03:05:20.392183   10499 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 03:05:20.442: INFO: 
Latency metrics for node node3
[1mSTEP[0m: Dumping a list of prepulled images on each node...
Sep  4 03:05:20.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-gs6xr" for this suite.
Sep  4 03:05:26.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:05:26.525: INFO: namespace: e2e-tests-statefulset-gs6xr, resource: bindings, ignored listing per whitelist
Sep  4 03:05:26.607: INFO: namespace e2e-tests-statefulset-gs6xr deletion completed in 6.15331674s

[91m[1mâ€¢ Failure [650.171 seconds][0m
[sig-apps] StatefulSet
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    [91m[1mshould perform rolling updates and roll backs of template modifications [Conformance] [It][0m
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m

    [91mSep  4 03:05:08.086: Failed waiting for state update: timed out waiting for the condition[0m

    /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/statefulset_utils.go:339
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:05:26.608: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-5f6bd28b-afef-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 03:05:26.788: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5f6c9167-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-qq5tf" to be "success or failure"
Sep  4 03:05:26.792: INFO: Pod "pod-projected-secrets-5f6c9167-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.48548ms
Sep  4 03:05:28.797: INFO: Pod "pod-projected-secrets-5f6c9167-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00966888s
[1mSTEP[0m: Saw pod success
Sep  4 03:05:28.797: INFO: Pod "pod-projected-secrets-5f6c9167-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:05:28.802: INFO: Trying to get logs from node node3 pod pod-projected-secrets-5f6c9167-afef-11e8-8336-00073e906c7f container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:05:28.826: INFO: Waiting for pod pod-projected-secrets-5f6c9167-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:05:28.830: INFO: Pod pod-projected-secrets-5f6c9167-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:05:28.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-qq5tf" for this suite.
Sep  4 03:05:34.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:05:34.953: INFO: namespace: e2e-tests-projected-qq5tf, resource: bindings, ignored listing per whitelist
Sep  4 03:05:34.990: INFO: namespace e2e-tests-projected-qq5tf deletion completed in 6.15471498s

[32mâ€¢ [SLOW TEST:8.382 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0777,default) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:05:34.991: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0777 on node default medium
Sep  4 03:05:35.159: INFO: Waiting up to 5m0s for pod "pod-646a13b5-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-xmxpn" to be "success or failure"
Sep  4 03:05:35.164: INFO: Pod "pod-646a13b5-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.55456ms
Sep  4 03:05:37.169: INFO: Pod "pod-646a13b5-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00966652s
[1mSTEP[0m: Saw pod success
Sep  4 03:05:37.169: INFO: Pod "pod-646a13b5-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:05:37.174: INFO: Trying to get logs from node node3 pod pod-646a13b5-afef-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:05:37.197: INFO: Waiting for pod pod-646a13b5-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:05:37.202: INFO: Pod pod-646a13b5-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:05:37.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-xmxpn" for this suite.
Sep  4 03:05:43.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:05:43.321: INFO: namespace: e2e-tests-emptydir-xmxpn, resource: bindings, ignored listing per whitelist
Sep  4 03:05:43.362: INFO: namespace e2e-tests-emptydir-xmxpn deletion completed in 6.15504232s

[32mâ€¢ [SLOW TEST:8.372 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0777,default) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:05:43.363: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating the pod
Sep  4 03:05:48.079: INFO: Successfully updated pod "labelsupdate6968de0f-afef-11e8-8336-00073e906c7f"
[AfterEach] [sig-storage] Downward API volume
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:05:50.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-rljft" for this suite.
Sep  4 03:06:12.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:06:12.204: INFO: namespace: e2e-tests-downward-api-rljft, resource: bindings, ignored listing per whitelist
Sep  4 03:06:12.265: INFO: namespace e2e-tests-downward-api-rljft deletion completed in 22.15267408s

[32mâ€¢ [SLOW TEST:28.902 seconds][0m
[sig-storage] Downward API volume
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33[0m
  should update labels on modification [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:06:12.265: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating pod liveness-exec in namespace e2e-tests-container-probe-74v2g
Sep  4 03:06:24.451: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-74v2g
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Sep  4 03:06:24.455: INFO: Initial restart count of pod liveness-exec is 0
Sep  4 03:07:24.609: INFO: Restart count of pod e2e-tests-container-probe-74v2g/liveness-exec is now 1 (1m0.15332892s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:07:24.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-74v2g" for this suite.
Sep  4 03:07:30.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:07:30.700: INFO: namespace: e2e-tests-container-probe-74v2g, resource: bindings, ignored listing per whitelist
Sep  4 03:07:30.779: INFO: namespace e2e-tests-container-probe-74v2g deletion completed in 6.15302784s

[32mâ€¢ [SLOW TEST:78.514 seconds][0m
[k8s.io] Probing container
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable from pods in env vars [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-api-machinery] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:07:30.779: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating secret with name secret-test-a96f6f51-afef-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 03:07:30.962: INFO: Waiting up to 5m0s for pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-secrets-8hfvm" to be "success or failure"
Sep  4 03:07:30.967: INFO: Pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.56262ms
Sep  4 03:07:32.972: INFO: Pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00938564s
Sep  4 03:07:34.977: INFO: Pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01414502s
Sep  4 03:07:36.981: INFO: Pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01898516s
Sep  4 03:07:38.986: INFO: Pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02379094s
Sep  4 03:07:40.991: INFO: Pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02852516s
Sep  4 03:07:42.996: INFO: Pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03319202s
[1mSTEP[0m: Saw pod success
Sep  4 03:07:42.996: INFO: Pod "pod-secrets-a9703663-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:07:43.000: INFO: Trying to get logs from node node3 pod pod-secrets-a9703663-afef-11e8-8336-00073e906c7f container secret-env-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:07:43.023: INFO: Waiting for pod pod-secrets-a9703663-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:07:43.029: INFO: Pod pod-secrets-a9703663-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:07:43.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-8hfvm" for this suite.
Sep  4 03:07:49.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:07:49.175: INFO: namespace: e2e-tests-secrets-8hfvm, resource: bindings, ignored listing per whitelist
Sep  4 03:07:49.183: INFO: namespace e2e-tests-secrets-8hfvm deletion completed in 6.14910018s

[32mâ€¢ [SLOW TEST:18.404 seconds][0m
[sig-api-machinery] Secrets
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30[0m
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0644,tmpfs) [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:07:49.184: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test emptydir 0644 on tmpfs
Sep  4 03:07:49.360: INFO: Waiting up to 5m0s for pod "pod-b4677477-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-emptydir-zs4jt" to be "success or failure"
Sep  4 03:07:49.365: INFO: Pod "pod-b4677477-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.86632ms
Sep  4 03:07:51.370: INFO: Pod "pod-b4677477-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01001072s
[1mSTEP[0m: Saw pod success
Sep  4 03:07:51.370: INFO: Pod "pod-b4677477-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:07:51.375: INFO: Trying to get logs from node node3 pod pod-b4677477-afef-11e8-8336-00073e906c7f container test-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:07:51.431: INFO: Waiting for pod pod-b4677477-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:07:51.435: INFO: Pod pod-b4677477-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:07:51.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-zs4jt" for this suite.
Sep  4 03:07:57.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:07:57.541: INFO: namespace: e2e-tests-emptydir-zs4jt, resource: bindings, ignored listing per whitelist
Sep  4 03:07:57.594: INFO: namespace e2e-tests-emptydir-zs4jt deletion completed in 6.153353s

[32mâ€¢ [SLOW TEST:8.410 seconds][0m
[sig-storage] EmptyDir volumes
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:07:57.595: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 03:07:57.763: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b96984d6-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-svk9f" to be "success or failure"
Sep  4 03:07:57.769: INFO: Pod "downwardapi-volume-b96984d6-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.32754ms
Sep  4 03:07:59.774: INFO: Pod "downwardapi-volume-b96984d6-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01076224s
[1mSTEP[0m: Saw pod success
Sep  4 03:07:59.774: INFO: Pod "downwardapi-volume-b96984d6-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:07:59.779: INFO: Trying to get logs from node node3 pod downwardapi-volume-b96984d6-afef-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:07:59.803: INFO: Waiting for pod downwardapi-volume-b96984d6-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:07:59.808: INFO: Pod downwardapi-volume-b96984d6-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:07:59.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-svk9f" for this suite.
Sep  4 03:08:05.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:08:05.860: INFO: namespace: e2e-tests-projected-svk9f, resource: bindings, ignored listing per whitelist
Sep  4 03:08:05.962: INFO: namespace e2e-tests-projected-svk9f deletion completed in 6.1489362s

[32mâ€¢ [SLOW TEST:8.367 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should provide container's memory request [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume as non-root [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:08:05.962: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-test-volume-be677210-afef-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 03:08:06.142: INFO: Waiting up to 5m0s for pod "pod-configmaps-be683f67-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-4p595" to be "success or failure"
Sep  4 03:08:06.147: INFO: Pod "pod-configmaps-be683f67-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.58668ms
Sep  4 03:08:08.152: INFO: Pod "pod-configmaps-be683f67-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00963226s
[1mSTEP[0m: Saw pod success
Sep  4 03:08:08.152: INFO: Pod "pod-configmaps-be683f67-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:08:08.156: INFO: Trying to get logs from node node3 pod pod-configmaps-be683f67-afef-11e8-8336-00073e906c7f container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:08:08.180: INFO: Waiting for pod pod-configmaps-be683f67-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:08:08.184: INFO: Pod pod-configmaps-be683f67-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:08:08.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-4p595" for this suite.
Sep  4 03:08:14.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:08:14.251: INFO: namespace: e2e-tests-configmap-4p595, resource: bindings, ignored listing per whitelist
Sep  4 03:08:14.338: INFO: namespace e2e-tests-configmap-4p595 deletion completed in 6.14884848s

[32mâ€¢ [SLOW TEST:8.376 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node with explicit kubelet port using proxy subresource  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] version v1
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:08:14.339: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 03:08:14.516: INFO: (0) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 11.13826ms)
Sep  4 03:08:14.524: INFO: (1) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 7.48118ms)
Sep  4 03:08:14.531: INFO: (2) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 7.15506ms)
Sep  4 03:08:14.538: INFO: (3) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.9559ms)
Sep  4 03:08:14.545: INFO: (4) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.80024ms)
Sep  4 03:08:14.552: INFO: (5) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.78096ms)
Sep  4 03:08:14.559: INFO: (6) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.84092ms)
Sep  4 03:08:14.566: INFO: (7) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.90046ms)
Sep  4 03:08:14.573: INFO: (8) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.90542ms)
Sep  4 03:08:14.580: INFO: (9) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.94282ms)
Sep  4 03:08:14.587: INFO: (10) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.95274ms)
Sep  4 03:08:14.594: INFO: (11) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.98312ms)
Sep  4 03:08:14.601: INFO: (12) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.78856ms)
Sep  4 03:08:14.607: INFO: (13) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.69468ms)
Sep  4 03:08:14.614: INFO: (14) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.83864ms)
Sep  4 03:08:14.621: INFO: (15) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.79372ms)
Sep  4 03:08:14.628: INFO: (16) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.86432ms)
Sep  4 03:08:14.635: INFO: (17) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.67102ms)
Sep  4 03:08:14.642: INFO: (18) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 7.05904ms)
Sep  4 03:08:14.649: INFO: (19) /api/v1/nodes/node3:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 6.95402ms)
[AfterEach] version v1
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:08:14.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-wzzlx" for this suite.
Sep  4 03:08:20.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:08:20.798: INFO: namespace: e2e-tests-proxy-wzzlx, resource: bindings, ignored listing per whitelist
Sep  4 03:08:20.802: INFO: namespace e2e-tests-proxy-wzzlx deletion completed in 6.1478425s

[32mâ€¢ [SLOW TEST:6.464 seconds][0m
[sig-network] Proxy
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:08:20.803: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-c740be44-afef-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume secrets
Sep  4 03:08:20.989: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c741a420-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-jxph2" to be "success or failure"
Sep  4 03:08:20.995: INFO: Pod "pod-projected-secrets-c741a420-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.78742ms
Sep  4 03:08:23.000: INFO: Pod "pod-projected-secrets-c741a420-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0110146s
[1mSTEP[0m: Saw pod success
Sep  4 03:08:23.000: INFO: Pod "pod-projected-secrets-c741a420-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:08:23.004: INFO: Trying to get logs from node node3 pod pod-projected-secrets-c741a420-afef-11e8-8336-00073e906c7f container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:08:23.029: INFO: Waiting for pod pod-projected-secrets-c741a420-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:08:23.033: INFO: Pod pod-projected-secrets-c741a420-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:08:23.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-jxph2" for this suite.
Sep  4 03:08:29.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:08:29.090: INFO: namespace: e2e-tests-projected-jxph2, resource: bindings, ignored listing per whitelist
Sep  4 03:08:29.186: INFO: namespace e2e-tests-projected-jxph2 deletion completed in 6.1482788s

[32mâ€¢ [SLOW TEST:8.384 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's command [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Variable Expansion
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:08:29.187: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test substitution in container's command
Sep  4 03:08:29.360: INFO: Waiting up to 5m0s for pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-var-expansion-q4jmx" to be "success or failure"
Sep  4 03:08:29.365: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.83764ms
Sep  4 03:08:31.370: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0097699s
Sep  4 03:08:33.375: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01478866s
Sep  4 03:08:35.380: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01963888s
Sep  4 03:08:37.385: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02443714s
Sep  4 03:08:39.389: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02913766s
Sep  4 03:08:41.394: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.03402778s
Sep  4 03:08:43.399: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.03921274s
Sep  4 03:08:45.404: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.0439084s
[1mSTEP[0m: Saw pod success
Sep  4 03:08:45.404: INFO: Pod "var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:08:45.408: INFO: Trying to get logs from node node3 pod var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:08:45.483: INFO: Waiting for pod var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:08:45.488: INFO: Pod var-expansion-cc3ee5a2-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:08:45.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-q4jmx" for this suite.
Sep  4 03:08:51.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:08:51.620: INFO: namespace: e2e-tests-var-expansion-q4jmx, resource: bindings, ignored listing per whitelist
Sep  4 03:08:51.649: INFO: namespace e2e-tests-var-expansion-q4jmx deletion completed in 6.15445506s

[32mâ€¢ [SLOW TEST:22.463 seconds][0m
[k8s.io] Variable Expansion
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:08:51.650: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Sep  4 03:08:51.827: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9a31cd7-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-cl6vl" to be "success or failure"
Sep  4 03:08:51.832: INFO: Pod "downwardapi-volume-d9a31cd7-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.6872ms
Sep  4 03:08:53.837: INFO: Pod "downwardapi-volume-d9a31cd7-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00996498s
[1mSTEP[0m: Saw pod success
Sep  4 03:08:53.837: INFO: Pod "downwardapi-volume-d9a31cd7-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:08:53.842: INFO: Trying to get logs from node node3 pod downwardapi-volume-d9a31cd7-afef-11e8-8336-00073e906c7f container client-container: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:08:53.866: INFO: Waiting for pod downwardapi-volume-d9a31cd7-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:08:53.870: INFO: Pod downwardapi-volume-d9a31cd7-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:08:53.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-cl6vl" for this suite.
Sep  4 03:08:59.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:08:59.986: INFO: namespace: e2e-tests-projected-cl6vl, resource: bindings, ignored listing per whitelist
Sep  4 03:09:00.030: INFO: namespace e2e-tests-projected-cl6vl deletion completed in 6.15470122s

[32mâ€¢ [SLOW TEST:8.380 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should provide container's memory limit [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl api-versions[0m 
  [1mshould check if v1 is in available api versions  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:09:00.030: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: validating api versions
Sep  4 03:09:00.192: INFO: Running '/root/gopath/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://192.168.2.117:6443 --kubeconfig=/etc/kubernetes/admin.conf api-versions'
Sep  4 03:09:00.511: INFO: stderr: ""
Sep  4 03:09:00.511: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:09:00.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-dmqvw" for this suite.
Sep  4 03:09:06.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:09:06.637: INFO: namespace: e2e-tests-kubectl-dmqvw, resource: bindings, ignored listing per whitelist
Sep  4 03:09:06.667: INFO: namespace e2e-tests-kubectl-dmqvw deletion completed in 6.14956612s

[32mâ€¢ [SLOW TEST:6.637 seconds][0m
[sig-cli] Kubectl client
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl api-versions
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
    should check if v1 is in available api versions  [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:09:06.668: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-e29616e7-afef-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 03:09:06.846: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e296e196-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-projected-97cpv" to be "success or failure"
Sep  4 03:09:06.851: INFO: Pod "pod-projected-configmaps-e296e196-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.88884ms
Sep  4 03:09:08.857: INFO: Pod "pod-projected-configmaps-e296e196-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01016906s
[1mSTEP[0m: Saw pod success
Sep  4 03:09:08.857: INFO: Pod "pod-projected-configmaps-e296e196-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:09:08.861: INFO: Trying to get logs from node node3 pod pod-projected-configmaps-e296e196-afef-11e8-8336-00073e906c7f container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:09:08.883: INFO: Waiting for pod pod-projected-configmaps-e296e196-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:09:08.887: INFO: Pod pod-projected-configmaps-e296e196-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] Projected
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:09:08.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-97cpv" for this suite.
Sep  4 03:09:14.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:09:14.983: INFO: namespace: e2e-tests-projected-97cpv, resource: bindings, ignored listing per whitelist
Sep  4 03:09:15.046: INFO: namespace e2e-tests-projected-97cpv deletion completed in 6.15347308s

[32mâ€¢ [SLOW TEST:8.378 seconds][0m
[sig-storage] Projected
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:09:15.046: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-e793a909-afef-11e8-8336-00073e906c7f
[1mSTEP[0m: Creating a pod to test consume configMaps
Sep  4 03:09:15.220: INFO: Waiting up to 5m0s for pod "pod-configmaps-e794851a-afef-11e8-8336-00073e906c7f" in namespace "e2e-tests-configmap-lnxkn" to be "success or failure"
Sep  4 03:09:15.225: INFO: Pod "pod-configmaps-e794851a-afef-11e8-8336-00073e906c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.94118ms
Sep  4 03:09:17.231: INFO: Pod "pod-configmaps-e794851a-afef-11e8-8336-00073e906c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01072346s
[1mSTEP[0m: Saw pod success
Sep  4 03:09:17.231: INFO: Pod "pod-configmaps-e794851a-afef-11e8-8336-00073e906c7f" satisfied condition "success or failure"
Sep  4 03:09:17.235: INFO: Trying to get logs from node node3 pod pod-configmaps-e794851a-afef-11e8-8336-00073e906c7f container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Sep  4 03:09:17.259: INFO: Waiting for pod pod-configmaps-e794851a-afef-11e8-8336-00073e906c7f to disappear
Sep  4 03:09:17.263: INFO: Pod pod-configmaps-e794851a-afef-11e8-8336-00073e906c7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:09:17.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-lnxkn" for this suite.
Sep  4 03:09:23.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:09:23.388: INFO: namespace: e2e-tests-configmap-lnxkn, resource: bindings, ignored listing per whitelist
Sep  4 03:09:23.419: INFO: namespace e2e-tests-configmap-lnxkn deletion completed in 6.15123778s

[32mâ€¢ [SLOW TEST:8.373 seconds][0m
[sig-storage] ConfigMap
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:09:23.420: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Sep  4 03:09:43.613: INFO: Container started at 2018-09-04 03:09:24 +0000 UTC, pod became ready at 2018-09-04 03:09:43 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:09:43.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-tft96" for this suite.
Sep  4 03:10:05.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:10:05.706: INFO: namespace: e2e-tests-container-probe-tft96, resource: bindings, ignored listing per whitelist
Sep  4 03:10:05.772: INFO: namespace e2e-tests-container-probe-tft96 deletion completed in 22.1531154s

[32mâ€¢ [SLOW TEST:42.352 seconds][0m
[k8s.io] Probing container
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679[0m
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: http [NodeConformance] [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] Networking
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:10:05.772: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-nsvws
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Sep  4 03:10:05.939: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Sep  4 03:10:22.019: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.32.0.8:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nsvws PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 03:10:22.019: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
Sep  4 03:10:22.375: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:10:22.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-nsvws" for this suite.
Sep  4 03:10:44.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:10:44.432: INFO: namespace: e2e-tests-pod-network-test-nsvws, resource: bindings, ignored listing per whitelist
Sep  4 03:10:44.535: INFO: namespace e2e-tests-pod-network-test-nsvws deletion completed in 22.1547174s

[32mâ€¢ [SLOW TEST:38.763 seconds][0m
[sig-network] Networking
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for node-pod communication: http [NodeConformance] [Conformance]
    [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould provide secure master service  [Conformance][0m
  [37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[BeforeEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
[1mSTEP[0m: Creating a kubernetes client
Sep  4 03:10:44.536: INFO: >>> kubeConfig: /etc/kubernetes/admin.conf
[1mSTEP[0m: Building a namespace api object
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Sep  4 03:10:44.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-vnwhd" for this suite.
Sep  4 03:10:50.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 03:10:50.798: INFO: namespace: e2e-tests-services-vnwhd, resource: bindings, ignored listing per whitelist
Sep  4 03:10:50.877: INFO: namespace e2e-tests-services-vnwhd deletion completed in 6.15194268s
[AfterEach] [sig-network] Services
  /root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

[32mâ€¢ [SLOW TEST:6.342 seconds][0m
[sig-network] Services
[90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide secure master service  [Conformance]
  [90m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684[0m
[90m------------------------------[0m
[36mS[0m[36mS[0mSep  4 03:10:50.878: INFO: Running AfterSuite actions on all node
Sep  4 03:10:50.878: INFO: Running AfterSuite actions on node 1


[91m[1mSummarizing 2 Failures:[0m

[91m[1m[Fail] [0m[90m[sig-apps] StatefulSet [0m[0m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic] [0m[91m[1m[It] should perform canary updates and phased rolling updates of template modifications [Conformance] [0m
[37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/statefulset_utils.go:323[0m

[91m[1m[Fail] [0m[90m[sig-apps] StatefulSet [0m[0m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic] [0m[91m[1m[It] should perform rolling updates and roll backs of template modifications [Conformance] [0m
[37m/root/gopath/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/statefulset_utils.go:339[0m

[1m[91mRan 166 of 996 Specs in 5535.459 seconds[0m
[1m[91mFAIL![0m -- [32m[1m164 Passed[0m | [91m[1m2 Failed[0m | [33m[1m0 Pending[0m | [36m[1m830 Skipped[0m --- FAIL: TestE2E (5535.53s)
FAIL

Ginkgo ran 1 suite in 1h32m16.84866208s
Test Suite Failed
!!! Error in ./hack/ginkgo-e2e.sh:143
  Error in ./hack/ginkgo-e2e.sh:143. '"${ginkgo}" "${ginkgo_args[@]:+${ginkgo_args[@]}}" "${e2e_test}" -- "${auth_config[@]:+${auth_config[@]}}" --ginkgo.flakeAttempts="${FLAKE_ATTEMPTS}" --host="${KUBE_MASTER_URL}" --provider="${KUBERNETES_PROVIDER}" --gce-project="${PROJECT:-}" --gce-zone="${ZONE:-}" --gce-region="${REGION:-}" --gce-multizone="${MULTIZONE:-false}" --gke-cluster="${CLUSTER_NAME:-}" --kube-master="${KUBE_MASTER:-}" --cluster-tag="${CLUSTER_ID:-}" --cloud-config-file="${CLOUD_CONFIG:-}" --repo-root="${KUBE_ROOT}" --node-instance-group="${NODE_INSTANCE_GROUP:-}" --prefix="${KUBE_GCE_INSTANCE_PREFIX:-e2e}" --network="${KUBE_GCE_NETWORK:-${KUBE_GKE_NETWORK:-e2e}}" --node-tag="${NODE_TAG:-}" --master-tag="${MASTER_TAG:-}" --cluster-monitoring-mode="${KUBE_ENABLE_CLUSTER_MONITORING:-standalone}" --prometheus-monitoring="${KUBE_ENABLE_PROMETHEUS_MONITORING:-false}" ${KUBE_CONTAINER_RUNTIME:+"--container-runtime=${KUBE_CONTAINER_RUNTIME}"} ${MASTER_OS_DISTRIBUTION:+"--master-os-distro=${MASTER_OS_DISTRIBUTION}"} ${NODE_OS_DISTRIBUTION:+"--node-os-distro=${NODE_OS_DISTRIBUTION}"} ${NUM_NODES:+"--num-nodes=${NUM_NODES}"} ${E2E_REPORT_DIR:+"--report-dir=${E2E_REPORT_DIR}"} ${E2E_REPORT_PREFIX:+"--report-prefix=${E2E_REPORT_PREFIX}"} "${@:-}"' exited with status 1
Call stack:
  1: ./hack/ginkgo-e2e.sh:143 main(...)
Exiting with status 1
2018/09/04 03:10:50 process.go:155: Step './hack/ginkgo-e2e.sh --ginkgo.focus=\[Conformance\]' finished in 1h32m17.61287118s
2018/09/04 03:10:50 main.go:307: Something went wrong: encountered 1 errors: [error during ./hack/ginkgo-e2e.sh --ginkgo.focus=\[Conformance\]: exit status 1]
2018/09/04 03:10:50 e2e.go:81: err: exit status 1
exit status 1
k8s monitor pv...
